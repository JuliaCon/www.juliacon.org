- speaker: "Sacha Verweij and Jane Herriman"
  avatar: https://avatars3.githubusercontent.com/u/5799177?s=460&v=4
  affiliation: "Stanford University and Julia Computing"
  title: "An Introduction to Julia"
  type: workshop
  abstract: >
    Are you new to Julia?! This beginners’ tutorial should be accessible to anyone with technical computing needs and some experience with another language. We will show you why Julia is special, demonstrate how easy Julia is to learn, and get you writing some Julia code.
  desc: |
    Are you new to Julia?! This introductory workshop should be accessible to anyone with technical computing needs and some experience with another programming language. We will show you why Julia is special, demonstrate how easy Julia is to learn, and get you writing Julia code.

    In the first half of this tutorial, we will briefly introduce the language, giving attendees a sense of why Julia is special and what needs Julia meets. After that, we will show how easy it is to pick up Julia’s syntax, covering string manipulation, data structures, loops, conditionals, and functions.

    In the second half of this tutorial, we will illustrate Julia’s speed, power, and expressiveness. Among other things, we will look at Julia’s generic linear algebra infrastructure, benchmark Julia against C and Python, and discuss how Julia’s design paradigm leads to flexible performance.

    Exercises to ingrain concepts will be included throughout the tutorial with an integrative exercise at the end.
  bio: |
    Jane Herriman is Director of Diversity and Outreach at Julia Computing and a PhD student in the Department of Applied Physics and Materials Science at Caltech. She has completed part of her PhD at Lawrence Livermore National Lab.

    Sacha Verweij has recently completed his PhD in Applied Physics and Computational Mathematics at Stanford University, and is a core developer of the Julia language.
  id: 1

- speaker: "Andy Ferris"
  avatar: https://avatars3.githubusercontent.com/u/2974526?s=460&v=4
  affiliation: "Fugro Roames"
  title: "A practical introduction to metaprogramming in Julia"
  type: workshop
  abstract: >
    Julia focuses on speed and user productivity, due in part to its metaprogramming capability. This workshop arms you with the knowledge to create fast, generic and easy-to-use APIs using techniques including multiple dispatch, recursion, traits, constant propagation, macros, and generated functions.
  desc: |
    In many programming environments, user friendliness must be traded of with execution speed. Using abstractions or “generic” code may come with a run-time overhead. Avoiding abstract or generic code exposes the user to underlying details that they may not care about, making code harder to read and reason about at a higher level, reducing programmer productivity. Often two languages are even employed - one for rapid prototyping, and one for deployment.

    It doesn’t have to be this way. The Julia language has been carefully constructed to allow for many common abstractions to be dealt with statically at compile time and have a have a zero run-time cost. This workshop will cover the topic of “metaprogramming” in Julia, which plays a large role in providing for low-cost abstractions and generic APIs. Traditionally, a “meta” program is logic which executes at compile time to help generate the code of a resulting program - that is, it is code that generates other code.

    In this workshop we will cover the building blocks of metaprogramming in Julia, starting with one of its core concepts - multiple dispatch, which in combination with the type system is itself is a Turing-complete computational environment. We will then begin working our way to more advanced topics such as traits, macros, constant propagation and generated functions, following approximately this order:

    * Multiple dispatch as a metaprogramming technique
    * Method inlining: faster than C
    * Games with tuples: splatting, slurping and recursion
    * Dispatch revisited: traits
    * Constant propagation (and what are @pure functions?)
    * Expressions and macros
    * Generated functions and when (not) to use them
    * This workshop will attempt to be a pedagogical tutorial on how and when to use these techniques, full of practical examples I’ve seen in the wild or have used in my own code. Consideration will be given in how to use metaprogramming and still maintain a readable code base. Advice will also be provided on how to work with the compiler, and not against it, and how to make effective use of tools such as @code_typed. At the end of the workshop I hope you will have learned a technique or two that will help you to create generic, user-friendly APIs without sacrificing peak performance.
  bio: |
    I am an algorithm and software engineer at Fugro Roames, applying machine learning techniques to big data in order to make sense of and to model the physical world. I have been using Julia since v0.3 for both research and commercial production-at-scale, and am the author of several Julia packages including StaticArrays.
  id: 2

- speaker: "Pontus Stenetorp"
  avatar: https://avatars1.githubusercontent.com/u/354934?s=460&v=4
  affiliation: "University College London"
  title: "Machine Learning with Julia: Elegance, Speed and Ease"
  type: workshop
  abstract: >
    Machine Learning has become one of the hottest research and industry areas over the last few years; we believe Julia is the strongest contender to become the language for Machine Learning and in this tutorial we will give a flying start to train/deploy models and use of the power that Julia brings.
  desc: |
    Machine Learning (ML) is at its core the art of programming by data, rather than by hand, and ML has risen to become one of the most desirable skills in academia and industry. The common maxim is that two traits control who rules the ML landscape, ability to find and ingest more data and those that can innovate the quickest. Given these traits, we argue that Julia is uniquely poised as a very strong contender as the language for ML; as we allow for quick development cycles and offer unrivalled speed. After a quick introduction to the basics of ML, we will give the audience a description of the lay of the land in terms of libraries and frameworks in Julia, and finally proceed to build simple to complex models using the premier framework Flux. After attending the workshop the audience will be familiar with the basics of ML to avoid common pitfalls and be ready to tackle their own ML problems the Julian way.
  bio: |
    I am Pontus Stenetorp, a researcher and educator that finds Natural Language Processing (NLP) and Machine Learning research to be fascinating. The widely-adopted text annotation and visualisation tool brat is one of my creations and since 2012 a majority of my work has been on representation learning (Deep Learning) for natural language.

    My current research focuses on end-to-end models that learns with a minimal amount of human supervision – with a particular focus on allowing computers to pass real-world exams – and is supported by the Paul G Allen Family Foundation. If you share any of my research interests, do have a look at my list of publications and if you have questions regarding my research, feel free to contact me. I also teach and supervise student research projects in my area of expertise.

    Currently, I am a Senior Research Associate at University College London (UCL) and a member of the Machine Reading Group lead by Reader Sebastian Riedel at the Department of Computer Science. I received a PhD from the University of Tokyo in 2013 and a MSc Eng from the Royal Institute of Technology (KTH) in 2010. In my spare time I contribute to the Julia programming language community, read plenty of books, and enjoy being a mediocre amateur photographer.
  resources:
    - name: "Repo"
      url: "http://fluxml.ai/"
  id: 3

- speaker: "Sheehan Olver"
  avatar: https://avatars3.githubusercontent.com/u/1229737?s=400&v=4
  affiliation: "Imperial College, London"
  title: "Numerical Analysis in Julia"
  type: workshop
  abstract: >
    This workshop brings together 4 speakers on different topics in numerical analysis, to demonstrate the strengths of Julia’s approach to scientific computing in atomistic simulations, function approximation, differential equations, fast transformations, validated numerics, and linear algebra.
  desc: |
    This workshop proposal brings together 4 speakers on different topics in numerical analysis. The aim of the workshop is to have demonstrations of Julia packages in this area in a way to motivate the results to a “general” audience. Our speakers cover a variety of areas to give a broad demonstration of what is now possible using Julia.

    Speakers and titles
    -------------------
    * Sheehan Olver: ApproxFun.jl, Approximating Functions and Solving Differential Equations.
    * David P. Sanders: ValidatedNumerics.jl, Rigorous Floating-point Calculations with Interval Arithmetic.
    * R. Mikael Slevinsky: FastTransforms.jl, Fast Orthogonal Polynomial Transforms.
    * Weijian Zhang: MatrixDepot.jl, Testing Linear Algebra Algorithms in Julia.

    Abstracts
    ---------
    *ApproxFun.jl, Approximating Functions and Solving Differential Equations*
    Sheehan Olver, Imperial College, London

    ApproxFun.jl is a Julia package that makes working with functions on a computer fast and easy. Basic algebra and calculus operations are available, so that one can, for example, differentiate the function $\sin\cos^2 x$ as easy as typing `sin(cos(x)^2)'`. Further capabilities include solving differential equations and random number sampling. This talk will demonstrate the capabilities of ApproxFun, and how Julia’s approach to typing allows for these capabilities to be used with other types, such as Dual numbers (from DualNumbers.jl) or BigFloats.

    *ValidatedNumerics.jl, Rigorous Floating-point Calculations with Interval Arithmetic*
    David P. Sanders, Universidad Nacional Autónoma de México

    I will present a suite of Julia packages in the JuliaIntervals organisation which provide implementations of numerical methods that provide results that are guaranteed to be correct. These are based on interval arithmetic, i.e. defining arithmetic and elementary functions acting on intervals of real numbers.

    This gives us a tool to calculate with continuous sets of real numbers, and thus rigorously bound the range of a function over a given set. Applications of this technology include finding, in a guaranteed way, all the roots of a multivariable function in a given region of space, and finding the global optimum of a function.

    *FastTransforms.jl, Fast Orthogonal Polynomial Transforms*
    R. Mikael Slevinsky, University of Manitoba

    FastTransforms.jl allows the user to conveniently work with orthogonal polynomials with degrees well into the millions. Transforms include conversion between Jacobi polynomial expansions, with Chebyshev, Legendre, and ultraspherical polynomial transforms as special cases. For the signal processor, all three types of nonuniform fast Fourier transforms available. As well, spherical harmonic transforms and transforms between orthogonal polynomials on the triangle allow for the efficient simulation of partial differential equations of evolution. Algorithms include methods based on asymptotic formulae to relate the transforms to a small number of fast Fourier transforms, matrix factorizations based on the Hadamard product, hierarchical matrix decompositions à la Fast Multipole Method, and the butterfly algorithm.

    *MatrixDepot.jl, Testing Linear Algebra Algorithms in Julia*
    Weijian Zhang, University of Manchester

    Test matrices are important for exploring the behavior of linear algebra algorithms and for measuring their performance with respect to accuracy, stability, convergence rate, speed, or robustness. We give a brief historical remark on the development of test matrices in different programming languages and then focus on the advantage of using MatrixDepot.jl for testing and exploring new algorithms in Julia. Using both contrived and real-world examples, we demonstrate the power of MatrixDepot.jl which takes advantage of many nice Julia features, such as using multiple dispatch to help provide a simple user interface and to allow matrices to be generated in any of the numeric data types supported by the language.
  bio: |
    I am a Reader (equivalent to Assoc. Professor) in Applied Mathematics and Mathematical Physics at Imperial College, London. My research is in numerics, in particular spectral methods and complex analytical methods. I have extensive experience with programming Julia, having developed several packages (ApproxFun.jl, BandedMatrices.jl, BlockBandedMatrices.jl, etc.).
  id: 4

- speaker: "David Anthoff"
  avatar: https://avatars2.githubusercontent.com/u/1036561?s=400&v=4
  affiliation: "University of California, Berkeley"
  title: "Queryverse"
  type: workshop
  abstract: >
    This workshop will introduce the Queryverse family of packages, a unified data science stack on julia. It provides tools for file IO, data querying, visual data exploration and statistical plotting. It also integrates with a large number of other julia packages.
  desc: |
    This talk will give an update on the current state of the Queryverse. I will highlight packages for file IO (CSVFiles.jl, ExcelFiles.jl, StatFiles.jl, FeatherFiles.jl, ParquetFiles.jl), querying and manipulating data (Query.jl), visual data exploration (DataVoyager.jl) and graphics (VegaLite.jl). I will show how all of these pieces are designed to work together and provide a unified API for users that spans traditional tabular data and data in custom julia types. I will also highlight how the Queryverse integrates smoothly with all the other julia packages in this space.
  bio: |
    David Anthoff is an environmental economist who studies climate change and environmental policy. He co-develops the integrated assessment model FUND that is used widely in academic research and in policy analysis. His research has appeared in Science, the American Economic Review, Nature Climate Change, the Journal of Environmental Economics and Management, Environmental and Resource Economics, the Oxford Review of Economic Policy and other academic journals. He contributed a background research paper to the Stern Review and has advised numerous organizations (including US EPA and the Canadian National Round Table on the Environment and the Economy) on the economics of climate change.

    He is an assistant professor in the Energy and Resources Group at the University of California at Berkeley, a senior fellow at the Berkeley Institute for Data Science and a University Fellow at Resources for the Future. Previously he was an assistant professor in the School of Natural Resources and Environment at the University of Michigan, a postdoc at the University of California, Berkeley and a postdoc at the Economic and Social Research Institute in Ireland. He also was a visiting research fellow at the Smith School of Enterprise and the Environment, University of Oxford.

    He holds a PhD (Dr. rer. pol.) in economics from the University of Hamburg (Germany) and the International Max Planck Research School on Earth System Modelling, a MSc in Environmental Change and Management from the University of Oxford (UK) and a M.Phil. in philosophy, logic and theory of science from Ludwig-Maximilians-Universität München (Germany).
  resources:
    - name: "Repo"
      url: "https://github.com/davidanthoff/Query.jl"
  id: 5

- speaker: "Chris Rackauckas"
  avatar: https://avatars3.githubusercontent.com/u/1814174?s=460&v=4
  affiliation: "UC Irvine and MIT"
  title: "Solving Partial Differential Equations with Julia "
  type: workshop
  abstract: >
    Climate scientists solve fluid dynamics PDEs. Biologists solve reaction-diffusion PDEs. Economists solve optimal control PDEs. But solving PDEs is hard! Where do you start? This workshop gives a broad overview of the Julia package ecosystem and shows how to tie it together to solve these problems.
  desc: |
    Partial differential equations (PDEs) are used throughout scientific disciplines, modeling diverse phenomena such as the spread of chemical concentrations across biological organisms to global temperature flows. However, solving PDEs efficiently is not easy: it requires a vertical toolkit with many interconnected pieces. In this workshop we will introduce the participants to some basic PDEs, where they come from, and how to tie together the various tools across the Julia package ecosystem to solve them efficiently.

    We will start by focusing on elliptic problems and show how these decompose into solving sparse linear systems. To solve the resulting linear systems, the participants will be introduced three methods: Julia’s special matrix types for efficient dense solutions, BandedMatrices.jl for more generic banded operators, and IterativeSolvers.jl for Krylov methods. The differences between the methodologies and the current status of distributed and GPU compatibility will be discussed. From there, the extension to nonlinear elliptic problems will be shown as effectively solving nonlinear systems with sparse Jacobians, and demonstrations/comparisons of Roots.jl, NLsolve.jl, and Sundials.jl’s KINSOL for solving the resulting systems will be addressed. Lastly, the concept of pseudospectral discretizations will be introduced using the library ApproxFun.jl, it will be shown how this methodology simply leads to different linear/nonlinear systems.

    After understanding the tooling for elliptic PDEs, “time-dependent” PDEs such as parabolic and hyperbolic PDEs will be introduced. It will be shown how similar discretizations as done in the elliptic portion lead to systems of coupled ordinary differential equations (ODEs). It will be demonstrated how to efficiently solve the resulting ODE systems via DifferentialEquations.jl using methods such as via banded Jacobian Rosenbrock integrators, Newton-Krylov BDF, Implicit-Explicit (IMEX) Runge-Kutta, and exponential integrators like ETDRK4. Participants will be shown how to integrate pseudospectral operators from ApproxFun.jl and linear solvers from IterativeSolvers.jl to customize the integrators to their problem. Additionally, special time-stepping issues for hyperbolic PDEs and the strong-stability preserving (SSP) integrators will be introduced.

    Together, the workshop participants should be able to leave with a good understanding of how to tie together the Julia scientific packages to efficiently solve a large class of partial differential equations.
  bio: |
    I am a mathematician and theoretical biologist at the University of California, Irvine. My programming language of choice is Julia and I am the lead developer of the JuliaDiffEq organization dedicated to solving differential equations (and includes the package DifferentialEquations.jl). My research is in time stepping methods for solving stochastic differential equations (SDEs) and applications to stochastic partial differential equations (SPDEs) which model biological development.
  resources:
    - name: "Repo"
      url: "https://github.com/JuliaDiffEq/DifferentialEquations.jl"
  id: 6

- speaker: "Juan Pablo Vielma"
  avatar: https://avatars2.githubusercontent.com/u/6369022?s=460&v=4
  affiliation: "MIT Sloan"
  title: "The JuMP ecosystem for mathematical optimization "
  type: workshop
  abstract: >
    JuMP is an award-winning DSL for mathematical optimization that has quickly become the gold-standard for its simplicity, performance, and versatility. A major overhaul of JuMP will be finalized during the JuMP-dev workshop in June, so it is the perfect time for an updated tutorial and feature demo.
  desc: |
    JuMP is a multi-award-winning domain-specific language for mathematical optimization. JuMP has already been successfully used in academic and industrial problems related to marketing, causal inference, daily fantasy sports, optimal control of aerial drones, machine learning, school bus routing, sustainable power systems expansion, and decarbonization of electrical networks. The JuMP ecosystem gives access to a wide range of highly-effective commercial and open-source optimization tools in a natural syntax that requires only a basic knowledge of mathematical optimization. JuMP provides this access with a performance that matches or exceeds those of commercial and open-source alternatives, as well as unparalleled versatility and extensibility allowed by the advanced features of the Julia language. In particular, JuMP and its infrastructure was used to develop the solver Pajarito.jl, which is currently the state-of-the-art for the class known as mixed-integer conic optimization problems. JuMP has recently received a major overhaul that should further facilitate the development of similar advanced optimization tools.

    In this tutorial, we begin with basic syntax and features of JuMP and associated packages assuming no previous knowledge of JuMP and only an elementary knowledge of mathematical optimization. We then cover more advanced features, give performance tips, and cover the recent improvements to JuMP developed in the second Annual JuMP-dev Workshop. Finally, we demo some state-of-the-art features, including showing how various packages in the rich Julia ecosystem can be seamlessly combined to provide simple solutions to complicated problems in the optimal control of aerial drones.
  bio: |
    Juan Pablo Vielma is an associate professor at MIT’s Sloan School of Management and is also associated to MIT’s Operations Research Center. Juan Pablo’s research interests include the development of theory and technology for mathematical optimization and their application to problems in marketing, statistics and sustainable management of energy and natural resources. Juan Pablo is the Ph.D. advisor of two of the creators of JuMP and continues to be closely involved in JuMP’s development. Some projects he is currently associated with are the Pajarito Solver, JuMP’s extension for piecewise linear optimization and the Cassette and Capstan tools.
  resources:
    - name: "Repo"
      url: "https://github.com/JuliaOpt/JuMP.jl"
  id: 7

- speaker: "Avik Sengupta"
  avatar: https://avatars1.githubusercontent.com/u/378918?s=460&v=4
  affiliation: "Julia Computing"
  title: "Natural Language Processing in Julia"
  type: workshop
  abstract: >
    A hands on workshop demonstrating the use of natural language processing tools in Julia. Working with textual data, we will discuss methods for data collection, parsing, pre-processing, embedding, classification and deep neural networks.
  desc: |
    In this hands on workshop, we will explore the use of natural language processing tools in Julia, with a particular focus on statistical machine learning based approaches. The content will be based primarily around the TextAnalysis.jl and Flux.jl packages. We will learn some of the primary algorithms in this area, and implement practical examples using these packages. The course will be aimed at someone who has a basic understanding of the Julia programming language, but no prior experience of natural language processing

    * Data Collection
        * Using existing corpora
        * Web scraping to collect your own data
        * Data storage and representation
    * Pre-processing
        * Stemming
        * Stopwords
    * Word representations
        * Bag of words, TF-IDF
        * Text Rank algorithm for summarisation
    * Word Embeddings
    * Deep neural networks for machine learning
        * Language Detection
        * Parsing
        * Text generation
  bio: |
    Avik has spent many years helping investment banks leverage technology in risk and capital markets. He’s worked on bringing AI powered solutions to investment research, and is currently the VP of Engineering at Julia Computing.
  resources:
    - name: "Repo"
      url: "https://github.com/JuliaText/TextAnalysis.jl"
  id: 8

- speaker: "Harsha Byadarahalli Mahesh"
  title: "JuliaPro post 1.0 release"
  type: "lightning"
  abstract: "JuliaPro is all set for a huge makeover post Julia 1.0 release, this talk is all about revealing the new features that will be included in the next generation of JuliaPro."
  desc: |
    <a href="https://juliacomputing.com/products/juliapro.html">JuliaPro</a> is a free prepackaged bundle of Julia which includes debugger, integrated development environment, 100+ curated packages, data visualization and plotting tools. More than 15,000 users have downloaded JuliaPro since its inception, and the number of JuliaPro users are growing every day.
    Julia 1.0 is bringing in a lot of new exciting features to Julia ecosystem. With this in mind, we’re improving JuliaPro to take advantage and enhance its usability. We are also adding new features to JuliaPro such as GPU support, reduced installer size, long term support and many more. All these exciting features will be showcased in this talk.
  bio: |

  id: 12

- speaker: "Jamie Brandon"
  avatar: "http://avatars.schd.ws/5/15/5709080/avatar.jpg.320x320px.jpg?928"
  title: "Julia as a platform for language development"
  type: "talk"
  abstract: "Language developers are torn between the need to quickly iterate on language designs and the need to prove that those designs can be efficiently implemented. I’ll show that Julia neatly captures many of the proposed solutions to this dilemma, making it a compelling platform for language development."
  desc: |
    Many problems turn out to be compiler problems, in fields as diverse as <a href="https://dl.acm.org/citation.cfm?id=2002940">database querying</a>, <a href="https://databricks.com/blog/2016/05/23/apache-spark-as-a-compiler-joining-a-billion-rows-per-second-on-a-laptop.html">‘big data’ engines</a>, <a href="https://www.tensorflow.org/performance/xla/">machine learning</a>, <a href="http://pyro.ai/">probabilistic programming</a>, <a href="https://facebook.github.io/relay/">web APIs</a>, <a href="https://angular.io/guide/aot-compiler">GUI development</a>, <a href="https://propane-lang.org/">network configuration</a>, <a href="https://lasp-lang.readme.io/">distributed systems</a> and <a href="http://alloytools.org/">model checking</a>.
    But creating a quality compiler from scratch takes an incredible amount of effort. The PL community has <a href="http://tratt.net/laurie/blog/entries/fast_enough_vms_in_fast_enough_time.html">long recognized</a> this problem and has produced a whole zoo of proposed solutions, including shared virtual machines (eg <a href="https://en.wikipedia.org/wiki/List_of_JVM_languages">JVM</a>, <a href="https://en.wikipedia.org/wiki/List_of_CLI_languages">CLR</a>), staging (eg <a href="http://terralang.org/">Terra</a>, <a href="http://epfldata.github.io/squid/home.html">Squid</a>) and partial evaluation (eg <a href="http://rpython.readthedocs.io/en/latest/index.html">RPython</a>, <a href="https://blog.plan99.net/graal-truffle-134d8f28fb69">Truffle</a>).
    Using examples from both personal and commercial projects, I’ll show that many of these approaches are already available in Julia, and can be mixed and matched as needed to produce fast language implementations with minimal effort. I’ll also cover problems we’ve encountered along with workarounds.
  bio: |
    I make programming languages and interfaces. Until recently a researcher at <a target="_blank" rel="nofollow me noopener noreferrer" href="http://relational.ai/">RelationalAI</a>, working on declarative languages for in-database machine learning.
  id: 13

- speaker: "Ben J. Ward"
  title: "BioJulia and Bioinformatics in Julia: Past, Present, Future"
  type: "talk"
  abstract: "In this talk I will describe the past, present and the future (in the context of recent changes to sequencing technology and genome assembly techniques) of BioJulia, and how we are working towards our mission of provide a performant, human-friendly bioinformatics infrastructure."
  desc: |
    At JuliaCon 2015, Daniel Jones presented BioJulia: A modern Bioinformatics framework. In the years following, as julia has developed, so has BioJulia grown in the number of packages, and the number of contributors.
    At the same time, sequencing technology has moved at a rapid pace, resulting more data, and in new techniques for assembling and analysing genomes. As a result biologists and bioinformaticians face both conceptual, scientific, and engineering questions: What is the canonical representation of a genome? What is the best way to analyse genomic data to address my hypothesis? How can these analyses be made reliable and repeatable? How do we do it quickly and efficiently, and on commonly available hardware?
    In this talk I will present how BioJulia has developed since 2015 and how we have addressed some of the challenges current Bioinformatics practices have presented us with. I will also talk about some of the directions Bioinformatics research (in particular genome assembly and multi-genome analyses) is heading, and where I think BioJulia development will be heading in anticipation of this comming “pan-genomics era”.
  bio: |

  id: 14

- speaker: "George Datseris"
  title: "Why Julia is the most suitable language for science …and how we use it in JuliaDynamics"
  type: "talk"
  abstract: "Julia is the best language one can do science with. It combines high performance with intuitive & simple code, and allows 1-to-1 correspondence between code and scientific algorithm. I will present an overview of the packages of the JuliaDynamics GitHub org. as examples that justify this claim."
  desc: |
    Because scientific computing requires the highest performance, most science related libraries are written in C/Fortran and define a high-level API, most commonly in Python. Julia solves this “two-languages” problem, and also offers many more benefits. In my talk I want to focus on something that I consider a big, but often unstressed, asset of Julia: the fact that it brings unprecedented code clarity and intuition, both of which are crucial for scientific progress. I want to argue about how Julia removes “black-boxes” and “blind-trust” by allowing you to easily inspect and understand source code without being a developer.
    The packages of the <a href="https://juliadynamics.github.io/DynamicalSystems.jl/latest/">JuliaDynamics</a> GitHub organization (currently: <a href="https://github.com/JuliaDynamics/DynamicalSystemsBase.jl">DynamicalSystemsBase.jl</a>, <a href="https://github.com/JuliaDynamics/ChaosTools.jl">ChaosTools.jl</a> and <a href="https://github.com/JuliaDynamics/DynamicalBilliards.jl">DynamicalBilliards.jl</a>) have been written to take full advantage of this asset of Julia. In my talk I will briefly overview them and show examples of how one can have a 1-1 correspondence between computer code and scientific thought and algorithms.
  bio: |

  id: 15

- speaker: "S. Hessam M. Mehr"
  title: "Saving lives with Julia"
  type: "lightning"
  abstract: "Thanks to Julia’s speed and expressiveness, our very small team (1 developer!) was quickly able to create an ecosystem of Julia libraries for state-of-the-art automatic analysis of drug mixtures using nuclear magnetic resonance (NMR) spectroscopy data."
  desc: |
    Healthcare, law enforcement, and regulatory bodies worldwide are working hard to keep up with the recent outpour of new designer drugs hitting the streets. The poster child of the phenomenon, fentanyl, is a notoriously addictive synthetic opioid with numerous potent derivatives, some deadly in milligram quantities. Quite a few of these are routinely encountered in drug samples throughout Canada, often mixed with various cutting agents. Drug overdose related to fentanyls took the lives of 2,861 Canadians in 2016 alone.
    Whatever the appropriate response to the crisis, it would requires a new breed of analytical technique that can quickly differentiate between and quantify the many members of this growing zoo of opioids. To this end, a recent addition to the toolbox at Health Canada is nuclear magnetic resonance (NMR) spectroscopy, which studies the interaction between radiofrequency (RF) waves and atomic nuclei (typically hydrogen, <em>i.e.</em> proton) placed in a very strong magnetic field. The resulting spectra reflect the electronic/magnetic environment of each proton in a given chemical compound, giving an indication of its molecular structure. Although they provide a wealth of quantitative structural information about sample constituents, NMR spectra of complex mixtures are difficult to manually interpret, especially by non-experts. This is often the case with street drugs, where samples often contain 3-6 major components.
    Luckily, the NMR spectrum of a mixture can often be approximated by the linear combination of those of its constituents. We have used this property to write a Julia program that, given the NMR spectra for various compounds of interest, uses this mathematical decomposition scheme to find the exact composition of an unknown mixture. As always, things do get more complicated since the above relationship is only approximately true. In reality, mixing different chemicals together slightly modifies each compound’s contribution to the overall spectrum. Still, we found it straightforward to prototype and implement more robust implementations of the algorithm in Julia that could deal with this added complexity.
    The end result, <em>NMR.jl</em>, is the core project of the nascent <em>JuliaNMR</em> ecosystem on GitHub. <em>NMR.jl</em> aims to be a general-purpose NMR processing library and comes with state-of-the-art routines for automatic quantitative analysis of mixtures. Julia’s multiple dispatch semantics, excellent performance, and interactive development style allowed us to design much of the library in an exploratory manner and freely experiment with different ideas.
    This talk gives an overview of <em>NMR.jl</em> and how its spectral decomposition algorithm is being used at Health Canada’s Drug Analysis Service. We hope to demonstrate the unique features of the Julia programming language that helped quickly prototype and implement <em>NMR.jl</em> and the custom automation routines around it, all without sacrificing performance. Aside from the language itself, we hope to credit the excellent Julia libraries (e.g. <em>Plots.jl</em>) without which <em>NMR.jl</em> would not have been possible.
  bio: |
    Hessam Mehr is an electrical engineer turned synthetic chemist who graduated from the University of British Columbia last year and badly misses the good old days of graduate school. Between September 2017 and March 2018, Hessam was working with Health Canada to develop techniques for analyzing drug samples using nuclear magnetic resonance. Currently, he is a post-doc at the University of Glasgow where he continues to spend his free time biking, learning new human and computer languages, practicing calligraphy (not very well at all), and baking bread.

  id: 16

- speaker: "Meghan Ferrall-Fairbanks"
  title: "Unraveling lymphoma tumor microenvironment interactions with Julia"
  type: "lightning"
  abstract: "Julia is my scientific computing programming language of choice to implement my mathematical model of Burkitt lymphoma, a highly aggressive disease plaguing children in Africa. This talk will appeal to people interested in solving Mathematical Biology applications with Julia."
  desc: |
    Burkitt’s lymphoma is a highly aggressive B-cell non-Hodgkin lymphoma that accounts for about half of all childhood cancers in areas of holoendemic malaria across Africa and Papau New Guinea. This rapidly growing malignancy has a cell doubling time of every 24-48 hours, suggesting that the tumor microenvironment plays an important role in tumor evolution and progression. To study the tumor microenvironment, we used Jupyter Notebook to implement a game theoretic, ordinary differential equation-based framework. We seek to understand the dynamics between lymphoma cells, fibroblasts, and macrophages using DifferentialEquations.jl. To this end, we parameterized our mathematical model using longitudinal cell-growth data from triple culture experiments with different initial conditions of each cell type, using MonteCarloProblem with Optim.jl and L1-Loss Regularization with PenaltyFunctions.jl. Julia’s platform provided a cohesive, easy to use environment, customizable to our specific problem, allowing us to easily estimate our model parameters simultaneously over 47 different growth conditions. From our parameter estimated, we could infer the biological interactions in the lymphoma tumor microenvironment. This will enable us to propose better detection and treatment strategies for lymphoma. Julia provided an integrated ecosystem which allowed us to use one single platform to create our model, estimate parameters from experimental data, and make predictions from in silico simulations.
  bio: |

  id: 17

- speaker: "Josh Christie"
  avatar: "http://avatars.schd.ws/6/7a/5709052/avatar.jpg.320x320px.jpg?4d2"
  affiliation: "Fugro"
  title: "Understanding the real world: large-scale point cloud classification"
  type: "lightning"
  abstract: "Fugro Roames provides automated extraction of geointelligence at scale. I’ll discuss how we are using Julia in our machine learning pipeline to identify buildings, roads, trees, and other objects in unstructured point cloud data, and how we deliver billions of points without human intervention."
  desc: |
    Fugro has collected huge amounts of data relating to the Earth’s surface and subsurface. Manual methods of classification are time-consuming and expensive. In the last year, we have developed algorithms using Julia to provide per-point classification of 3D point clouds using our own spatial feature libraries in combination with classifiers such as XGBoost. This work has been so successful that we’ve been able to provide detail about a range of real-world objects, such as buildings, roads, powerlines, vehicles and fences, to our clients without requiring expensive and slow human quality assurance processes.
    In this talk I’ll discuss the machine learning algorithms we use, approaches for optimisation, data storage, and our greatest challenges and opportunities going forward.
  bio: |
    Josh is a data scientist/engineer at Fugro, where he develops machine learning algorithms to model the world from lidar and imagery data.
  id: 18

- speaker: "Diego Javier Zea"
  avatar: "http://abs.twimg.com/sticky/default_profile_images/default_profile_400x400.png"
  affiliation: "Sorbonne Université"
  title: "MIToS.jl: Mutual Information Tools for protein Sequence analysis in the Julia language"
  type: "lightning"
  abstract: "MIToS is a package developed for the analysis of protein sequence and structure. It allows fast and flexible calculation of conservation and coevolution scores and helps to analyze them. It has been used in a large dataset to understand evolutionary signals due to protein structures."
  desc: |
    Background Coevolution methods generate a growing interest in the scientific community due to its usefulness to predict the tridimensional protein structures, protein-protein binding interfaces and functionally important sites [1,2]. Mutual Information (MI) algorithm is useful for determining covariation or coevolving between positions in a Multiple Sequence Alignment (MSA). There is a great number of tools for estimating MI and derived scores from a MSA [3,4]. Although, none of them use a high level programming language, easy to use and modify, while having a good performance. As the Julia language is a high level programming language for scientific computing with a close to C performance [5], MIToS implements MI analysis and several useful tools for MSA and protein structure management in it.
    Materials and methods MIToS starting point was an improvement of the algorithm published by Buslje et. al. [1]. Other MI derived scores described in Brown & Brown [3] and Dickson & Gloor [4] were also included in MIToS. MIToS implements all the necessary tools for developing and testing new scores based on amino acid frequencies: functions and types for dealing with MSAs, parsing protein structures and determine inter residue contacts, mapping information between sequence and structure using SIFTS and predictive performance testing using ROC curves. MIToS also allows running these analysis from a command line, without requiring programming knowledge. We successfully used it to integrate structural and sequence information from a protein family large dataset.
    Results MIToS modules allow to write and run an entire protein sequence and structure analysis pipeline in a single programming language. Julia performance and easy to use parallelism allow us to run these analyses on a large dataset of protein sequence and structures and to test multiple hypotheses, parameter combinations, etc. As a result, we were able to create new knowledge about the relation between the evolutionary signals and the change of protein structures through the evolution [6].
    Conclusions MIToS allows users to access the the Julia language programming power for analysing and managing protein multiple sequence alignments. The implementation of several useful scripts in MIToS for command line execution allows acceding to this new MI implementations and its derived score to non-programmers. MIToS tools makes MSA editing and MI calculation easy and facilitates the integration of sequence and structure information.
    References <ol type="1"> <li>Buslje, C. M., Santos, J., Delfino, J. M., & Nielsen, M. Correction for phylogeny, small number of observations and data redundancy improves the identification of coevolving amino acid pairs using mutual information. Bioinformatics 2009, 25(9), 1125-1131.
    * Buslje, C. M., Teppa, E., Di Doménico, T., Delfino, J. M., & Nielsen, M. Networks of high mutual information define the structural proximity of catalytic sites: implications for catalytic residue identification. PLoS Comput Biol 2010, 6(11), e1000978-e1000978.
    * Brown, C. A., & Brown, K. S. Validation of coevolving residue algorithms via pipeline sensitivity analysis: ELSC and OMES and ZNMI, oh my. PloS one 2010,5(6), e10779.
    * Dickson, R. J., & Gloor, G. B. The MIp Toolset: an efficient algorithm for calculating Mutual Information in protein alignments. arXiv preprint 2013, arXiv:1304.4573.
    * Bezanson, J., Edelman, A., Karpinski, S., & Shah, V. B. Julia: A fresh approach to numerical computing. arXiv preprint 2014, arXiv:1411.1607.
    * Zea, D.J., Monzon, A.M., Parisi, G. and Marino-Buslje, C., 2017. How is structural divergence related to evolutionary information?. bioRxiv, p.196782.
  bio: |
    I learned C at the university, then I did Bash, Perl, Python and R during the PhD. Now I’m a postdoc student doing Bioinformatics that has moved all its research pipeline into Julia. I think that Julia and its ecosystem are mature enough to do research with it. Also, MIToS shows how Julia can be used to solve the two/multiple language problem in Bioinformatics. MIToS also uses high-level abstractions that are possible in Julia to be faster than its C predecessor, even for someone without a strong programming background.
  id: 20

- speaker: "Jeff Mills"
  title: "BayesTesting.jl: Bayesian Hypothesis Testing without Tears"
  type: "lightning"
  abstract: "Bayestesting.jl is a Julia package that implements a new Bayesian hypothesis testing procedure that does not suffer from the problems inherent in both the standard Bayesian and frequentist approaches, and is easy to use in practice. Of interest to anyone who does any statistical hypothesis testing.
    <em>"
  desc: |
    BayesTesting.jl implements a fresh approach to hypothesis testing in Julia. The Jeffreys-Lindley-Bartlett paradox does not occur.&nbsp; Any prior can be employed, including uninformative and reference priors, so the same prior employed for inference can be used for testing, and objective Bayesian posteriors can be used for testing. In standard problems when the posterior distribution matches (numerically) the frequentist sampling distribution or likelihood, there is a one-to-one correspondence with the frequentist test.&nbsp; The resulting posterior odds against the null hypothesis are easy to interpret (unlike p-values), do not violate the likelihood principle, and result from minimizing a linear combination of type I and II errors rather than fixing the type I error before testing. The testing procedure satisfies the Neyman-Pearson lemma, so tests are uniformly most powerful, and satisfy the most general Bayesian robustness theorem.
    BayesTesting.jl provides functions for a variety of standard testing situations, along with more generic modular functions to easily allow the testing procedure to be employed in novel situations. For example, given any Monte Carlo or MCMC posterior sample for an unknown quantity, &theta;, the generic BayesTesting.jl function mcodds can be used to test hypotheses concerning &theta;, often with one or two lines of code.
    The talk will demonstrate application of the new approach in several standard situations, including testing a sample mean, comparison of means, and regression parameter testing. A brief presentation of the methodology will be followed by examples. The examples illustrate our experiences with implementing the new testing procedure in Julia over the past year.
  bio: |

  id: 21

- speaker: "Nathan Daly"
  avatar: "http://pbs.twimg.com/profile_images/621167588236595200/7eszbtra.jpg"
  title: "Julia apps on the App Store: Building and Distributing an application written in Julia"
  type: "talk"
  abstract: "Learn how to turn your software into a portable application you can compile, distribute - and sell - anywhere!
    Julia is great for building robust, cross-platform software. In April, I published the first-ever app on the Mac App Store written entirely in Julia. Learn how you can do the same!"
  desc: |
    Turning your Julia software into a compiled, portable application is simple. In only a few steps you can have your code compiled to run on any computer, even if your users have never heard of Julia.
    We will use <a href="https://github.com/NHDaly/ApplicationBuilder.jl">ApplicationBuilder.jl</a> to build an application together, starting from scratch and ending with a complete, distributable application.
    We will also discuss a few options for adding a GUI to your application.
    After this talk, you will be empowered to write, compile, and sell software written in Julia!
  bio: |

  id: 22

- speaker: "Hong Ge"
  avatar: "https://graph.facebook.com/v2.12/749661002068079/picture?width=400&height=400"
  affiliation: "University of Cambridge"
  title: "The Turing language for probabilistic programming"
  type: "talk"
  abstract: "We introduce recent developments in Turing.jl — a probabilistic programming language. Similar to Stan, Turing provides a black box tool for Bayesian inference. Turing provides researchers experts with a research toolbox for implementing, investigating and benchmarking new or composed algorithms."
  desc: |
    Probabilistic programming is becoming an attractive approach to probabilistic machine learning. Through relieving researchers from the tedious burden of hand-deriving inference algorithms, not only does it enable the development of more accurate and interpretable models but it also encourage reproducible research. However, successful probabilistic programming systems require flexible, generic and efficient inference engines. In this work, we present a system called Turing for flexible composable probabilistic programming inference. Turing has an intuitive modelling syntax and supports a wide range of sampling based inference algorithms. Most importantly, Turing inference is composable: it combines Markov chain sampling operations on subsets of model variables, e.g. using a combination of a Hamiltonian Monte Carlo (HMC) engine and a particle Gibbs (PG) engine. This composable inference engine allows the user to easily switch between black-box style inference methods such as HMC, and customized inference methods. Our aim is to present Turing and its composable inference engines to the community and encourage other researchers to build on this system to help advance the field of probabilistic machine learning.
  bio: |

  id: 23

- speaker: "Hayden Klok"
  title: "Teaching Statistics to the Masses with Julia"
  type: "lightning"
  abstract: "In this talk I first present the hurdles and challenges associated with teaching a course with a large cohort using Julia while still in development. I then move on to present a variety of unique perspectives on the presentation of elementary statistical concepts via short and concise code snippets."
  desc: |
    For several years, Julia has been used as a tool of choice for several specialized courses around the globe. However, with V1.0 still in the works, using it as a teaching tool for massive (service) statistics courses bears some risks. Nevertheless, in a second year engineer statistics course, taught to a student body involving 500 students, we have used Julia and JuliaBox for two years consecutively. Through this experience, we have also developed an array of elementary to intermediate coding examples, each presenting a different aspect of probability, statistics, and the Julia language.
  bio: |

  id: 24

- speaker: "Thijs van de Laar"
  avatar: "http://avatars.schd.ws/4/e3/5709067/avatar.jpg.320x320px.jpg?9d5"
  affiliation: "Eindhoven University of Technology"
  title: "ForneyLab.jl: a Julia Toolbox for Factor Graph-based Probabilistic Programming"
  type: "lightning"
  abstract: "Scientific modeling concerns a continual search for better models for given data sets. This process can be elegantly captured in a Bayesian inference framework. ForneyLab enables largely automated scientific design loops by deriving fast, analytic algorithms for approximate Bayesian inference."
  desc: |
    Scientific modeling concerns a continual search for better models for given data sets. This process can be elegantly captured in a Bayesian (probabilistic) inference framework. ForneyLab is an open source probabilistic programming toolbox that enables largely automated design loops by deriving fast, analytic algorithms for message passing-based approximate Bayesian inference.
    Probabilistic programming extends conventional programming languages with the facility to compute rationally with random variables through probability calculus. ForneyLab is a Julia package that allows the user to specify a probabilistic model and pose inference problems on those models. In return, FL automatically constructs a Julia program that executes a message passing-based approximate inference procedure. In conjunction with a specification of (possibly streaming) data sources, the inference program can be executed to fit the model to the data. Additionally, ForneyLab provides a measure of the performance of the model fit, thus facilitating comparison to alternative models. Typical applications include the design of dynamic models for (Bayesian) machine learning systems, statistical signal processing, computational neuroscience, etc.
    More specifically, a design cycle in ForneyLab consists of three phases. First, in the <em>build phase</em>, the end user specifies a (probabilistic) model. Through the use of macros, the model is specified in a domain-specific syntax that strongly resembles notational conventions in alternative probabilistic programming languages. Usually, even complex model specifications fit on less than one page of code. Under the hood, ForneyLab builds a <em>Forney-style factor graph</em> (FFG), which is a computational network representation of the model. A strong feature of the FFG formalism includes its extremely modular make-up, which allows re-use of computational inference primitives. The choice for FFG-based model specifications (and consequently, message passing-based inference procedures) is where ForneyLab differs from competing probabilistic programming languages (aside from our choice for a native Julia realization).
    Next, in the <em>schedule phase</em>, the user specifies the inference problem. This is usually encoded by a few lines of code. ForneyLab then automatically derives a message passing algorithm that, when executed, computes the posterior marginal probability over the desired variables. The generated message passing code may contain thousands of code lines, depending on the size of the model. A clear asset of message passing-based inference algorithms is that they are comprised of many cheap and analytical updates that can be re-used across models, and furthermore can potentially be implemented on dedicated (parallel) hardware configurations. This contrasts to modern sampling-based approaches to inference, such as Markov chain Monte Carlo and Automatic Differentiation Variational Inference, which usually require massive computational resources.
    In the final <em>infer phase</em>, ForneyLab parses and executes the automatically generated inference program. For the user, this action is initiated by one statement. Additionally, a separate function can be generated to evaluate the model fit, which provides insights on model quality and algorithm convergence during inference.
    ForneyLab relies heavily on Julia’s meta-programming functionality. Not only does it use macros for the model specification, but the main output is also a Julia program by itself. This flexibility, together with benefits of the modular FFG approach, makes it a powerful tool for a scientist or engineer who wants to develop models for a given data set.
  bio: |
    Thijs van de Laar received his MSc degree in natural sciences from the Radboud University Nijmegen in 2010. Currently he works as a PhD student in the BIASlab group (http://biaslab.org) at the Electrical Engineering department at Eindhoven University of Technology (TU/e). He is interested in Bayesian machine learning for personalized audio processing.
  id: 25

- speaker: "Peter Ahrens"
  avatar: "http://avatars.schd.ws/0/ae/5709087/avatar.jpg.320x320px.jpg?a58"
  affiliation: "MIT Computer Science and Artificial Intelligence Laboratory"
  title: "For-Loops Are Not a Frontend: Index Notation And The Future Of Array Compilers"
  type: "talk"
  abstract: "Index notation (Einstein summation) is an elegant representation for array operations, powering several recent high-level compilers for array/tensor algebra. Attend to enjoy a programmer-centric explanation of index notation, its generalizations, and how it will revolutionize array library design!"
  desc: |
    The task of writing a complete library for linear algebra can be summarized as:
    * For all linear algebra problems:
    * For all matrix and problem structures:
    * For all data types:
    * For all architectures and networks:
    * …
    * Produce the best algorithms with respect to performance and accuracy       <a href="https://people.eecs.berkeley.edu/~demmel/cs267_Spr14/Lectures/lecture12_densela_1_jwd14_v2_4pp.pdf">UC Berkeley CS267 Class Notes</a>
    In Julia, the explosion in the number of array types and operations (both in terms of representation and function) has added even more dimensions of complexity to this problem. Automation is necessary to handle the software engineering complexity of a performant linear algebra compiler, and defining the inputs with a unified generic computational framework for array operations is the first step.
    <a href="https://en.wikipedia.org/wiki/Einstein_notation">Index notation (Einstein summation)</a> is a powerful representation of array operations that is general enough to encapsulate most nested loops on array accesses, but simple enough for humans and machines to understand and manipulate. With some small generalizations of the datatypes and operations, this notation can elegantly express important computations in a staggering range of applications. A few examples include <a href="https://arxiv.org/abs/1802.04730">machine learning</a>, <a href="http://www.csc.lsu.edu/~gb/TCE/">quantum chemistry</a>, <a href="http://graphblas.org/index.php?title=Graph_BLAS_Forum">graph algorithms</a>, <a href="http://glaros.dtc.umn.edu/gkhome/node/1146">data mining</a>, and <a href="http://halide-lang.org/">image processing</a>.
    Index notation is catching on as an API for array metaprogramming. Several emerging computational frameworks for linear algebra and tensor operations have have emerged that use index notation (or subsets thereof) to describe input operations. <a href="http://tensor-compiler.org/">TACO</a> (a compiler for operations on sparse tensors), <a href="http://solomon2.web.engr.illinois.edu/ctf/">Cyclops</a> (A library for performing distributed tensor contractions), Facebook’s <a href="https://arxiv.org/abs/1802.04730">Tensor Comprehensions</a> (A compiler for tensor expressions seen in deep learning applications) and the <a href="http://www.csc.lsu.edu/~gb/TCE/">Tensor Contraction Engine</a> (A library for dense tensor operations arising in computational chemistry) are just a few prominent examples of libraries which use index notation to describe input operations. Libraries for stencil computation (such as <a href="http://halide-lang.org/">Halide</a>) also often use syntax which can be thought of as a generalization of index notation.
    By using this simple representation of array computations, we can separate the description of an operation from how the operation is actually implemented. When the operation is described in index notation, it becomes easy to optimize the implementation or specialize the whole operation for new or mixed array or element types. With small modifications, index notation can generalize broadcast, transpose, and reduce operations, providing more specific control of which axes should be manipulated. Index notation can also generalize Julia’s more complicated getindex and setindex! operations. This was originally recognized by the <a href="https://github.com/shashi/ArrayMeta.jl">ArrayMeta.jl</a> project, with the goal of unifying the implementation of an entire Julia Array type into a single generated function. Several Julia projects have used index notation as an interface to linear-algebraic metaprogramming, among them <a href="https://github.com/shashi/ArrayMeta.jl">ArrayMeta.jl</a>, <a href="https://github.com/Jutho/TensorOperations.jl">TensorOperations.jl</a>, and <a href="https://github.com/KristofferC/Tensors.jl">Tensors.jl</a>.
    Since index notation was created for use in scientific domains to describe tensor operations, few descriptions are targeted towards programmers. In this talk, I will give a programmer-centric description of index notation and it’s various flavors, showing how it can be used to describe some example operations. I will summarize how index notation separates mechanism and policy in the ecosystem of tensor implementations and compilers. Finally, I will explain how to transform and specialize index notation from the operation to the array types to the elementwise operations.
  bio: |
    I write algorithms to improve interfaces and automate performance engineering tasks in scientific computing. When I get distracted, I enjoy woodworking, glassblowing, burritos, and climbing. I am a second year computer science graduate student at MIT, and Department of Energy Computational Science Graduate Fellow.
  id: 26

- speaker: "Adrian Salceanu"
  title: "Tame your databases: SearchLight ORM"
  type: "lightning"
  abstract: "Some people swear by them. Other, at them. But every language has one. Python has SQLAlchemy, Java has JOOQ, .NET has Entity, Ruby has ActiveRecord. Now Julia has SearchLight. The SearchLight ORM provides a powerful DSL which makes working with SQL databases more productive, secure and fun."
  desc: |
    SearchLight is an Object Relational Mapping layer for Julia. It exposes a concise but powerful API for database querying and persistence by simply manipulating Julia objects – while also packing a versatile DSL for database migrations, and a robust helper for data validation. It can future-proof your code with its transparent support for multiple backends (SQLite, MySQL, PostgreSQL, ODBC and JDBC) while implementing best practices with automatic user input escaping, support for environments, file generators, database seeding, logging and more.
    SearchLight models are nothing but Plain Julia Objects so they can augment your existing codebase. Or they can be the foundation for building your next data-centric applications: SearchLight promotes a streamlined workflow through convention over configuration and handy generators.
    It can also considerably reduce development time with its large set of built-in types and the wide support for CRUD operations. And if you need more control, you can always get down to the metal and run raw SQL queries or retrieve the underlying DataFrame results, through SearchLight’s lower level API.
    Join me on a quick tour of the main features and learn how to use SearchLight to tame your databases!
  bio: |
    Seasoned web developer on a quest to reinvent web development through Julia. Creator of Genie, the highly productive Julia web framework. Author of “Julia v1 By Example”.
  id: 27

- speaker: "Bogumił Kamiński"
  title: "Performance of Monte Carlo pricing of Asian options using multi-threading"
  type: "lightning"
  abstract: "Multi-threading in Julia is an excellent feature to speed up Monte Carlo simulations, e.g. for Asian option pricing. However, if you are not careful how you generate pseudo random numbers you can get wrong results or have your code run slowly. I discuss how one can avoid both problems."
  desc: |
    During the talk I discuss how to use MersenneTwister pseudorandom number generator in-built into Julia in multi-threading computations.
    It is divided into three parts:
    <ol type="1"> <li>The implementation of MersenneTwisteris not thread-safe. I show an example of bad results of a simulation when a single instance of RNG is shared by more than one thread.
    * You can use randjump function to create several independent RNGs. I explain why and how it can be used in multi-threading code.
    * When using many threads on modern CPUs, you often you can improve the performance of the code by making sure that fields of RNGs do not have adjacent memory locations. I show that randjump by default creates adjacent RNGs and how this can be fixed.  The above issues will be presented using an example of Asian option pricing using Monte Carlo simulation. Here are example timings of the code with and without fixing of randjump output (run on AWS EC2 c4.4xlarge 16 vCPU machine):
    <ol type="1"> <li>single thread: 3.0583 s.
    * 16 threads; default randjump: 0.9068 s.
    * 16 threads; fixed randjump: 0.3399 s.
  bio: |

  id: 28

- speaker: "Ranjan Anantharaman"
  affiliation: "Julia Computing, Inc."
  title: "The New Circuitscape in Julia - modern, fast and scalable"
  type: "talk"
  abstract: "The Circuitscape rewrite in Julia provides a 4-8x benefit in speed and scalability over the old Python package . We show the specific benefits of Julia over Python and how to write an end-to-end application purely in Julia, from native Julia solvers to packaging and shipping."
  desc: |
    Circuitscape is a widely used tool in landscape ecology. It borrows ideas from electronic circuit theory to predict connectivity in heterogeneous landscapes. We have re-implemented Circuitscape (originally a Python package) in Julia, providing a <strong>4-8x benefit</strong> in speed and scalability. This talk will focus on two main thrusts: 1. The specific benefits that Julia provides over Python, and how that manifests in the end-user experience. The Julia package has several additional features as compared to the Python package: the ability to switch solvers seamlessly, single precision support, and the ability to provide parallelism on all three platforms (Mac, Linux and Windows). 2. How we developed a complete end-to-end product in pure Julia, from writing native Julia iterative solvers (AMG.jl) to packaging and shipping, including writing our own Windows installers.
  bio: |
    Ranjan Anantharaman is a data scientist at Julia Computing. His interests span applied mathematics and numerical computing, and he enjoys working with computation across a variety of fields and domains.
  id: 29

- speaker: "Michael Krabbe Borregaard"
  avatar: "http://avatars.schd.ws/3/cf/5709063/avatar.jpg.320x320px.jpg?7b1"
  affiliation: "U of Copenhagen"
  title: "EcoJulia - towards a framework for ecological data analysis in Julia."
  type: "lightning"
  abstract: "Ecological analysis draws upon many different tools - geographic, phylogenetic, bioinformatic and simulation packages and a wide range of statistics. Most ecologists use R, but its package ecosystem is severely fragmented. EcoJulia is a framework to bring cohesive ecological data analysis to Julia."
  desc: |
    Today’s ecologists rely increasingly on complex data analysis, and the ability to creatively define new analyses and design new computational tools has become a key component of ecological research. Ecologists generally rely on the R programming language for this, which has opened up exciting new possibilities, but also has inherent problems. Performance-critical functionality in R generally needs to be implemented in C or Fortran, making library code essentially a black box for scientific users. But more fundamentally there isn’t a strong culture for widespread collaboration on developing software tools in the ecological community, meaning that useful functionality is scattered across a fragmented package landscape.
    Becaus of its combination of clear syntax and quick processing speed, Julia has the potential to solve these issues. Julia makes the development of efficient libraries easy for any researcher, and anyone familiar with the language can easily understand package code. But more importantly, Julia creates an opportunity to start from scratch, and develop a package ecosystem for ecology where different packages use the same types and interfaces.
    We present the beginnings of such an infrastructure for ecological data analysis in Julia, that allows for an integrated and cohesive ecosystem of packages, without sacrificing the freedom of creating new packages with new implementations. We will also demonstrate the SpatialEcology package, which makes it easy to analyse ecological data in a split-apply-combine framework.
  bio: |
    I’m a tenure-track professor at University of Copenhagen. I’ve used Julia since 0.4 and has used it for several published papers. I run EcoJulia together with Tim Poisot (Uni Montreal) with collaboration with Richard Reeve (Uni Glasgow). I’ve also been heavily invested in JuliaPlots in the past. Michael Krabbe Borregaard, MSc, PhD Assistant Professor (TT), Center for Macroecology, Evolution &amp; Climate Natural History Museum of Denmark, University of Copenhagen Universitetsparken 15, DK-2100 Copenhagen Subject Editor, Ecography Associate Editor, Global Ecology and Biogeography Featured recent papers: Island biogeography: Taking the long view of nature’s laboratories, Science (2017) Oceanic island biogeography through the lens of the general dynamic model: assessment and prospect, Biological Reviews (2016). An Anthropocene map of genetic diversity, Science (2016)
  id: 30

- speaker: "Helen Jiang"
  avatar: "http://avatars.schd.ws/2/51/5709077/avatar.jpg.320x320px.jpg?cbc"
  affiliation: "San Francisco Bay Area"
  title: "Hacking with Julia"
  type: "talk"
  abstract: "The talk shows how to implement some of the best-known attacks on real-world cryptography - in Julia! To break crypto is to solve mathematical puzzles, and it is valuable as a technical exercise, as well as an educational experiment for Julia. Few knows how to actually break crypto, want to see how?"
  desc: |
    To break cryptography is to solve mathematical puzzles, so Julia is perfect for the mission of attacking crypto. With this new use case, I would like to share what I discovered about Julia’s advantages and limitations. This includes: what are the kinds of crypto-puzzle-solving that Julia is best suited for? How is Julia used in building up these attacks? How would Julia be used for further cryptanalysis?
    Some well-known but hard-to-get-right attacks I plan to share may include: block cipher cryptography (CBC) bitflipping attack, breaking fixed-nonce CBC in CTR mode, attacking a popular random number generator (RNG), breaking fixed-nonce XOR, and breaking stream cipher from a RNG. Want to see Julia in the wild in real-world hacking? Curious about how Julia functions in this not-so-common use case? This talk may be just right for you.
  bio: |
    Helen does research and development at the intersection of cybersecurity and machine learning, solving problems and building solutions. Because she is not good at writing her own bio, she welcomes you to ask her in person about her stories, learnings, research, experiences, and evolution.
  id: 32

- speaker: "Zenna Tavares"
  title: "Omega: Fast, Causal Inference from Simple Parts"
  type: "talk"
  abstract: ""
  desc: |
    <em>Abstract</em>
     Omega is a library for probabilistic and causal inference. It started with the question &ldquo;How can we say what we want to say in probabilistic languages?&rdquo;. More precisely, we wondered why frameworks for deep learning and probabilistic inference provide little support to add declarative knowledge to our models. For instance, we should be able to simply assert that our classifiers are robust from adversarial attack; that they and are algorithmically fair; that physical objects persist continuously through time, in order to make make object tracking more robust; that human and mouse models are similar, so that measurements from mice help us make better inferences about humans, where data is expensive. Omega is the culmination of a theoretical and engineering effort to address this challenge. In short, an Omega program is a normal Julia function augmented with uncertainty, and inference is execution of that function under constraints. The salient features that distinguish Omega from other approaches are:
    <ol type="i"> <li>Declarative knowledge: Omega allows you to condition on any Julia predicate, providing a mechanism to encode declarative knowledge about a domain.
    *  Causal inference: Omega allows you to imagine counter-factually what would happen under different scenarios.
    * Higher-order: Omega allows you to condition on distributional properties such as expectation, variance, and divergences.&nbsp; This allows us to encode properties such as algorithmic fairness and robustness directly.  In this talk I will outline the principles of Omega through several examples in probabilistic and causal inference. I will also dive into some implementation details, such as how for inference we hijack the random number generator and automatically turn Boolean functions into "soft" Boolean function.
  bio: |

  id: 33

- speaker: "Tom Krauss"
  avatar: "http://avatars.schd.ws/9/4d/5709034/avatar.jpg.320x320px.jpg?7b0"
  affiliation: "Epiq Solutions"
  title: "How to design equiripple filters in Julia?"
  type: "lightning"
  abstract: "Julia has great potential for signal processing, but it’s DSP.jl package is missing a fundamental filter design algorithm: “remez”, also known as the Parks-McClellan algorithm. I’m going to talk about the algorithm, review efforts to implement it in Julia, and compare it with what’s in Scipy."
  desc: |
    The existing Finite Impulse Response (FIR) filter design routines in the DSP.jl package are window based - a suboptimal technique that starts with an optimal L2 approximation to a desired response, and then applies a window to smooth out the ringing around the transition band. “remez” - the common name for the Parks-McClellan algorithm - is a better technique that gives much better control over the filter’s deviations from the desired response in the pass- and stop-bands. It designs FIR filters with optimal Chebyshev approximations to the desired response. In this talk I’ll provide an overview of the algorithm and efforts to include a pure Julia implementation in DSP.jl, and compare it to scipy’s C implementation.
  bio: |
    I’ve been working in signal processing and wireless communications, doing software and system development for over 20 years. I worked 5 years at MathWorks (makers of MATLAB) between my MS and PhD, and 15+ years combined at Motorola and <a href="https://epiqsolutions.com/about.php">Epiq Solutions</a>. I am coinventor on 15 issued US patents and have authored or coauthored over 20 conference and journal papers. I am on <a href="https://www.linkedin.com/in/tomkrauss/">linked in</a> and <a href="https://github.com/sirtom67">github</a>. I gave a <a href="http://sirtom67.github.io/jacobs">talk at my son’s High School AP CS class</a> (click on a slide to zoom in, arrow keys to navigate) about computers and engineering that also includes some of my personal philosophy about learning and life.
  id: 34

- speaker: "Carsten Bauer"
  avatar: "http://avatars.schd.ws/1/8d/5709066/avatar.jpg.320x320px.jpg?6dc"
  affiliation: "University of Cologne"
  title: "Julia for Physics: Quantum Monte Carlo"
  type: "lightning"
  abstract: "I will share my experience on how Julia can improve numerical physics research. This will provide evidence for the claim that Julia can replace Fortran/C++ as workhorses in science. Also I’ll introduce MonteCarlo.jl, a new package for conducting (quantum) Monte Carlo simulations of physical systems."
  desc: |
    Julia has the potential to become <em>the</em> major programming language in numerical physics. In this presentation I will share my personal story about how switching to Julia has improved my physics research as well as outline some issues I have encountered. I will explain how I replaced an opaque C++ quantum Monte Carlo code by a clean and simple Julia implementation. While showing similar performance in large scale simulations of so-called metallic quantum critical points the Julia code has an order of magnitude fewer lines and allows one to perform number crunching and analysis in the same framework. I will argue that Julia’s type system and multiple dispatch paradigm naturally leads to flexible code which can be used in many different projects. As an implementation of this idea, I will conclude by introducing <a href="https://github.com/crstnbr/MonteCarlo.jl">MonteCarlo.jl</a>, a new package for simulating physical systems such as spin models and itinerant fermions by various (quantum) Monte Carlo flavors.
  bio: |
    Carsten is a Ph.D. student in the theoretical physics department of the University of Cologne working on quantum criticality in metals. He studied physics and computer science at the Goethe University Frankfurt, the University of Florida, and the TU Darmstadt.
  id: 35

- speaker: "Andy Ferris"
  avatar: "http://avatars.schd.ws/2/2e/5709037/avatar.jpg.320x320px.jpg?d95"
  affiliation: "Fugro Roames"
  title: "Interacting with nested data"
  type: "talk"
  abstract: "Data comes in all shapes and sizes. While Julia’s built-in arrays are wonderful for dealing with flat or “flattish” data - here I’ll introduce some strategies and tools for dealing with more complex nested data structures, the split-apply-combine paradigm, and working with relational data (tables)."
  desc: |
    In this talk I will identify some commonly occurring data manipulation tasks, and introduce strategies to deal with them concisely and generically. By the end, you will be equipped with the tools to
    * extend Julia’s notion of multiple indexing to container types other than arrays
    * manipulate data by adding new tools beyond Julia’s existing map, filter and reduce functionality to provide generic, higher-order functions for inherently nested data, such as splitting, grouping, combining and joining operations
    * represent <em>relational</em> data with in-built Julia types, and manipulate relations with the tools above  To be specific, we aim to cover the key features of <a href="https://github.com/andyferris/Indexing.jl">Indexing.jl</a>, <a href="https://github.com/JuliaData/SplitApplyCombine.jl">SplitApplyCombine.jl</a> and the somewhat-cheekily-named <a href="https://github.com/andyferris/MinimumViableTables.jl">MinimumViableTables.jl</a>.
  bio: |
    I am an algorithm and software engineer at Fugro Roames, applying machine learning techniques to big data in order to make sense of and to model the physical world. I have been using Julia since v0.3 for both research and commercial production-at-scale, and am the author of several Julia packages including StaticArrays.
  id: 36

- speaker: "Thierry Dhorne"
  affiliation: "University of South Brittany"
  title: "Teaching Data Analysis first steps with Julia"
  type: "lightning"
  abstract: ""
  desc: |

  bio: |

  id: 37

- speaker: "Jacob Quinn"
  affiliation: "Domo"
  title: "Domo + Julia: Learnings from scaling Julia up to process petabytes in production"
  type: "lightning"
  abstract: "At Domo we see a LOT of data. Like, Fortune-500-sized automated pipelines of business-critical data kind of data. And now we’re turning to Julia to get smart about all that data. While deploying pre-1.0 may sound risky, Domo is no stranger to blazing trails in search of the right tool for the job."
  desc: |
    Domo is the operating system for your business. Bring all your data into one place, transform it, and start getting real insights and value out of it. <em>Automatically</em> generating insights on petabytes of Fortune 500 data is no trivial task, so we turned to Julia for a solution that has performance, scale, and most importantly, statistics close to the heart.
    Come learn about our custom Julia stack: how it came together, what we’ve learned scaling it, and how we’re leveraging it to bring automatic insights to Domo users.
  bio: |
    Attended Carnegie Mellon for a master's degree in data science and active Julia contributor for 4 years now.
  id: 38

- speaker: "Ollin Demian Langle Chimal"
  avatar: "http://avatars.schd.ws/7/73/5709073/avatar.jpg.320x320px.jpg?0f4"
  affiliation: "Ministry of Social Development, Mexico"
  title: "Complex Network Analysis of Political Data"
  type: "lightning"
  abstract: "Political data is widely available in the internet but non-informative at all. I use Julia capabilities to extract the information from the Mexican Senate, transform it to a temporal network and get insights from the dynamics of the system."
  desc: |
    Complex Network Analysis of Political Data The Mexican Senate was recently awarded for fulfilling its transparency obligations, meaning that a vast amount of information is on their website. The problem is that the way in which they present it is largely uninformational so a complex network approach is proposed to study the dynamics of the given system.
    We use <em>Cascadia</em> package and Julia’s parallelization capabilities in order to scrap the data that we consider useful for our research and export it to the graph oriented database Neo4j and make an exploratory data analysis for attendancy and voting patterns. Using <em>LightGraphs</em> package we build a temporal weighted network and apply a self developed algorithm for community detection in order to study coalition dynamics. Finally we make use of <em>RCall</em> to build a visualization that represents such dynamics through an alluvial diagram getting interest insight such as party switching and opposite parties coalitions.
    As we want to make this as automatic and portable as possible, everything runs in Docker containers and is orchestrated via Docker Compose and a Luigi Pipeline. That gives us the opportunity to enlarge and analyze new information automatically once a week.
  bio: |
    Musician who studied Physics and Data Science. Currently working at the Ministry of Social Development in Mexico using data science to focalize aid to those with greater needs.
  id: 39

- speaker: "Eric Davies"
  title: "Memento: Logging for Systems and Applications"
  type: "lightning"
  abstract: "Julia’s basic Logging package is sufficient for console logging but lacks the features necessary for monitoring large, multi-component systems and cloud applications. This talk will attempt to convince you to use Memento instead and demonstrate its strengths."
  desc: |
    Memento is a logging library for Julia designed for software systems and cloud applications. It’s the ideal choice in Julia for monitoring large, multi-component applications as it gives users control and flexibility over all aspects of logging for each component.
    Memento’s main features:
    * Set log levels to control verbosity for any part of your project using modular, hierarchical logging
    * Send logs for parts of your project to multiple places in different formats using modular, hierarchical log <em>handling</em>
    * Log to a variety of backends including Syslog
    * Skip log message creation for performance when it wouldn’t be logged
    * v0.6 and v0.7 support
    * v0.7+: substitute Base’s logger for Memento  This talk will demonstrate these features and will showcase Memento in action in a simulated application environment. It will also compare Memento to other approaches to logging in Julia.
  bio: |

  id: 40

- speaker: "John Lapeyre"
  avatar: "http://avatars.schd.ws/d/48/5709084/avatar.jpg.320x320px.jpg?f89"
  title: "Symbolic Mathematics in Julia"
  type: "talk"
  abstract: "Before Julia, it was not possible, starting from scratch, for one person to make significant progress writing a tool that can compete with Wolfram on a reasonable time scale. But, the many advantages of Julia, for instance syntactic macros and access to the syntax tree, put this goal in reach."
  desc: |
    The same unique feature set that makes Julia great for a variety of numerical domains makes it the best choice today for implementing a general-purpose symbolic math language. I’ll begin with a brief zoology of symbolic math languages, and explain why I am interested in those that focus on giving the user great flexibility in rewriting essentially meaningless symbolic expressions. I’ll give an overview of the distinct achievements of the projects in the Julia community that share this focus. Symata.jl is the most highly developed of these projects. I’ll show how Symata.jl provides another example of how the astonishing productivity of the Julia ecosystem allows one to compete with industry heavy-weights, and opens possibilities that are closed to these existing systems.
  bio: |
    John Lapeyre has worked in industry in device physics and data science, and in academia in statistical physics. Before working on symbolic math in Julia, he was a developer for the Maxima computer algebra project.
  id: 41

- speaker: "Todd Green"
  avatar: "http://avatars.schd.ws/6/8c/5709088/avatar.jpg.320x320px.jpg?5b6"
  affiliation: "Relational AI"
  title: "Low-Level Systems Programming in High-Level Julia"
  type: "talk"
  abstract: "In designing a new language for technical computing, we believe the designers of Julia have accidentally created a great language for systems programming. We explain how efficient, low-level data structures like B+-trees can be implemented in high-level Julia code, with help from a recent package."
  desc: |
    Computer system software, like operating systems, database management systems, or video game engines, has traditionally been implemented in low-level programming languages like C or C++. There are good reasons for this: among them, systems programmers must routinely cope with resource constraints dictating low-level control over memory layouts and memory management. Such concerns are some of the very ones that productivity languages like Julia seek to hide from view.
    For example, consider the venerable <a href="https://en.wikipedia.org/wiki/B%2B_tree">B+-tree</a>, which has been used for decades in database systems, file systems, and elsewhere. A B+-tree is a tree-structured index (over, say, file system metadata or SQL tables) aiming to minimize disk I/O for datasets too large to fit in main memory. It achieves this by using large nodes, sized to some multiple of operating system pages, with wide fanout. Because nodes are so wide, the tree is very shallow, and searching from root to leaf incurs just a few disk I/Os. Here’s a picture from Wikipedia (in a real B+-tree, the nodes would contain thousands of entries each and have more intricate internal structure):
    <img src="https://upload.wikimedia.org/wikipedia/commons/3/37/Bplustree.png" alt="B+-tree" />B+-tree In a student project, B+-trees could be implemented in a straightforward way, with e.g. search through a node done by deserializing the page’s contents into appropriate heap-allocated data structures in the host language, and then working with those data structures. In a real implementation, however, this is considered unacceptably slow and resource-intensive; instead the page itself is simply “cast” to a C/C++ data structure, for example, and worked with directly. Systems languages are distinguished by their capability to support this style of programming.
    At the same time, systems programmers are painfully aware of the productivity limitations of languages like C/C++, and recurrent attempts have been made over the years in nearly every systems context to experiment with the use of higher-level languages. Indeed, the most famous and successful example of this is C itself, which replaced assembly language as the “high-level” systems alternative of its time.
    Recently, in database systems, the use of <a href="https://15721.courses.cs.cmu.edu/spring2018/slides/03-compilation.pdf">query compilation</a> (on-the-fly compilation of ad-hoc SQL queries into machine code) has become more or less ubiquitous in high-performance systems. The pain of implementing query compilation in a traditional systems language like C/C++ has motivated researchers to explore the use of higher-level languages like Scala, equipped with staged code generation libraries like <a href="https://scala-lms.github.io/">LMS</a> or <a href="https://github.com/epfldata/squid">Squid</a>, in order to build high-performance systems prototypes.
    In such a context, Julia presents an intriguing alternative, due to its excellent performance and well-developed staged metaprogramming facilities. But if we want to build a full-blown database system in Julia, can we also implement low-level data structures like B+-trees in a way that is both idiomatic to Julia (and therefore productive), but also efficient?
    In this talk, we answer this question in the affirmative, by showing how such data structures can be implemented with help from a recently-developed package called <a href="https://github.com/RelationalAI-oss/Blobs.jl">Blobs</a> package. Blobs (see also <a href="https://github.com/RelationalAI-oss/ManualMemory.jl">ManualMemory</a>) uses Julia metaprogramming techniques to make it easy and efficient to lay out complex data structures within a memory region, such as an OS page. Data structures are defined as ordinary isbits Julia structs, and can have rich nested structure. Rather than give examples here, take a look at the <a href="https://github.com/RelationalAI-oss/Blobs.jl/blob/master/README.md">package overview</a>.
    We’ll give a quick and self-contained overview of the necessary background on paged data structures, and then show how to use Blobs to implement such data structures natively in Julia.
    B+-trees are a bit old-fashioned nowadays, so time allowing, we may also try to cover an example of a more recent paged data structure, the <a href="http://supertech.csail.mit.edu/papers/BenderFaJa15.pdf">Bε-tree</a>. This data structure allows a precisely tunable tradeoff between read- and write-performance, and has been used recently in advanced database systems (<a href="https://www.percona.com/software/mysql-database/percona-tokudb">TokuDB</a>, <a href="http://www.logicblox.com/">LogicBlox</a>) and file systems (<a href="http://www.betrfs.org/">BetrFS</a>).
  bio: |
    T.J. Green is a Computer Scientist at Relational AI. Previously, he was a Computer Scientist at LogicBlox, and an Assistant Professor at UC Davis. He received his B.S. in Computer Science from Yale University in 1997, his M.S. in Computer Science from the University of Washington in 2001, and his Ph.D. in Computer and Information Science from the University of Pennsylvania in 2009. His awards include Best Student Paper at ICDT 2009, the Morris and Dorothy Rubinoff Award in 2010 (awarded to the outstanding computer science dissertation from the University of Pennsylvania), an honorable mention for the 2011 Jim Gray SIGMOD dissertation award, an NSF CAREER award in 2010, and Best Paper Runner-Up at ICDE 2012. Prior to beginning his Ph.D., he worked at Microsoft as a Software Design Engineer and Development Lead, and at Xyleme as a Software Design Engineer.
  id: 42

- speaker: "Przemyslaw Szufel"
  avatar: "http://avatars.schd.ws/2/a6/5709050/avatar.jpg.320x320px.jpg?183"
  affiliation: "Warsaw School of Economics"
  title: "Performance of a distributed Julia simulation on an AWS Spot Fleet vs a Cray supercomputer"
  type: "lightning"
  abstract: "Have you ever wondered what is faster - a supercomputer or a computational cluster in the AWS cloud? Do you want to know what is the easier option to run your massively parallel Julia program? In this presentation you will see how a massively parallel Julia scales with the cluster size increase."
  desc: |
    In this presentation performance of Julia in-built parallelism will be demonstrated on Cray supercomputer (Okeanos - https://www.top500.org/system/178753) vs a cluster of AWS Spot Fleet instances. For illustrative purposes a massively parallelized version of the classical Schelling (1974) segregation social model will be used. Scaling of the parallelized simulation from 400 up to 4096 cores will be discussed and compared. I will also share my experience about those small details that you should know before trying to setup a Julia cluster on AWS and a Cray.
  bio: |
    Przemyslaw Szufel is an Assistant Professor in the Decision Support and Analysis Unit at the Warsaw School of Economics, Poland. His current research focuses on distributed systems and methods for execution of large-scale simulations for numerical experiments and optimization. Dr. Szufel is currently working on asynchronous algorithms for the parallel execution of large-scale computations in the cloud and distributed computational environments.
  id: 43

- speaker: "Matt Bauman"
  avatar: "http://avatars.schd.ws/4/92/5709076/avatar.jpg.320x320px.jpg?b80"
  affiliation: "Julia Computing"
  title: "Advocating for public policy change with Julia"
  type: "lightning"
  abstract: "Harness your superpower for good and advocate for public policy issues that are important to you. I’ll tell the story about how I used a cell phone video and a Julia notebook to become part of a local movement for improved bike safety in the city of Pittsburgh."
  desc: |
    Everyone here has a hidden superpower: you know how to code! Given the right situations, this can serve as a powerful tool to shape public discourse as citizen scientists.
    Following several cyclist fatalities around the University of Pittsburgh, there was a strong advocacy movement for improved traffic safety. I was curious about the raw data underlying the issue, so I put together a Julia notebook that processed a short video of the traffic through campus and calculated each vehicle’s speed. Given more time I could have put together a thorough study, but this was enough: a local bicycling advocacy group picked up the story, leading to a blog post, newspaper story, and several radio interviews. I was just one more voice, but connecting with a non-profit amplified and unified the call for change. Since then the road has been re-designed with an emphasis on bicycle and pedestrian safety.
    This talk will focus on the key takeaways from my interactions with an advocacy nonprofit and local community, and what I believe made it a compelling story. I’ll have some key pointers on how you might be able to find success with your own project.
  bio: |
    Matt Bauman is a Senior Research Scientist at <a href="https://juliacomputing.com">JuliaComputing</a> at their Chicago outpost, where he spends lots of time working on Julia’s arrays. He’s been contributing to both the core language and multiple packages since 2014. At his previous position as a Data Science Fellow at the University of Chicago’s <a href="https://dssg.uchicago.edu">Center for Data Science and Public Policy</a>, he longed for dot-broadcasting in Python. He recently defended his PhD dissertation in Bioengineering from the University of Pittsburgh, focusing on neural prosthetics.
  id: 44

- speaker: "Aditya Puranik"
  avatar: "http://avatars.schd.ws/6/af/5709069/avatar.jpg.320x320px.jpg?bc4"
  affiliation: "The National Institute of Engineering, Mysore"
  title: "Minecraft and Julia : A new way to build stuff and learn how to program"
  type: "lightning"
  abstract: "Minecraft is arguably one of the most popular video games. The sandbox game is successful because it promotes building and creating from imagination. The PiCraft package allows manipulation of the Minecraft world. Programming in Julia we build amazing things like Mobius strips and Aztec Temples."
  desc: |
    The Minecraft API allows us to communicate with the Minecraft world to do simple things like placing blocks and teleporting players. This is functionality is enough to do big and beautiful projects in no time. A talk on building using Julia and some fun stuff like playing “Snake” using a Joystick connected to the Raspberry Pi GPIO pins inside the Minecraft world. This package is a great way to introduce kids to Julia and computer programming in general.
    A lot of functionality is being worked on right now. This includes a dozen building tools accompanied with guides. The work will be completed well before JuliaCon.
    * Show how a skyscraper building 200 blocks tall is built within 5 minutes
    * Show the same for pyramids, spheres, .etc
    * Show some Mathematical objects like Fractals, Klien Bottle generated inside the Minecraft world
    * Show some interactive games like Snake, Minesweeper in 3-D
  bio: |
    I am a Google Summer of Code Student working on the PiCraft.jl package for Julia. Currently a 2nd year student studying Computer Science at “The National Institute of Engineering, Mysore”.
  id: 45

- speaker: "Tim Holy"
  title: "Making the test-debug cycle more efficient"
  type: "lightning"
  abstract: "Julia’s JIT-compilation needs to run on each restart, and the compilation delay can slow development of large projects. I will describe a package, Revise.jl, that allows you to do more testing and debugging in a single Julia session."
  desc: |
    Julia’s interactivity and just-in-time (JIT) compilation are major assets for developers; however, as codebases grow larger, compilation time becomes a burden on the write-test-debug cycle. While the ultimate answer might be faster JIT-compilation, an alternative is to compile less often: specifically, to do more useful development per unit of compilation. This necessitates the ability to fix bugs—and test these fixes—interactively without restarting Julia. Until relatively recently, this was difficult especially for highly-modular projects involving many packages, where the right fix might lie at a deep layer in the package hierarchy. Fortunately, recent work in base Julia laid the groundwork for a more efficient approach in which functions can be arbitrarily redefined and their dependencies recompiled; however, to use this capability one had to re-evaluate these functions manually.
    I will describe a package, Revise.jl, that automates much of the work of the test-debug cycle. Revise scans “active” source files for changes and automatically updates function definitions in a running Julia session. In this talk I will describe the main things Revise can and can’t do, explain some of the strategies that Revise uses to limit the amount of code that needs re-evaluation, and emphasize some of its new capabilities present only in Julia 0.7/1.0.
  bio: |

  id: 46

- speaker: "Dave Kleinschmidt"
  avatar: "http://avatars.schd.ws/0/23/4154590/avatar.jpg.320x320px.jpg?4f0"
  affiliation: "Rutgers University"
  title: "A formula for bringing data across table-matrix divide"
  type: "talk"
  abstract: "Real-world data comes to you in tables full of strings, dates, numbers, etc. To analyze this data you often need to wrangle it into a numerical array. The “formula” DSL is a powerful tool to express these transformations, inspired by R but supercharged with Julia’s unique strengths."
  desc: |
    In order to analyze real-world, tabular data, it needs to be transformed into a suitable numerical format. The @formula domain-specific language in StatsModels.jl provides a way to specify table-to-numerical array transformations. This DSL was inspired by R and should be familiar to Julia users who have experience with R, but Julia has unique strengths and constraints. In this talk, I’ll talk about recent, ongoing, and future developments of a distinctly Julian formula DSL. Some of these make the formula more flexible and useful for users, like using metaprogramming to provide performant support for arbitrary Julia code in a formula, and support for any type of tabular data store (including streaming and out-of-core datasets), using NamedTuples as a common interchange format. But equally important are changes under the hood to make the formula DSL more useful and extensible for package developers. These changes draw on unique language features like multiple dispatch to allow packages to extend the formula syntax at multiple levels, from low-level details of how the underlying formulae expressions are parsed, to high-level specialization of the conversion from formula parts to specialized types of model matrices (as in MixedModels.jl). Together, this makes the formula DSL a solid foundation for building general purpose data analysis and modelling tools that can be applied across a variety of domains and data sources.
  bio: |
    Like many before and after him, Dave started hacking on Julia to procrastinate finishing his dissertation.  Despite his best efforts he finished his PhD in Brain and Cognitive Sciences in 2016.  In his day job as an Assistant Professor of Psychology at Rutgers New Brunswick, he works on understanding how people understand spoken language with such apparent ease, combining behavioral, computational, and neural approaches.  Otherwise he's committed to promoting open, reproducible science, and designing tools that empower researchers and lower the barrier to entry for data analysis and statistics.
  id: 47

- speaker: "Gajendra Deshpande  and Dr. S.A.Kulkarni"
  avatar: "http://avatars.schd.ws/3/6d/5709091/avatar.jpg.320x320px.jpg?6c9"
  affiliation: "KLS Gogte Institute of Technology, Belgaum"
  title: "Brainy Things: Brain Computer Interface meets Internet of Things"
  type: "talk"
  abstract: "Welcome to the exciting world of Brain Computer Interface with Internet of Things. With our project we have made an attempt to provide voice to the voiceless and capability to the incapable (paralyzed) with the help of wonderful programming language known as Julia."
  desc: |
    Brain Computer Interface and Internet of Things are the two sides of a river. On one side, we have Internet of Things which connects electronic gadgets used in our daily life. On the other side we have, Brain Computer Interface which is still in its infancy, but has shown great potential to influence our lives. We made an attempt to build the bridge between Brain Computer Interface and Internet of Things with the help of Julia programming language and achieved satisfactory results. For our experiment we used Raspberry Pi, muse a consumer grade electroencephalography device, sensors, lab streaming layer library written in Python, JuliaBerry package for programming GPIO pins of Raspberry Pi using Julia.
    The process followed for performing the experiment is described below:
    Step 1: Prepare Raspberry Pi 3 by Installing and Configuring necessary, Python and Julia software packages for Raspberry Pi like JuliaBerry, PiGPIO.jl, pylsl.
    Step 2: Connect Raspberry Pi with Muse EEG device via Bluetooth.
    Step 3: Record raw EEG signals from muse brain sensing device using pylsl lab streaming layer library written in Python. The signal processing of raw EEG signals includes filtering, feature extraction, noise reduction and spike classification techniques and implemented in Julia.
    Step 4: Interface Raspberry Pi and devices in home environment.
    Step 5: Based on neural activity of brain i.e., brainwave measurement of concentration, Julia programs perform variety of tasks such as control devices at home, play prerecorded audio file.
    We believe that the above application is useful to people who are suffering from medical conditions such as Paralysis and Laryngeal Surgery by helping them controlling the devices, generating voice input commands and voice output through EEG signals.
  bio: |
    Mr. Gajendra Deshpande holds a masters degree in Computer Science and Engineering and working as Assistant Professor at the Department of Computer Science and Engineering, KLS Gogte Institute of Technology, Belgaum, Karnataka, India. He is pursuing Ph.D. under the guidance of Dr. S.A.Kulkarni at VTU, Belagavi. He has a teaching experience of 10 years and Linux and Network Administration experience of one year. He is winner of Smart India Hackathon 2018. He is Technical Director for Sestoauto Networks Pvt. Ltd. and Founder of Thingsvalley. His areas of Interest include Programming, Web Designing, Artificial Intelligence, Machine Learning, Brain Computer Interface, Internet of Things and Virtual Reality. Dr. S.A.Kulkarni is working as Associate Professor at Vellore Institute of Technology, Vellore, Tamil Nadu, India. He has a Ph.D. in faculty of Computer and Information Science from National Institute of Engineering Research Center under Visvesvaraya Technological University. He loves pursuing certifications and has done many online MOOC and related courses. He is an avid writer and enjoys writing research papers, technology and programming related articles in journals and computer magazines.
  id: 48

- speaker: "Thomas Dickson"
  title: "Probabilistic modelling of long course sailing craft routing"
  type: "lightning"
  abstract: "Sailing craft experience a range of environmental conditions in their voyages across the seas. I show how Julia can be used to model the weather, compare weather scenarios and optimise the route whilst avoiding the structural failure of the craft and to thus reduce cost and crew injury.
    <em>"
  desc: |
    The problem of sailing craft route optimisation involves considering a range of stochastic factors, from weather model used to prediction of performance and structural failure. This research introduces the sailing craft routing problem as a bi-level optimisation problem, with the leader problem being the route optimisation problem and the follower problem being the speed attainable at different reliability levels. The key issue is of how to model these stochastic factors. I use Julia exclusively due to its speed and the ability to rapidly develop code.
    In this talk I will introduce how I generate probabilistic temporal weather models. From these I am able to generate weather scenarios. To reduce computational running time I identify a representative collection of scenarios through comparing based on comparing probability metrics, solved using JuMP. I then show how I use monte carlo simulations to model the reliability of a sailing craft and then optimise the route using a recursive algorithm.
    This talk will demonstrate how I solve many optimisation and statistical problems which are common across engineering and scientific disciplines with respect to modelling and solving stochastic optimisation problems. As a result it has broad appeal across the scientific modelling community with a specific application in an unusual and interesting area.
  bio: |

  id: 49

- speaker: "Luis Benet and David Sanders"
  avatar: "https://graph.facebook.com/v2.3/10158780079130026/picture?width=400&height=400"
  affiliation: "Universidad Nacional Autonoma de Mexico andUniversidad Nacional Autonoma de Mexico"
  title: "Representing functions and solving differential equations rigorously with Taylor models"
  type: "talk"
  abstract: "We approximate a function rigorously with Julia: find a Taylor series that is close, using automatic differentiation, and bound the resulting error using intervals, giving a “Taylor model”. We use this to get <em>guaranteed</em> approximate solutions of ordinary differential equations in the form of tubes."
  desc: |
    We will show how to use Julia to approximate functions in a rigorous way: find a truncated Taylor series that is close to the function, using automatic differentiation techniques provided by the TaylorSeries.jl package. Next, bound the error from truncating the series, using intervals from the IntervalArithmetic.jl package. The resulting object is a <em>Taylor model</em>, as provided by the new TaylorModels.jl package.
    We can now perform rigorous calculations on functions, e.g. multiplying two functions or finding sin(f) for a function f, by manipulating the corresponding Taylor models. This has many applications, for example global optimization: we can find rigorous optima of arbitrary functions by optimizing a polynomial instead, which is easier (although not “easy”).
    We will focus on showing how Taylor models can be used as a building block to solve ordinary differential equations (ODEs): find a Taylor series expansion of the solution to the ODE and bound the error. This gives approximations to the solution, in the form of tubes that are guaranteed to enclose the true solution of the ODE.
  bio: |
    David P. Sanders is associate professor of computational physics in the Department of Physics of the Faculty of Sciences at the National University of Mexico in Mexico City. His previous Julia tutorials on YouTube have a total of more than 80,000 views. He is a principal author of the packages in the <a> suite of packages for interval methods.
  id: 50

- speaker: "Michael Cai"
  title: "Estimating Non-Linear Macroeconomic Models at the New York Fed"
  type: "talk"
  abstract: "Sophisticated tools are required to accurately estimate modern economic models, in the face of unprecedented macroeconomic conditions. The tempered particle filter is a novel method for filtering nonlinear state space models, surpassing conventional tools in accuracy and flexibility. This talk will also mention other applications of sequential Monte Carlo methods as well as current work being done on solving and estimating heterogeneous agent models by the NY Fed DSGE team.
    <em>"
  desc: |
    In this talk, I will highlight StateSpaceRoutines.jl, a repository containing state-space filtering and smoothing methods such as the Kalman filter, Durbin Koopman smoother, and others. Specifically, I will discuss our latest addition to StateSpaceRoutines.jl, the &ldquo;tempered particle filter&rdquo; (TPF) which was developed by Ed Herbst and Frank Schorfheide in a 2016 Journal of Econometrics paper. TPF provides a sequential Monte Carlo approximation of the conditional mean and covariance of the states (the filtered states/covariances) and of the likelihood for general non-linear state space models. Furthermore, as a nonlinear filtering method, TPF produces more accurate approximations than the standard bootstrap particle filter. StateSpaceRoutines.jl and TPF in particular should prove useful to economists, statisticians, and those generally interested in Bayesian methods and/or structural models as a stand-alone suite of tools, which can be used to estimate a variety of both linear and non-linear state space models. I will discuss a few lessons we have learned and will also highlight a few issues we are still currently facing with regards to optimizing the performance of TPF (with a practical aside on &ldquo;optimal&rdquo; MATLAB and Julia implementations and the Julia parallel computing framework, which will prove useful to economists given that MATLAB is still the main language used for computationally intensive modeling). Lastly, I will briefly highlight the NY Fed DSGE team's recent work on implementing various kinds of heterogeneous agent models, both in discrete and continuous time, and discuss the relevance of our implementations of TPF and other sequential Monte Carlo methods to estimating these models in the future.

     Disclaimer: This talk reflects the experience of the author and does not represent an endorsement by the Federal Reserve Bank of New York or the Federal Reserve System of any particular product or service. The views expressed in this talk are those of the authors and do not necessarily reflect the position of the Federal Reserve Bank of New York or the Federal Reserve System. Any errors or omissions are the responsibility of the authors.
  bio: |

  id: 51

- speaker: "Pietro Vertechi"
  title: "JuliaDBMeta and StatPlots: metaprogramming tools for manipulating and visualizing data"
  type: "lightning"
  abstract: "JuliaDBMeta&rsquo;s macros provide a simple syntax to select, filter, map, group and transform JuliaDB data tables for in memory or out-of-core processing. Plots based visualizations can be incorporated in the pipeline. InteractBase provides a graphical interface to define and compose these operations.
    <em>"
  desc: |
    <a href="https://github.com/JuliaComputing/JuliaDB.jl" target="_blank">JuliaDB</a> is a library for tabular data manipulation (either in memory or out of core) that is recently becoming more and more popular. To simplify the JuliaDB user experience , I have designed the metaprogramming based package <a href="https://github.com/piever/JuliaDBMeta.jl" target="_blank">JuliaDBMeta</a> . JuliaDBMeta, starting from a user provided expression with symbols corresponding to fields, detects which columns of the dataset will be used and what anonymous function will be applied to them, then proceeds to iterate data only from the relevant columns and compute the relevant transformation. All operations can be concatenated and can then be piped in a plotting command using <a href="https://github.com/JuliaPlots/StatPlots.jl" target="_blank">StatPlots</a>.
    To maximally simplify the user experience, we try to support both grouped data and out of core data as much as possible out of the box. All column based macros have an optional grouping argument, whereas all row-based macros work out-of-core out of the box. Furthermore special macros are provided to apply a pipeline separately on each processor (or on each group) and then join the results together.For users preferring a more graphical environment, the packages <a href="https://github.com/piever/InteractBase.jl" target="_blank">InteractBase</a> and <a href="https://github.com/piever/TableWidgets.jl" target="_blank">TableWidgets</a> allow to define, select and compose data manipulations and visualizations interactively in a web-based UI with immediate visual feedback.
  bio: |

  id: 52

- speaker: "Weijian Zhang"
  avatar: "http://avatars.schd.ws/9/3e/5709017/avatar.jpg.320x320px.jpg?be8"
  affiliation: "The University of Manchester"
  title: "EvolvingGraphs.jl: Working with Time-dependent Networks in Julia"
  type: "lightning"
  abstract: "Modern networks often store the relationship between entities with time stamps. It is difficult to model and study the evolving nature of such network using traditional graph software package. We present EvolvingGraphs.jl, a Julia software package for analysing time-dependent networks."
  desc: |
    In this talk, we present EvolvingGraphs.jl, a Julia software package for working with time-dependent networks. Many modern real-world networks are time dependent. Consider a group of online users interacting through messaging. Each message sent from user A to user B at time stamp t can be represented as an edge from A to B at time stamp t in an evolving graph. Ignoring the direction of time in a network flow can result in wrong information. However, it is difficult for researchers to model and study the evolving nature of such networks using traditional graph software package. EvolvingGraphs.jl is designed to meet this need. The source code is available at: https://github.com/EtymoIO/EvolvingGraphs.jl. We discuss the structure of EvolvingGraphs.jl and demonstrate a real life use case: tracing the development of ideas in research literature.
  bio: |
    I am a fourth year PhD student in Numerical Analysis at the University of Manchester and I was a visiting student at MIT Julia Lab. I am the creator of EvolvingGraphs.jl (https://github.com/EtymoIO/EvolvingGraphs.jl) and MatrixDepot.jl (https://github.com/JuliaMatrices/MatrixDepot.jl).
  id: 53

- speaker: "Francesco Zappa Nardelli"
  title: "Subtyping Made Friendly"
  type: "talk"
  abstract: ""
  desc: |
    Have you ever wondered how Julia dispatches method calls? As an answer, have you been pointed to a mysterious .c file in the source tree understood by at most five people on Earth? Are you afraid of complex type annotations?&nbsp;&nbsp;If yes, do not wonder anymore. This talk will be a friendly walkthrough across the rules that govern subtyping, the relation at the very core of method dispatch. We will start from the basics and we will build intuitions to grasp the intricate but unavoidable interactions between the various features of Julia type system. As a result you won&rsquo;t be afraid to rely on the most advanced features of Julia type system anymore, and won&rsquo;t be puzzled by runtime error messages or odd dispatch behaviors ever again.
  bio: |

  id: 54

- speaker: "Vaibhav Kumar Dixit"
  title: "An introduction to bayesian parameter estimation of differential equation models using DiffEqBayes.jl."
  type: "lightning"
  abstract: "Parameter estimation is the problem of accurately determining the parameters of a dynamic model. I plan to introduce DiffEqBayes.jl, a package for solving these problems using bayesian techniques."
  desc: |
    Many disciplines of science involve mathematical modeling of phenomena with dynamic systems. The general trend is to model complex dynamical systems through the use of differential equations. These differential equation models often have non-measurable parameters such as planetary masses or chemical reaction rates. The “forward-problem” of simulation consists of solving the differential equations for a given set of parameters. The “inverse problem” or parameter estimation in this case, is the process of using data to determine these model parameters. The inverse problem has been heavily studied in certain fields as has already been presented in the case of Geophysics in the previous JuliaCon with jInv.jl, additionally because of its applications in different fields like systems biology, HIV-AIDS study, and drug dosage estimation it presents a good avenue for further research. This talk will introduce the attendees to the parameter estimation problems and show how to use DiffEqBayes.jl to perform Bayesian parameter estimation via techniques like Markov Chain Monte Carlo, Stochastic Approximation Expectation Maximization algorithm and Maximum A Posteriori estimation. Through this talk attendees will learn the purpose of parameter estimation and leave with knowledge of tooling for estimating parameters of differential equation models created using Julia’s differential equations suite.
  bio: |

  id: 55

- speaker: "Giulio Martella"
  avatar: "http://pbs.twimg.com/profile_images/954485309877649408/9eoX7434.jpg"
  title: "LARLIB.jl: Solid Modeling in Julia"
  type: "lightning"
  abstract: "Big data mass in fields like Bioengineering needs fast computations and simplified operations on complex geometric models. LARLIB.jl is a library for efficient solid modeling operations that works on non-manifold cases with a compact representation that permits fast computations and operations."
  desc: |
    Increased geometric data complexity, operations on n-dimensional manifold and non-manifold geometries are the modern challenges of many field like CAD, Biomedical Imaging and Physical Simulations. Therefore there is the need of a representation scheme capable to handle these challenges with ease. For this task we propose LAR (Linear Algebraic Representation) which offers many interesting features such as efficient support for topological queries and construction, data representation via matrices and the opportunity for easy parallel processing. LARLIB.jl is the official Open Source implementation of LAR which enables the user to use the features of LAR with operations like: incidences and adjacencies between topological entities, boundary and co-boundaries of Cellular Complexes, Boolean Operations such as union of several complexes. This was possible thanks to the Julia ecosystem that provides and easy environment for scientific computation such as parallel capabilities, definition and operations on CSC Sparse Matrices builtin types, and third-party scientific libraries (IntervalTrees.jl and NearestNeighbors.jl). We will demonstrate the library efficiency through the union of big random cellular complexes and a real Bioinformatics use case with the creation of a compact model from MRI images.
  bio: |
    I have a B.Sc. in Computer Engineering at the University of Roma Tre which is the host of the Computational Visual Design Lab (CVDLAB). I worked there as a research fellow for more than a year. During this period I developed LARLIB.jl with Francesco Furiani and Prof. Alberto Paoluzzi.
  id: 56

- speaker: "Anna Kiefer"
  avatar: "http://avatars.schd.ws/5/a3/3695628/avatar.jpg.320x320px.jpg?2c4"
  affiliation: "Kevala Analytics"
  title: "Whale Recognition using a CNN in Julia"
  type: "lightning"
  abstract: "For decades, conservationists have captured photographs of whales and their flukes (tails) in the open water. Can these images be used to accurately identify whale species? In this talk, see one implementation of an image recognition tool using Julia that may aid global whale conservation efforts.
    <em>"
  desc: |
    I will discuss one image recognition algorithm I have created using Julia to train and classify images of whale flukes. This talk will demonstrate a convolutional neural network used to train and test whale images contributed by photographers around the world. It aims to demonstrate Julia&rsquo;s capabilities for use in machine learning, image recognition, and conservation efforts.
  bio: |

  id: 57

- speaker: "Simon Byrne"
  avatar: "http://avatars.schd.ws/b/54/5709072/avatar.jpg.320x320px.jpg?12a"
  affiliation: "Julia Computing"
  title: "0.1 vs 1//10: How numbers are compared"
  type: "lightning"
  abstract: "Have you ever wondered why 0.1 &gt; 1//10, 1*pi &lt; pi or 10^16+1 &gt; 1e16+1? I will explain how equalities and inequalities in Julia work across different numeric types."
  desc: |
    Julia provides many different numeric types, including signed and unsigned integers, floating point numbers, rationals, arbitrary precision numbers, and irrational constants. The type hierarchy and multiple dispatch allow all these different types to be used together. For most operations, this is handled via promotion to common type, however comparisons such as equalities and inequalities are handled in a more complicated manner, in order to obtain the mathematically correct result.
  bio: |
    Simon started using Julia in 2012. He promptly found a bug. Since then, he’s made some pull requests, created some packages, and spent a lot of time waiting for tests to finish running (arguably not as much as he should).
  id: 59

- speaker: "Mayeul d'Avezac"
  title: "Julia is an R&D binding agent"
  type: "lightning"
  abstract: "Research and development pulls together disparate tools and creates seamless product. Julia is an integrated R&D platform: it can command an instrument, e.g. an android phone, call existing C libraries, perform complex scripting and analysis. But best of all, it can unit-test the whole ordeal."
  desc: |
    Much of research comes down to giving commands to instruments, and pulling results, and then performing some sort of analysis. Each of these tasks is generally done via an interface or language of its own: Bash or similar to give commands to instruments and manipulate files, some scripting language for analysis, and a sprinkling of libraries to read input data and perform more complex analysis. Eventually the manifestation of this type of work is a set of scripts with vaguely defined input and outputs. These are passed on semi-religiously from one PhD student to the next, until modifying them becomes almost an act of sacrilege, thus limiting what new science can be attempted (until a student throws it all out of the window, restarting the process from scratch).
    Julia has the potential to remediate to this situation. It offers a platform where it is easy to combine systematic testing with every aspects of an R&D workflow, from command-line calls, to wrapping C libraries, to beautiful plots. I illustrate this workflow using my experience in a startup developing a quantum random number generator on an android phone. Julia allowed me to test and analyse the random number generator by simply issuing commands to the android bride as an external program, pull results from the phone as files via the same android bridge, open these files by wrapping an external C library, and then analyse and plot the results, all in the comfort of an IJulia notebook. Other than the fact that Julia solved these problems within a single language, it also allowed me to easily integrate testing directly into the notebook, thus ensuring that the workflow remains tested, and legible, even as it grows. Julia decidely lowers the barrier to reproducible, auditable research.
  bio: |

  id: 60

- speaker: "Chris Rackauckas"
  avatar: "http://avatars.schd.ws/2/EB/4113616/avatar.jpg.320x320px.jpg"
  affiliation: "University of California, Irvine"
  title: "PKPDSimulator.jl: Drug dosage prediction in Julia"
  type: "talk"
  abstract: "Drug development costs $1.2billion over 12 years. Clinical trial simulations, using PKPD models, de-risk this investment. Simulations help narrow-down target patient, dosing schedule and trial size choices. PKPDSimulator.jl is a Julia package for trial simulation."
  desc: |
    Informed decision-making across various phases of drug development is challenging as it has to utilize an enormous amount of information produced during the development process. Models of drug, disease and trials are particularly useful in summarizing essential information in a succinct and efficient manner, allowing the integration of knowledge from different studies and external sources. Simulations combined with appropriate assumptions, such models can explore the potential outcomes of yet-to-be-conducted studies, enabling optimization of the study design to increase the probability of success and de-risk investment.
    Pharmacokinetic and Pharmacodynamic (PK/PD) models are one such class of models used by pharmaceutical professionals to guide drug development and clinical therapeutic decisions. These models allow forecasting drug concentrations in the body and the response to the drug at various dose levels. Further, these models require flexible and high performance solving of differential equations to simulate patient data. However, the development of open-source software tools for this discipline lag due to the requisite performance and domain-expertise. In this talk we will introduce PKPDSimulator.jl, a Julia package for simulation of PK/PD models. This package includes the addition of functions for implementing compartmental PK/PD models and schedules of dosing and other discrete events. We will demonstrate how models of clinical trials are developed to simulate clinical measurements and responses to drug administration. Unique features which make new ground in the field, such as the ability to incorporate stochastic differential equations, delay differential equations, and discrete stochastic models will be emphasized.
  bio: |
    Chris Rackauckas is a 4th year Ph.D. Candidate in Mathematics at the University of California, Irvine. He is the principal author of many Julia packages, including the JuliaDiffEq packages (DifferentialEquations.jl) and ParallelDataTransfer.jl, and has contributed to numerous other packages related to scientific computing. Chris is also actively engaged in the Julia community as the author of the StochasticLifestyle blog and the tutorial “A Deep Introduction to Julia for Data Science and Scientific Computing".
  id: 61

- speaker: "Dr. Daniel Bachrathy"
  title: "Multi-Dimensional Bisection Method for finding the roots of non-linear implicit equation systems"
  type: "lightning"
  abstract: "In the proposed talk an efficient root finding algorithm is presented, which can determine whole high-dimensional submanifolds (points, curves, surfaces…) of the roots of implicit non-linear equation systems, even in cases, where the number of unknowns surpasses the number of equations."
  desc: |
    Multi-Dimensional Bisection Method for finding the roots of non-linear implicit equation systems Introduction The bisection method - or the so-called interval halving method - is one of the simplest root-finding algorithms which is used to find zeros of continuous non-linear functions. This method is very robust and it always tends to the solution if the signs of the function values are different at the borders of the chosen initial interval.
    Geometrically, root-finding algorithms of f(x)=0f(x)=0 find one intersection point of the graph of the function and the axis of the independent variable. In many applications, this 1-dimensional intersection problem must be extended to higher dimensions, e.g.: intersections of surfaces in a 3D space (volume), which can be described as a system on non-linear equations. In higher dimensions, the existence of multiple solutions becomes very important, since the intersections of two surfaces can create multiple intersection lines.
    Multiple solutions The original form of the bisection method can easily be extended to find numerous roots of a non-linear equation in a given interval. If the function values are computed in an initial mesh on the examined interval, then the original method can be used for each neighboring points where the sign of the function values are different. This way, some roots may be omitted if the initial mesh is not fine enough, and even number of roots are placed inside one interval.
    Generalization for higher dimensions In many applications, the roots of a system of non-linear implicit equations
  bio: |

  id: 62

- speaker: "Tim Holy"
  title: "Opening remarks"
  type: ""
  abstract: ""
  desc: |

  bio: |

  id: 63

- speaker: "Kristoffer Carlsson"
  avatar: "http://avatars.schd.ws/D/2E/4113646/avatar.jpg.320x320px.jpg"
  affiliation: "Chalmers University of Technology"
  title: "Pkg3 — The new Julia package manager"
  type: "talk"
  abstract: "Julia 1.0 comes with a brand new package manager, currently called Pkg3. Pkg3 was redesigned from scratch to solve a number of fundamental problems with the old package manager. This talk discusses the decisions we made to ensure that Pkg3 allows the Julia package ecosystem to grow and succeed."
  desc: |
    Julia 1.0 comes with a brand new package manager under the working name Pkg3. It has been rewritten from scratch based on the experiences of the previous package managers—both Julia’s an those in other languages. This talk discusses some of the design and implementation choices made and the reason behind them. Some of the topics included in the talk are:
    <strong>Federated package ecosystem.</strong> This means that multiple independent parties can maintain both public and private packages and registries of them, and that projects can depend on a mix of public and private packages from different registries. Packages from various registries are installed and managed using a common set of tools and workflows. One consequence of federation is that there cannot be a central authority for package naming: different entities may use the same name to refer to unrelated packages. Instead, packages are identified by universally unique identifiers (UUIDs) assigned to them prior to registration. UUIDs are mostly invisible to the casual user of Julia—they are used in project and manifest files maintained by the package manager but regular Julia code continues to use packages by name as it always has.
    <strong>Environments.</strong> Julia’s code loading and package manager natively support having multiple independent sets of packages at different versions. This alleviates “DLL hell” for Julia packages since unrelated projects don’t need to fight about what version of their dependencies to use—they can each use whatever version of a dependency they prefer. Manifest files record the exact version of each dependency in a complete dependency graph for a given application and can be reconstituted with a single command on the same system or a different one—a huge boon for reproducibility.
    <strong>Immutability and content addressing.</strong> One of the basic design principles of Pkg3 is that an installed version of a package is immutable and identified by its content. In other words, once a version of a package is installed, it is never changed and anyone who wants that version asks for by a hash of its source tree. When a version is no longer needed anywhere, it is automatically deleted. Identifying package versions by content rather than git commit also means that packages are free to rewrite their development history—for example to discard large objects—and allows packages to be installed without any need for git history at all, so long as the source tree is correct.
  bio: |
    Ph.D. student in computational mechanics at Chalmers University of Technology. Using Julia both for studies and as a hobby.
  id: 64

- speaker: "Jeffrey Sarnoff"
  title: "Math with more good bits, times+dates with nanoseconds"
  type: "lightning"
  abstract: "Julia&rsquo;s built-in numeric and datetime types are very good. Sometimes we need better. We introduce SaferIntegers, ArbNumerics and TimesDates for nanosecond resolution."
  desc: |
    This talk introduces three packages: SaferIntegers, ArbNumerics and TimesDates. SaferIntegers are safer because they do not allow numerical overflow to occur silently. ArbNumerics provides best-in-class performance with 35..350 digits, and accurately encloses its values.&nbsp; TimesDates provides nanosecond timestamps over timezones.
  bio: |

  id: 65

- speaker: "Kelly Shen"
  avatar: "http://avatars.schd.ws/c/2b/5709071/avatar.jpg.320x320px.jpg?34e"
  affiliation: "Etsy"
  title: "How Etsy Handles “Peeking” in A/B Testing"
  type: "lightning"
  abstract: "Etsy relies heavily on experimentation to improve our decision-making process. In this talk, I will present how Etsy handles data peeking and how we use Julia to help us investigate and assess the problem on our platform."
  desc: |
    At Etsy, we leverage our internal A/B testing tool when we launch new campaigns, polish the look and feel of our site, or even make changes to our search and recommendation algorithms. As our experimentation platform scales and the velocity of experimentation increases rapidly across the company, we also face a number of challenges. In this talk, I will talk about how we utilize Julia to investigate and evaluate one of the problems, “peeking” at results early in order to detect maximum significance with minimum sample size.
    We used Julia to assess the overall problem and how it affected experiments at Etsy. We also used Julia to evaluate a few solutions that have been proposed and applied in industry and academia, keeping in mind the unique challenges we face as a fast-paced e-commerce company. After going through the analysis and evaluation, I will discuss the approach we at Etsy took to tackle the peeking problem.
  bio: |
    Kelly Shen is a data engineer at Etsy, where she works on improving the e-commerce company’s in-house A/B testing platform. Previously, she was an undergraduate student at MIT studying computer science and mathematics and used Julia extensively in both her classes and research.
  id: 66

- speaker: "Nishanth H. Kottary"
  avatar: "https://media.licdn.com/mpr/mprx/0_1KOz6z8Vl0rq9s0l8zi1QdTMlShU_4YO3Vi19wjVrTgj_qPt8niKF8hM8trvrs0A8MiKNtTpPcyZTdgl1R7sAa3VXcy4TdClLR7ckzjslDDATY14Lxx9mf5KaG"
  affiliation: "Julia Computing, Inc."
  title: "JuliaBox: scalable apps, GPUs and courses"
  type: "lightning"
  abstract: "Over the past year Julia Computing has released a new version of JuliaBox. It was designed to be not just a hosted notebook service but also to let users deploy, scale and share their julia code. This talk describes how we achieve this and other new features."
  desc: |
    JuliaBox is an online service for running julia from the browser. With over 70,000 users since 2015, JuliaBox is used by scientists, engineers and universities worldwide. We present the new JuliaBox that was released over the past year. New features have been added to support courses for universities. We now provide GPU enabled notebooks with drivers, libraries and packages fully setup. Users can now deploy their julia code on JuliaBox as interactive web applications. We have also introduced UI for scaling CPU and memory for the notebook or any custom app.
  bio: |
    Software Developer at Julia Computing Inc.
  id: 67

- speaker: "Jesse Bettencourt"
  avatar: "http://avatars.schd.ws/c/b8/5709053/avatar.jpg.320x320px.jpg?0bf"
  affiliation: "U of Toronto"
  title: "Self-tuning Gradient Estimators through Higher-order Automatic Differentiation in Julia"
  type: "lightning"
  abstract: "Recent work in machine learning and deep reinforcement learning uses self-tuning optimization methods which utilize higher-order gradients. Higher-order automatic gradients are challenging to implement correctly, even in Tensorflow and PyTorch. I show how to do this using Flux.jl."
  desc: |
    Gradient-based optimization is the main trick of deep learning and deep reinforcement learning. However, it’s hard to estimate gradients in the most interesting settings - when the mechanism being optimized is unknown (as in reinforcement learning) or involves discrete operations (such as in optimizing programs).
    I’ll give a quick overview of the tricks of the trade:
    * The REINFORCE estimator, which can be summarized as “if it works, do it more”.
    * The reparameterization trick, which factors out randomness to expose the deterministic relationship between inputs and outputs.
    * Control variates, which reduce variance by introducing a predictable baseline.
     I’ll also talk about a recent family of self-tuning gradient estimators that combines all of these, LAX <a href="https://arxiv.org/abs/1711.00123">1</a>. This involves not just automatic differentiation, but also differentiating through automatic differentiation itself. I’ll talk about the subtleties of doing this correctly, and how to approach these problems in Julia.
  bio: |
    Jesse Bettencourt is a graduate student in the Machine Learning group at the University of Toronto and the Vector Institute. He is supervised by David Duvenaud and Roger Grosse and teaches the undergraduate/graduate course on probabilistic models and machine learning. He is very excited to use Julia in his ML research and possibly in future course offerings.
  id: 68

- speaker: "James Fairbanks"
  avatar: "http://avatars.schd.ws/e/3b/5709035/avatar.jpg.320x320px.jpg?992"
  affiliation: "GTRI"
  title: "Graph interfaces: bespoke graphs for every occasion"
  type: "talk"
  abstract: "LightGraphs defines abstractions to implement for any graph or network. Instead of re-inventing the wheel, we can share existing algorithms and functions within the ecosystem. We will live-code a new graph type. Attendees will learn to extend JuliaGraphs with a custom graph type for any application."
  desc: |
    LightGraphs offers both (a) a set of simple, concrete graph implementations – Graph (for undirected graphs) and DiGraph (for directed graphs), and (b) an API for the development of more sophisticated graph implementations under the AbstractGraph type. The data structures and algorithms are now decoupled in order to allow users to extend the basic graph implementations with novel data structures which include support for weights, properties, and more efficient storage.
    We have integrated with EvolvingGraphs.jl, MetaGraphs.jl, and SimpleWeightedGraphs.jl. These packages allow you to use graphs with various forms of metadata attached to the nodes or edges. From traditional weighted graphs, to dynamic graphs with changing edge sets, to MetaGraphs.jl which allows you to ingest a DataFrame as a property graph. MetaGraphs provides the foundation for an in memory GraphDB.
    Demo! We will live-code a simple graph type defined by its adjacency matrix and leverage LightGraphs for different applications. This talk will show how anyone can extend JuliaGraphs with a custom graph implementation for their application.
  bio: |
    Mathieu Besançon is a PhD student in a double program between Ecole Polytechnique of Montréal, at the GERAD lab and the INOCS team at INRIA Lille, in mathematical optimization and game theory for smart grids. James Fairbanks earned a Ph.D in Computational Science and Engineering at Georgia Tech. My research focuses on numerical, statistical, and streaming algorithms for data analysis. The applications include complex networks, online media, medical data, and sensor data.
  id: 69

- speaker: "Stefan Lenz"
  title: "BoltzmannMachines.jl: a Julia-native package for training and evaluating multimodal deep Boltzmann machines"
  type: "talk"
  abstract: "We present the package “BoltzmannMachines.jl”: Different types of restricted Boltzmann machines serve as flexible building blocks for our Julia-native implementation of multimodal deep Boltzmann machines, a generative model for unsupervised deep learning on composite or partitioned data sets."
  desc: |
    Deep learning algorithms have proved to be very successful on image data: Facial recognition and autonomous cars are already out there. The analysis of biomedical data, however, is an exciting new field that still waits for such breakthroughs because it poses different challenges. Genomic sequencing data, e. g., usually encompasses a large number of variables, so-called single nucleotide polymorphisms (SNPs). But since DNA sequencing is still expensive, the available sample sizes are very low compared to the number of measured variables for each sample. This new area is what we want to target with our package “BoltzmannMachines.jl”. With the ability to partition layers of deep Boltzmann machines, the number of model parameters that are to be estimated can be reduced significantly. This makes deep learning possible in a setting with a high number of dimensions but low sample size. We showed that partitioning on basis of correlation structure can enable deep Boltzmann machines to learn meaningful SNP patterns (Hess M., Lenz S., Blätte T. J., Bullinger L., Binder H. <em>Partitioned learning of deep Boltzmann machines for SNP data</em>. Bioinformatics 2017 btx408. doi: https://doi.org/10.1093/bioinformatics/btx408). Besides partitioned modeling, multimodal deep Boltzmann machines are in particular capable of modeling different types of input data, e.g., datasets also containing continuously valued variables. In our implementation, this is possible by using different types of restricted Boltzmann machines and plugging them in at the level of the visible layer.
    When training on heterogeneous types of data, the choice of the hyperparameters is especially challenging. Therefore, our package puts a strong focus on evaluation and monitoring during model training. As primary evaluation criterion, the likelihood can be estimated using annealed importance sampling. Additionally to that, the package offers convenience methods to monitor a number of other statistics. Also, the monitoring is designed to be easily customizable, which allows the user to examine the learning process and gain more insights into the nature of deep Boltzmann machines.
  bio: |

  id: 72

- speaker: "Jarrett Revels"
  affiliation: "MIT"
  title: "Cassette: Dynamic, Context-Specific Compiler Pass Injection For Julia"
  type: "talk"
  abstract: "Cassette is a tool for injecting user-defined code transformation passes into Julia’s JIT compilation cycle, enabling normal Julia packages to analyze, optimize, and modify Cassette-unaware Julia programs via both low-level IR transformation and high-level dispatch using Cassette’s context types."
  desc: |
    Cassette is a tool for injecting user-defined code transformation passes into Julia’s JIT compilation cycle, enabling normal Julia packages to analyze, optimize, and modify Cassette-unaware Julia programs via both low-level IR transformation and high-level dispatch using Cassette’s context types. This latter feature, dubbed “contextual dispatch”, allows users to safely and quickly overload existing Julia methods with context-specific behaviors, like graph construction or derivative computation, without ever needing to handle Julia’s IR directly.
    Importantly, Cassette requires no manual source annotation or refactoring of target code. Cassette even works in the presence of structural and/or dispatch type constraints. This renders traditionally “invasive” techniques, like automatic differentiation, applicable to previously inapplicable Julia programs.
    Downstream applications for Cassette include lightweight multistage programming, dynamic code analysis (e.g. profiling, rr-style debugging, etc.), compilation to new hardware/software backends, automatic differentiation, interval constraint programming, automatic parallelization/rescheduling, automatic memoization, and more.
    In this talk, I’ll discuss Cassette’s design, implementation, and show how it can be used to implement automatic differentiation for native Julia code.
  bio: |
    I like to make Julia code differentiate itself.
  id: 73

- speaker: "Lyndon White"
  title: "DataDeps.jl and other foundational tools for data driven research"
  type: "talk"
  abstract: "The focus of this talk is DataDeps.jl – BinDeps for Data – Repeatable Data Setup for Replicable Data Science. How to manage data dependencies to ensure any script can be executed by others. The secondary topic is what comes next: data ingestion, with a focus on NLP, though that generalizes."
  desc: |
    This talk will cover the fundamental process of getting from a dataset on a web-server, into data in your program. Almost all empirical research work is data driven. This is particularly true of any field that is using machine learning. As such, setting up your data environment in a repeatable and clean way is essential for producing replicable research. Similarly, many packages have some requirement on data included to function, for example WordNet.jl requires the WordNet database. Deploying a package based on using an already trained machine learning model requires downloading that model.
    This talk will primarily focus on DataDeps.jl which allows for the automatic installation and management of data dependencies. For researchers and package developers DataDeps.jl solves 3 important issues:

    * <strong>Storage location:</strong> Where do I put it?
    * Should it be on the local disk (small) or the network file-store (slow)?
    * If I move it, I’m going to have to reconfigure things.
    * <strong>Redistribution:</strong> I didn’t create this this data
    * Am I allowed to redistribute it?
    * How will I give credit, and ensure the users know who the original creator was?
    * <strong>Replication:</strong> How can I be sure that someone running my code has the same data?
    * What if they download the wrong data, or extract it incorrectly?
    * What if it gets corrupted or modified?   On top of this: by allowing fully automate Data Dependency setup, end to end automated testing becomes possible.

    To achieve this DataDeps.jl needs each data dependency to be declared. This declaration requires information such as the name of the dataset, it’s URLs, a checksum, and who to give credit to for its original creation etc. I found myself copy-pasting that data from the websites. <a href="https://github.com/oxinabox/DataDepsGenerators.jl">DataDepsGenerators.jl</a> is a package that can generate this code given a link to a supported webpage describing. This makes it really easy to just grab someone else’s published data, and depend upon it. Then DataDeps.jl will resolve that dependency to get the data onto your machine.
    Once you’ve got the data onto your machine, the final stage is to load it up into a structure Julia can work with. For tabular data, julia has you well covered with a number of packages like JuliaDB, DataFrames.jl and many other supporting packages. MLDatasets.jl, uses DataDeps.jl as a backend, provides specialised methods for accessing various commonly used machine learning datasets. CorpusLoaders.jl provides a similar service for natural language corpora. Corpora often have factors that differ from other types of data.

    * They often require tokenisation to become usable, for which we use WordTokenizers.jl.
    * Tokenization increases the memory used: to decreases this we use InternedStrings.jl; and load them lazily via iterators.
    * To handle the hierarchical structure (Document, Paragraph, Sentence, Word) of these iterators we introduce MultiResolutionIterators.jl.  Julia is excellent for data driven science, and this talk will help you understand how you can handle your data in a more robust way.

    Packages discussed Packages discussed in great detail:

    * <a href="https://github.com/oxinabox/DataDeps.jl/">DataDeps.jl</a>: This manages Data Dependencies.
    * <a href="https://github.com/JuliaText/CorpusLoaders.jl">CorpusLoaders.jl</a>: It is a data package building on roughly every other package mentioned here.  Packages discussed in significant detail:
    * <a href="https://github.com/oxinabox/DataDepsGenerators.jl">DataDepsGenerators.jl</a>: This converts URLs pointing webpages containing metadata, into code for DataDeps.jl
    * <a href="https://github.com/oxinabox/MultiResolutionIterators.jl">MultiResolutionIterators.jl</a> it is the core of having a good API for CorpusLoaders.
    * <a href="https://github.com/oxinabox/InternedStrings.jl">InternedStrings.jl</a> For decreasing memory usage, and speeding up equality checks.
    * <a href="https://github.com/JuliaText/WordTokenizers.jl">WordTokenizers.jl</a> it is a natural language tokenization and string splitting package.  Packages mentioned:
    * <a href="https://github.com/JuliaML/MLDatasets.jl">MLDatasets.jl</a>: a package full of datasets, similar overall to CorpusLoaders.jl but with some significant differences in philosophy and default assumptions.
    * <a href="https://github.com/JuliaML/MLDataUtils.jl">MLDataUtils.jl</a>: for most non-domain specific data wrangling before you feed your data to a machine learning system
    * <a href="https://github.com/JuliaText/WordNet.jl">WordNet.jl</a>: the julia interface to the WordNet lexical resource.
    * <a href="https://github.com/JuliaData/DataFrames.jl">DataFrames.jl</a> for working with tabular data.
    * <a href="http://juliadb.org/">JuliaDB</a> for working with n-dimensional tabular data.
    * <a href="https://github.com/oxinabox/MD5.jl">MD5.jl</a> and <a href="https://github.com/staticfloat/SHA.jl">SHA.jl</a>: for checksums for DataDeps.jl

  bio: |

  id: 74

- speaker: "Torkel Loman"
  avatar: "http://avatars.schd.ws/a/8f/5709074/avatar.jpg.320x320px.jpg?29c"
  affiliation: "U of Cambridge"
  title: "Efficient Modelling of Biochemical Reaction Networks"
  type: "lightning"
  abstract: "Our new reaction reader tool is an attempt to automate the boring parts of biochemical modelling (transcribing equations). The user can now spend more time actually analysing those models! Also makes your code prettier."
  desc: |
    Many biological models consider biochemical reaction networks. However, as these grow in size they also produce large amount of equations which needs to be transcribed into computer code. This is a monotonous task of little fun and which is prone to generating bugs (and finding these bugs is even less entertaining). Fortunately we have been able to automate it. By using Julia’s capability of meta programming we have created a DSL (domain-specific language) allowing its user to input their reaction network as chemical equations (as opposed to mathematical ones). This format both look aesthetically pleasing and efficiently handles features such as coupled noise. The DSL generates an IR (intermediate representation) which have been constructed with Julia’s high-performance DifferentialEquations.jl library in mind. It can be used to create ODE, SDE and JumpProblems, all of which can be solved using DifferentialEquations’ solvers. Taken in total this can significantly cut the amount of code required, as well as making what remains much prettier.
  bio: |
    Torkel is a mathematician and first year Ph.D. student at the University of Cambridge. With the use of mathematical models he investigates how B. Subtilis responds to various forms of stress by producing alternative sigma factors.
  id: 75

- speaker: "Scott Jones"
  avatar: "http://avatars.schd.ws/4/2B/4154505/avatar.jpg.320x320px.jpg"
  affiliation: "Gandalf Software, Inc."
  title: "Enhanced String handling in Julia"
  type: "lightning"
  abstract: "String performance is important in many areas, such as parsing text formats such as JSON, CSV, or bioinformatics data, for NLP (natural language processing), and for interfacing with other languages/libraries that use other encodings than UTF-8. This talk will discuss the JuliaString “ecosystem”."
  desc: |
    JuliaString is a new organization, formed with the goal of creating an ecosystem of standards compliant, fast, and easy to use string handling packages. Many people using Julia are scientists, and don’t really wish to deal with the complexities with things like indexing into variable-length string encodings, why their data loaded from a CSV file or from a database sometimes seem to be corrupted. There are also people interesting in writing Julia code for NLP (natural language processing), where the speed can be critical. Many fields such as bioinformatics have their own text file formats, and the new Strs package provides easier to use functions for writing fast string handling code. The talk will cover the added functionality of the Strs package, the importance of having validated strings for avoiding a number of known security exploits, the relative performance of the new strings, and its use for interfacing with other languages, databases, and libraries that frequently use other Unicode encodings, such as UTF-16. It will also cover the string literal format, with support for LaTeX, Unicode, HTML entities and Emojis, as well as easy to use formatted output that builds upon string interpolation, using the Julia type system, or alternatively using a C-like or Python-like format code syntax (but without having to count positions, or use a macro. Other topics such as thread-safe regex support, handling non-Unicode string encodings, optimized dictionaries for string keys, will be discussed, time permitting.
  bio: |
    Consulting for Dynactionize.com, working fulltime in Julia
  id: 76

- speaker: "Martijn Visser"
  title: "Building a strong foundation for geospatial innovation"
  type: "lightning"
  abstract: "This talk will showcase what is possible with the JuliaGeo related packages, with the aim to get you started if you want to do geospatial analysis in Julia. Making full use of the strengths of Julia, examples are shown of that would be either too slow or too much work in other languages."
  desc: |
    This talk will showcase what is possible with the JuliaGeo related packages, with the aim to get you started if you want to do geospatial analysis in Julia. The foundation here lies in solid, easy to install wrappers to established <a href="https://www.osgeo.org/">OSGeo</a> (Open Source Geospatial Foundation) projects such GDAL (Geospatial Data Abstraction Library), GEOS (Geometry Engine Open Source) and PROJ (coordinate transformation software library). On top of this, inspired by the Python ecosystem, we implemented a GeoInterface, to make sure the different geometry representations can talk to each other. From this basis some examples are given of customized processing that could not be done as efficiently in Python.
  bio: |

  id: 77

- speaker: "Niklas Korsbo"
  avatar: "http://avatars.schd.ws/6/f1/5709075/avatar.jpg.320x320px.jpg?983"
  affiliation: "Cambridge University"
  title: "Latexify.jl and how Julia's metaprogramming makes it useful."
  type: "lightning"
  abstract: "Latexify.jl allows you to create and render LaTeX code from not only simple types, but also arrays and even systems of equations. In this talk, I will introduce what Latexify.jl can do, how Julia’s metaprogramming makes it possible and how the underlying philosophy can be leveraged for other things."
  desc: |
    In this talk, I will both introduce <a href="https://github.com/korsbo/Latexify.jl">Latexify.jl</a> and explain how Julia enabled the creation of this package in a way that few other languages could.
    Latexify.jl allows you to convert Julia objects, and even equations, to LaTeX and Markdown. While Latexify.jl is useful for typesetting a matrix to a latex array, its practical value extends far beyond that. In this talk, I will: - describe how Julia’s metaprogramming facilities allows for not only create clever ways of inputting information to our programs, but also for extracting that information; - demonstrate how Latexify.jl uses this to latexify and render things ranging from strings to systems of differential equations and symbolically calculated Jacobians; - showcase how this has become an addictive and ubiquitous part of my work as an applied mathematician;
    and finally, I will reflect upon how the Julia features that allowed the making of Latexify.jl could be leveraged for other things.
  bio: |
    I am the author of <a target="_blank" rel="nofollow me noopener noreferrer" href="https://github.com/korsbo/Latexify.jl">Latexify.jl</a>, a member of the JuliaDiffEq organisation and a PhD student of applied mathematics at Cambridge University. I started tinkering with Julia a few years ago and I have for the last year and a half done almost all my work with Julia. I dabble in computational biology, non-linear dynamics, programming and occasionally beer brewing.
  id: 78

- speaker: "James Fairbanks"
  avatar: "http://avatars.schd.ws/e/3b/5709035/avatar.jpg.320x320px.jpg?992"
  affiliation: "GTRI"
  title: "The JuliaGraphs ecosystem: build fast -- don’t break things"
  type: "lightning"
  abstract: "The JuliaGraphs ecosystem has expanded this year, with new innovations in abstract representations and modularity. We discuss these improvements, highlighting the effects of changes in Julia 0.6 and 0.7 which affected the design of the JuliaGraphs ecosystem."
  desc: |
    Many areas of technical computing use graphs or networks and LightGraphs provides a common base of data structures and algorithm to manipulate and analyze these graphs. The JuliaGraphs ecosystem is evolving integrations with many other Domain ecosystems such as Optimization, Biology, Image Processing, and Statistics and 127 distinct packages.
    The JuliaGraphs ecosystem has expanded this year, with new innovations in abstract representations and modularity. We discuss these improvements, highlighting the effects of changes in Julia 0.6 and 0.7 such as Type System / Type Parameters, Traits, Module dependencies, Threading and Atomics which affected the design of the JuliaGraphs ecosystem.
    We will present developments in the JuliaGraphs community and celebrate the 1.0 release.
  bio: |
    Mathieu Besançon is a PhD student in a double program between Ecole Polytechnique of Montréal, at the GERAD lab and the INOCS team at INRIA Lille, in mathematical optimization and game theory for smart grids. James Fairbanks earned a Ph.D in Computational Science and Engineering at Georgia Tech. My research focuses on numerical, statistical, and streaming algorithms for data analysis. The applications include complex networks, online media, medical data, and sensor data.
  id: 79

- speaker: "Uri Patish"
  title: "From Deep Neural Networks To Fully Adaptive Programs"
  type: "lightning"
  abstract: "Deep neural networks can be highly useful. Nonetheless, some problems require structured programming elements such as variables, conditional execution, and loop clauses. We present a Julia framework that supports gradient based learning even when such programming elements are included in a model."
  desc: |
    Deep neural networks have been tremendously successful in approaching a variety of learning problems. Nonetheless, the basic building blocks that make up such models are mostly designed to facilitate gradient based parameter learning, rather than to enable productive programming, or to provide a fully fledged programming language. Standard programming languages on the other hand provide programming elements such as variables, conditional execution clauses, and definitions of subroutines that facilitate succinct descriptions of programs, but lack the flexibility that gradient based learning allows. We set on combining the best of both worlds in a new Julia framework that on the one hand supports structured programming elements, and on the other, supports gradient based parameter learning. The main challenge in combining the two is to provide an efficient algorithm for calculating the gradient when variables, and loops are involved. In such cases, the complexity of calculating the gradient using standard backpropagation grows exponentially with the number of iterations and the number of variables. To circumvent this problem, we present a new auto-differentiation mechanism that can handle such cases in linear time, and a new framework that supports it. We supplement our framework with operations that are typical of neural networks, paving the way to new kinds of adaptive programs. In particular, we show that convolutional neural networks that incorporate variables and loops can solve image classification problems with significantly less parameters, and more importantly, solve image classification tasks that standard neural networks fail to solve.
  bio: |

  id: 80

- speaker: "Abhijith Chandraprabhu"
  avatar: "http://avatars.schd.ws/2/de/5709070/avatar.jpg.320x320px.jpg?abf"
  affiliation: "Julia Computing"
  title: "500K - Providing training to 500K individuals across India in AI"
  type: "lightning"
  abstract: "Julia Computing and EkStep have launched an initiative to train 500k individuals in the field of AI. Come hear how we’re designing the courses and delivery."
  desc: |
    Julia Computing in partnership with Ek Step foundation (https://ekstep.org/) has started an initiative in India to train 500,000 individuals in machine learning to accelerate their upskilling and improve the AI and ML communities. The current state of talent in the field of AI and ML in India falls short of the requirements. We have designed the course content and delivery mode such that, the learning is great fun. It has been very well received by the first hundreds of students and professionals we have trained so far. This is one of the largest AI/ML outreach and training programs, and it has Julia at the center.
  bio: |
    I am currently working as a data scientist at Julia Computing, Bangalore. I have masters in Applied Mathematics from Linkoping University, Sweden. I have been using Julia since 2013, I love training in the field of machine learning, and Julia has been my choice as a programming since 2013.
  id: 81

- speaker: "Patrick Belliveau"
  title: "Large Scale Airborne Electromagnetic Geophysics in Julia"
  type: "lightning"
  abstract: "My research group uses Julia to solve large-scale industrial inverse problems in geophysics. These are rich computational problems involving differential equations and optimization. I’ll explain how we’ve used Julia to make fast, modular and scalable production geophysical inversion code."
  desc: |
    This talk will discuss how we’ve used Julia at scale, both on private clusters and the cloud, to solve industrial problems in Airborne electromagnetic (AEM) geophysical surveying. AEM surveying is a geophysical technique that uses electromagnetic induction to map the structure of the earth’s subsurface. Think of a giant metal detector attached to a helicopter flying low over the earth’s surface. The technique is used in mineral, oil and gas, and groundwater exploration as well as in environmental monitoring. Transforming the raw data collected by these surveys into 3D models of subsurface physical properties that can be used by geologists and other domain scientists is a computationally challenging problem—known as geophysical inversion. It is normally posed as a problem in partial differential equation (PDE) constrained optimization. Solving such problems requires repeatedly solving partial differential equations numerically as part of an iterative optimization process.
    Our research group at the University of British Columbia has developed a modular framework for solving PDE-constrained optimization problems, particularly those arising in applied geophysics. This framework, called [jInv] (https://github.com/JuliaInv/jInv.jl) was presented at JuliaCon 2017—find the video <a href="https://www.youtube.com/watch?v=Ss3w7XcFiGc">here</a>. Inversion of large-scale AEM survey data is a key application of the jInv framework. Cutting edge approaches to the problem involve dividing the PDE based survey simulation component of the problem into many quasi-independent subproblems. Julia is a great environment to exploit the parallelism inherent in this approach. We use a combination of Julia’s built in distributed memory parallelism, nested with shared memory parallel linear algebra libraries to take advantage of modern cluster architecture. In this talk we will describe how we’ve structured our code to use Julia’s distributed memory parallelism and will also emphasize how developing in Julia has allowed us to add new features to our inversion codes quickly while retaining the ability to deploy them on large-scale real world problems in mineral exploration.
    The work described here was conducted at the University of British Columbia and at <a href="http://www.compgeoinc.com/">Computational Geosciences Inc</a>.
  bio: |

  id: 82

- speaker: "Carlos Alberto da Costa Filho"
  avatar: "https://media.licdn.com/dms/image/C4E00AQHH4ofP4wFMpw/profile-originalphoto-shrink_450_600/0?e=1531245600&v=beta&t=4o6GCbdFvnZkKch5LGBY8weXvS93YkUQej2d1zAdcSU"
  affiliation: "University of Edinburgh"
  title: "Julia and Geophysics: Rocking with C calls and Metaprogramming"
  type: "lightning"
  abstract: "Can a shiny new language like Julia easily be added to a mature codebase? Yes it can! Come hear about my experience writing Julia code for Madagascar, an open-source software suite for geophysics. Be prepared for repeated abuse of ccall, metaprogramming and pipelines, but little geophysics (phew!)."
  desc: |
    Whenever a new programming language appears, first there is excitement: “It can do X and Y so well! Amazing!” Soon, however, reality sets in and you start having to rewrite vast swathes of your workflow in this shiny new language. Well, Julia is shiny, and it can certainly do many things very well, but can it also be easily incorporated into a mature codebase? My experience with Julia and <a href="http://www.ahay.org/wiki/Main_Page">Madagascar</a>—an open-source software package for geophysics—suggests that it can. In this talk I will explain how Julia’s C interface and metaprogramming support combine naturally with Madagascar’s main pillars: its C API and its user-contributed programs. I will show that <a href="https://github.com/ahay/src/tree/master/api/julia">my relatively small Julia API</a> (now sitting in upstream Madagascar), can provide functionality that is either lacking in other APIs (e.g. MATLAB), or requires complex external tools (e.g. Python+SWIG). Using these examples, I will make the case that Julia is not only a welcome addition to scientific computing communities, but that it can also be incorporated into established workflows with minimal effort. Indeed, I will show that one of Julia’s key advantages is its flexibility in being integrated into mature projects.
  bio: |
    Carlos is an applied scientist currently working as a postdoctoral researcher at the University of Edinburgh. He is interested in imaging and inversion, particularly large scale problems in Earth sciences. From Brazil, Carlos obtained a B.Sc. in Mathematics from PUC-Rio and an M.Sc. in Applied Mathematics from the University of Campinas, before moving to (equally sunny!) Scotland where he obtained his Ph.D. in Geophysics from the University of Edinburgh.
  id: 83

- speaker: "Vaska Dimitrova"
  title: "Optimization of a pumped-storage hydro power plant in Julia with SDDP Algorithm"
  type: "lightning"
  abstract: "Optimal dispatch of pumped storage is an important mechanism when optimizing a portfolio of energy assets with regard to its exposure to the electricity market. We present a solution to this problem in Julia and compare its advantages to some existing application that we use in our everyday work."
  desc: |
   Electric utilities in Europe are faced with squezeed margins in the marketing of its production units due to increased pressure on the electricity price levels assigned to renewable energy effects. As electricity markets gain dynamics and move closer to real-time redispatch and planning of the production facilites, partly also due to technical requirments of the transmission grid which maintains the energy balance in the system at all times, efficient and performant asset optimization and management software solutions become increasingly important. Well studied algorithms like the linear or mixed integer programming reach their limits in the ability to find the optimal dispatch in short time while taking volatility of the input parameters in consideration, such as water inflow or intraday prices. We are trying to tackle the challenges of the fast changing electricity market by developing models in different systems which satisfy our requirements for optimality and performance. We were happy to find out that an open-source programming language Julia with good performance reputation offers a great support for optimization solutions and algorithms, even more the trending ones like dynamic programming or stochastic dynamic programming. We were happy to find out that we dont have to ‚reinvent the wheel‘ and implement the algorithm ourselves but rather focus on the analysis part and analyse the results. We have built an optimized dispatch application of our pumped-storage hydro power plant in Julia and would like to share our experiences in working with SDDP Packages in Julia, while benchmarking it with the existing applications that we use in our everyday work.
  bio: |

  id: 84

- speaker: "Jameson Nash"
  affiliation: "Julia Computing, Inc."
  title: "Information overload: tools for making program analysis and debugging manageable"
  type: "talk"
  abstract: "We have many tools to provide some answers when analyzing Julia programs – code_warntype, @profile, VS Code workspace – but many more questions. Let’s explore a new experience for understanding Julia code!"
  desc: |
    Julia is a great language for code analysis tools. The combination of dynamic and static features gives a very rich environment for both producing and exploring the program full stack.
    Current tooling can provide essential insights into the workings of a program. These including everything from simple annotation and highlighting functions such as code_warntype, to performance testing tools like @profile and BenchmarkTools’s @benchmark, to tests and documentation, to Revise.jl workflows. This talk will open by exploring the strengths, limitations, and purposes of several of these.
    However, these tools share one significant common aspect: they are not especially interactive. Indeed, as a goal, these try to be absolutely stateless.
    What tools do we need to complement these and expand our workflow? One traditional stateful tool is the lowly – but essential – debugger. But in Julia, can we do even better? What if we could explore the compilation space just as easily as exploring the execution space? In what ways can we combine the insights from a debugger with the insights from the compiler to further our real understanding of the program (and, inevitably, its flaws)? How would we aggregate that information and present it in a way that can be exported and shared?
    In this talk I’ll introduce my new tool for interactive program analysis, aka debugging. Julia has a unique combination of dynamic features and a standard library designed to be strongly amenable to static analysis. These aspects make possible the integration of a range of the development aids mentioned earlier to benefit developers and users alike. Let’s see what a bright new future for analyzing Julia code might look like!
  bio: |
    I've been a Julia contributor since before it was cool. Now, I'm working for Julia Computing, as the static compilation champion, compiler correctness fiend, and performance cliff jumper.
  id: 85

- speaker: "Alex Mellnik"
  title: "Showcasing Julia on the Web"
  type: "lightning"
  abstract: "You just created an awesome new Julia package – congratulations! How can you show it off to potential users (many of whom may not have used Julia yet)? Create an online, interactive demo!"
  desc: |
    One way to attract new users to specific Julia packages (and the language in general) is to showcase our work to a wide audience of non-Julia users. There are many ways to do this including Julia blog posts, conference presentations and sandbox environments like JuliaBox, but this talk will focus on creating web-based demonstrations that allow anyone with a browser to interact with Julia code. I will discuss three sample projects:
    * DiffEqOnline, a tool that allows the user to solve Ordinary/Stochastic Differential Equations in the browser using the DifferentialEquations.jl ecosystem.
    * FluxJS Demos, which highlights how easy it is to construct models in Flux.js while showing off the results exported to the web via FluxJS.jl.
    * Julia-to-JS, which allows the user to write Julia code which is then converted into either asm.js (via ExportWebassembly.jl and CodeGen.jl) or WebAssembly (via Charlotte.jl) and then loaded into the browser, allowing the user to run it.  I will also discuss how package developers and other Julia users can create and deploy interactive demonstrations for their own code.
  bio: |

  id: 86

- speaker: "Gael Forget"
  avatar: "http://avatars.schd.ws/7/22/5709058/avatar.jpg.320x320px.jpg?43d"
  affiliation: "MIT"
  title: "Bringing ocean, climate, and ecosystem modeling to Julia"
  type: "lightning"
  abstract: "Earth systems are simulated using numerical models of increasing resolution that play a key role in predicting climate. This talk presents a Julia framework that will help educators and researchers leverage these models via an intuitive and scalable representation of gridded Earth variables."
  desc: |
    Earth systems are simulated using numerical models of increasing resolution that play a key role in helping us understand and predict climate. The <a href="https://mitgcm.readthedocs.io/en/latest/">MIT general circulation model</a> and <a href="http://darwinproject.mit.edu/">MIT Darwin Project</a> developers strive to provide open-source and user-friendly solutions to a wide user community of researchers and educators. In this talk, I will present an initial effort to interface these powerful and versatile tools with Julia. Emphasis, for now, is on porting the <a href="http://gcmfaces.readthedocs.io/en/latest/">gcmfaces toolbox</a> to Julia. This Matlab / Octave toolbox allows users to analyze <a href="https://doi.org/10.5194/gmd-8-3071-2015">ocean model output</a> using code that is readily applicable to all supported grid types. Porting it to Julia notably aims to (1) improve scalability to increasingly large data sets, (2) alleviate costs associated with proprietary software, (3) increase integration with cloud services, and (4) facilitate access for educators and researchers via jupyter notebooks. Examples will be taken from a recent simulation of marine ecosystems by the <a href="http://darwinproject.mit.edu/">MIT Darwin Project</a>. In the longer term, this effort aims to allow users to leverage <a href="https://mitgcm.readthedocs.io/en/latest/">MITgcm</a> capabilities (parallel solvers, automatic differentiation, virtual particle tracking, etc.) via Julia.
  bio: |
    I work as a research scientist at the Massachusetts Institute of Technology (MIT) where I investigate oceanography and climate. As part of the Department of Earth, Atmospheric and Planetary Sciences, my work focuses on ocean modeling and the analysis of global ocean data sets such as Argo profile collections and satellite altimetry. Amongst other approaches, I carry out ocean state estimation using the MIT general circulation model to interpolate and interpret ocean observations. I also participate in the development of the MITgcm and its adjoint. My scientific interests include: Ocean circulation and Climate variability; tracer transport and turbulent transformation processes; interaction of bio-geochemistry and physical processes; global cycles of heat, water, and carbon; observational statistics; forward and inverse modeling.
  id: 87

- speaker: "Helge Eichhorn"
  avatar: "http://avatars.schd.ws/4/a7/5709078/avatar.jpg.320x320px.jpg?f42"
  affiliation: "PTScientists"
  title: "Julia for Space Science: An Antidote for Complexity"
  type: "talk"
  abstract: "Julia might be a secret weapon for the next chapter of the New Space revolution. This talk will present the roadmap for the JuliaAstro and JuliaSpace organizations and demonstrate how Julia can be used to combat the current complexity crisis and enable the next generation of space explorers."
  desc: |
    Space science and industry have seen massive changes in recent years. New Space companies are bringing down the cost of space exploration and are achieving impressive technological milestones. Feats that have eluded established organizations for years. This new generation of space hardware is driven by the use of open and affordable technologies such as Cubesats and a willingness to re-examine old assumptions and for radical simplification.
    With the hardware revolution well under way the next big frontier in space systems engineering is software. The existing ground control systems and scientific mission data analysis tools have accumulated decades of technical debt and accidental complexity and thus cannot hold step with the rapid changes in the space segment. A fresh approach is needed to lower the barrier of entry for the next generation of space explorers and further bring down the cost of access to space.
    This presentation examines how Julia’s unique properties make it ideal for tackling the challenges in space science and exploration and will present the roadmaps for the JuliaAstro and JuliaSpace organizations.
  bio: |
    I am a mission analysis and flight dynamics engineer at <a target="_blank" rel="nofollow me noopener noreferrer" href="http://ptscientists.com/">PTScientists</a>, space nerd, Julia enthusiast since the beginning, and like to photograph remote moutains.
  id: 88

- speaker: "Carl Åkerlindh"
  avatar: "http://avatars.schd.ws/c/24/5709030/avatar.jpg.320x320px.jpg?e75"
  affiliation: "Lund U"
  title: "Fast derivative pricing in Julia"
  type: "lightning"
  abstract: "Are you interested in high performance code that is also easy to use? This talk will showcase how to price exotic financial derivatives, without having to compromise between speed and code readability."
  desc: |
    Stochastic differential equations is an important class of models with a wide range of applications, commonly used in finance. Pricing of exotic financial derivatives is often a very computationally intensive process, emphasizing the need to simulate models as time-efficient as possible. The general experience though, is that fast often means less flexible. With this in mind I developed SDEModels.jl, a package dedicated to simulation of stochastic differential equations. Using features available in Julia, such as metaprogramming and a very fast RNG, I was able to achieve both lightning-fast simulation with barely any overhead, and managed to make it very simple to define and switch models.
    Together with additional package OptionPrice.jl, which implements fast and accurate state-of-the-art pricing algorithms, the goal is to give you a great toolbox for pricing derivatives in Julia both easy and fast for a wide variety of models and contracts.
  bio: |
    Carl is doing his PhD studies in mathematical statistics at Lund University, Sweden. The focus of his research is inference methods for stochastic models used in mathematical finance, with a strong aspect of compuational methods and computational efficency. He has a strong interest of writing highly performant code, squeezing out every possible flop.
  id: 89

- speaker: "Diego Marinho de Oliveira"
  avatar: "http://avatars.schd.ws/b/fd/5709015/avatar.jpg.320x320px.jpg?500"
  affiliation: "Melbourne, Australia"
  title: "Towards Real-Time Job Recommendation AI Solution with Julia"
  type: "talk"
  abstract: "RecSys is based on predicting the best item set for a user. I used Julia in a real-time solution with Genie, DataFrames and XGBoost integrated with a Search Engine. As result, it helped my DS team to deliver impacting results processing +100,000 features for a large set of jobs in incredible 250ms!"
  desc: |
    This presentation has the aim of presenting a Content-Based (combination of Retrieval Phase; + Learning2Rank algorithm) solution made in Julia to improve the quality of Job Recommendations on the SEEK Asia homepage. As a topic to make accessible to any audience, I will present all components in high level and focus in how Julia helped to make it possible to process all features and natural language models necessary to generate high-quality recommendations using Genie API. The solution was deployed in AWS for production using Docker and Ansible. Key Points of Julia in the Presentation: • Speed-up the process in more than x10 • Make easy the natural language preprocessing • Give total control how to manipulate arrays and matrix for efficiency • Turns flexible the feature engineering calculation without adding much complexity by the language • It is capable to be used as API in a real system environment that need to scale to thousands of users • Last version v0.6.x is a remarkable achievement and stable to make the code go to production • Present performance improvements showing Sparse Matrix, @views, @. and special use of @inbounds, @simd, and @fastmath. • Quick highlights on the packages Genie, DataFrames, and XGBoost
  bio: |
    I`m a Lead Data Scientist specialized in Recommender Systems, Machine Learning, and Natural Language Processing.
  id: 90

- speaker: "Bogumił Kamiński"
  title: "BOF: Julia in the classroom"
  type: "Birds of a Feather (BOF)"
  abstract: ""
  desc: |
    This breakout session is intended for people who teach or plan to teach Julia language to share their experiences and best practices. Authors of books about Julia are also welcome to join the discussion how their materials can be best used to support teaching.

    When you start teaching Julia there are several natural questions that you typically have to answer, like:

    * what are essential parts of Julia language and ecosystem (type system, multiple dispatch, libraries, tooling) that students need to learn to get started with using it;
    * what teaching materials to use; what are exemplary problems for teaching;
    * what is an effective sequence of topics to cover; what concepts are difficult to understand and how to explain them;
    * how to best explain to the students why it is worth to learn Julia.This break out session invites all people who teach or plan to teach Julia to discuss about those and similar topics. Willing participants are invited to prepare a short talk or example that is worth sharing. If you would want to propose to present some longer topic please contact the session organizer (Bogumił Kamiński)[http://bogumilkaminski.pl/about/] to make sure that it can be properly planned.

    An ultimate objective of this breakout session is to prepare a material summarizing the conclusions from the discussion that would be openly shared to the community after the conference.
  bio: |

  id: 91

- speaker: "Ján Dolinský"
  title: "TIM: Unified Large-scale Forecasting System for Load, Gas, Solar and Wind in Julia"
  type: "talk"
  abstract: "TIM (Tangent Information Modeller) is a unified large-scale forecasting system written first in C++ and then in Julia. The key advantages in doing so will be shared covering both the computational and architectural aspects ranging from the engine kernel all the way up to its REST API with examples."
  desc: |
    <strong>Motivation & TIM</strong>
    Liberalization of energy market in Europe in recent years have made balancing the electricity grid a challenging task. Nowadays, there are diverse consumption patterns and highly variable re-newable power sources like solar, wind, small-scale hydro, etc. at play. Energy companies need to forecast both consumption patterns of their clients and production capacities of their power sources in large numbers.
    TIM (Tangent Information Modeller) is a unified large-scale forecasting system written first in C++ and then in Julia. The engine builds time-series models automatically with no human intervention fulfilling the industry need for forecasting at scale. TIM ranked no. 1 in recent GEFCom 2017 competition (https://juliacomputing.com/press/2017/11/21/tangent-works-uses-julia-to-win-ieee-competition.html).
    <strong>TIM in Julia</strong> This high performance engine relies heavily on Julia’s computational paradigms like loop fusion, map, mapreduce, SIMD support, direct calls to BLAS etc..
    TIM is AOT compiled and deployed in the cloud as a RabbitMQ worker. It is then used via an REST API in production by different energy platforms. In the talk, we would like to go through qualities of Julia which made this transition from C++ to Julia in production perfectly possible and share lessons learned. We also talk about entire architecture of the solution starting from the computational kernel all the way up to its REST API.
    Live demonstration showing how to set up your own forecasting system using TIM in Julia may also be included.
  bio: |

  id: 92

- speaker: "Jiahao Chen"
  title: "Parallel Prefix Polymorphism"
  type: "talk"
  abstract: "Julia’s multiple dispatch and generic functions lets you reuse code, not just for computing results, but also to visualize how the algorithm works and even prove formal correctness of an implementation. I’ll show this for parallel prefix, a fundamental algorithm of parallel computing."
  desc: |
    Parallel prefix (aka scan) is one of the basic algorithms underlying parallel computing, regrouping associative operations as necessary to provide scalability. In this talk, I will demonstrate how to implement parallel prefix as a higher order function in Julia, offering generic scan operations using any user specified function, on any indexable type. Simply by changing the type of the input indexable allows the exact same code to run in parallel as well as in serial. The serialized equivalent program can be introspected in new ways - by passing in a customized array type that logs accesses in getindex and setindex! operations, the algorithm can be made to generate its own visualization. Finally, by passing in formal types that do not contain data, but rather store only the relevant program invariants, we can use multiple dispatch to prove or disprove the correctness of any claimed implementation of parallel prefix.
  bio: |

  id: 93

- speaker: "Jacob Quinn"
  affiliation: "Domo"
  title: "HTTP.jl: Progressing library for all your Julia web needs"
  type: "lightning"
  abstract: "Client and server web interactions are at the heart of most modern applications, Julia and otherwise. Web APIs open doors for cross-language and service interoperability and HTTP.jl aims to provide a robust, modern foundation for Julia programs needing request or server capabilities."
  desc: |
    The HTTP protocol is a foundational building block of modern computing. Powering complex microservice architectures to individual Jupyter notebooks, programmers from all domains are constantly faced with tasks of interoperating with web REST APIs, scraping web pages, or spinning up servers to provide data and computation to others.
    This lightning talk will focus on: * Brief overview of HTTP.jl’s history and inspiration from other language http libraries (python requests and go net/http) * Request functionality, including automatic cookie handling, builtin AWS authentication, custom timeout handling, and more! * A powerful new middleware Handler framework for flexibly layering server functionality
    Come get up to speed on the latest and greatest web functionality in Julia and leave with a sharpened toolset that every coder needs in today’s computing world.
  bio: |
    Attended Carnegie Mellon for a master's degree in data science and active Julia contributor for 4 years now.
  id: 94

- speaker: "Simon Broda"
  avatar: "http://avatars.schd.ws/6/c7/5709046/avatar.jpg.320x320px.jpg?f6a"
  affiliation: "U of Amsterdam"
  title: "ARCH Models in Julia"
  type: "lightning"
  abstract: "Volatility modeling lies at the heart of much of financial risk management. The workhorse model in this field is the GARCH model, along with its various extensions. The talk describes a package that the author is developing to bring these models to Julia."
  desc: |
    The volatility of a financial asset is an important ingredient in asset allocation, derivative pricing, and Value at Risk calculations, among others. Consequently, there is a large literature on volatility modeling. The most successful class of models is that of (generalized) autoregressive conditional heteroskedasticity, or (G)ARCH models, pioneered by econometrician Robert Engle in his seminal 1982 paper, and for which he received the Nobel Memorial Prize in Economics in 2003. The author is developing a package which implements these models in Julia, which as a language is particularly well suited for this task.
  bio: |
    I am an assistant professor of econometrics at the University of Amsterdam, but currently on leave to the University of Zurich under an MSCA indiviual fellowship.
  id: 95

- speaker: "Jane Herriman"
  affiliation: "Caltech/Lawrence Livermore National Lab"
  title: "BOF: diversity and inclusion"
  type: "Birds of a Feather (BOF)"
  abstract: ""
  desc: |
    We'll have a birds of a feather session (concurrent with part of the poster session) to discuss and brainstorm diversity and inclusion in the Julia community. All are welcome!
  bio: |
    Jane is a graduate student in computational materials physics enrolled at Caltech. She is interning at Lawrence Livermore National Lab, where she is working with Xavier Andrade on methods for and applications of density functional theory.
  id: 96

- speaker: "Yuri Vishnevsky"
  avatar: "http://avatars.schd.ws/7/63/5709048/avatar.jpg.320x320px.jpg?afd"
  title: "Julia for Interactive Data Visualization: Adding Dynamic Behavior to Static Documents"
  type: "lightning"
  abstract: "In this talk I introduce a new approach to authoring highly polished interactive data visualizations on the web with Julia. Such visualizations historically been difficult to create without writing custom Javascript.
    <em>"
  desc: |
   It is now possible to create create beautiful, engaging, and interactive data visualizations that can easily reach a wide audience from the comfort of your Julia REPL. This short talk introduces a new way to create dynamic visualizations on the web for a large class of applications. The ideas are simple &mdash; the basic approach is to enumerate visual states ahead of time and compile them from Julia into a JSON representation &mdash; but can be usefully applied to a very wide range of use cases, many of which I&rsquo;ll showcase during the talk.
  bio: |
    I am an independent consultant in high-impact data visualization, design, and software development, and am an active member of the Julia community.
  id: 97

- speaker: "Claire Harris"
  affiliation: "University of Glasgow"
  title: "Simulating global plant biodiversity"
  type: "talk"
  abstract: "Global biodiversity loss is reaching critical levels. Working with 200M plant records, an evolutionary tree of 30k of plant species and global climate reconstructions to understand this process is a huge computational challenge, and one that requires many of Julia’s “ecosystems” working together."
  desc: |
    Biodiversity loss has reached critical levels in the past decade, just as computational techniques and available data sources have put us in a position to begin to quantify this reduction. The <a href="https://www.gbif.org">Global Biodiversity Information Facility</a> (GBIF) holds hundreds of millions of records of plant species and where they are found. The <a href="https://www.ecmwf.int">European Centre for Medium-range Weather Forecasting</a> (ECMWF) has reconstructed the climate of the whole earth since 1900, allowing us to understand the environment in which each plant was discovered. Other researchers, who have constructed a supertree of over thirty thousand of these plant species, give us the opportunity to investigate the evolutionary history of climate preferences among related species. Drawing these datasets together is a huge computational challenge, one exacerbated by our interest in simulating the potential changes these species will undergo in the face of sustained climate change.
    The Julia language has provided us with the opportunity to work with these huge datasets (<a href="https://github.com/JuliaComputing/JuliaDB.jl">JuliaDB.jl</a>, <a href="https://github.com/visr/GDAL.jl">GDAL.jl</a>), and make spatial simulations based upon endangered plant species on a global scale, which would be intractable in languages commonly used in the life sciences, like R, Python etc. We have been building this platform for almost two years now, along with several other components that come with it (especially <a href="https://github.com/richardreeve/Diversity.jl">Diversity.jl</a>, a package for the measurement and partitioning of biodiversity).
    We will talk about the results we have generated in understanding the evolutionary relationships between species across the whole kingdom of flowering plants, how our simulations work to predict responses of plants species to climate change, and how well we are likely to be able to detect these changes using existing biodiversity metrics.
    We have also attempted to base our work on Julia “ecosystems” like <a href="https://github.com/JuliaStats">JuliaStats</a>, <a href="https://github.com/JuliaArrays/AxisArrays.jl">JuliaArrays</a>, <a href="https://github.com/EcoJulia">EcoJulia</a>, <a href="https://github.com/BioJulia">BioJulia</a>, <a href="https://github.com/JuliaPlots">JuliaPlots</a> and <a href="https://github.com/JuliaGeo">JuliaGeo</a>, as well as many other individual packages (e.g. <a href="https://github.com/JuliaComputing/JuliaDB.jl">JuliaDB.jl</a>, <a href="https://github.com/ajkeller34/Unitful.jl">Unitful.jl</a>), and we will discuss the advantages to and difficulties of using and integrating across such systems.
  bio: |

  id: 98

- speaker: "wheynderickx@gmail.com"
  avatar: "http://avatars.schd.ws/e/4c/5709027/avatar.jpg.320x320px.jpg?6c6"
  title: "Systemic Model of Banking Originated Losses (SyMBOL) in Julia"
  type: "lightning"
  abstract: "The need for speed: SyMBOL is a model that analyses bank failures. The core of SyMBOL is a Monte Carlo simulation with correlated random shocks and it was written in C. Given the parallel computing capabilities of Julia and a different setup, we were able to reduce the computation time by 50%."
  desc: |
    SyMBOL is a micro-funded statistical tool which analyses the consequences of bank failures and is used by the European Commission to assess regulatory proposals to enhance financial stability and prevent future financial crises. At the core of the model, there is a Monte Carlo simulation applying the Basel Foundation Internal Rating Based loss distribution. For security reasons, we were asked not to use our server where the C code is usually run. This forced us to re-code SyMBOL and we opted to do this in Julia. We considered different design options and faced the issue that results must be exactly the same. Our current design uses the main process to generate the random numbers, while the remote processes fetch the random numbers to calculate the correlated random shocks and check whether a bank has defaulted. The simulations stop if a pre-set number of runs (usually 100.000 runs) have at least one defaulted bank. Given this set up and the parallel computing capabilities of Julia we were able to reduce the computing time by around 50% compared to the parallel C-code discussed in Muresano and Pagano (2016).
    Muresano, R., Pagano, A., 2016. Adapting and Optimizing the Systemic Model of Banking Originated Losses (SYMBOL) Tool to the Multi-core Architecture. Comput. Econ. 48, 253–280. doi:10.1007/s10614-015-9509-4
  bio: |

  id: 100

- speaker: "Paulito Palmes"
  avatar: "http://avatars.schd.ws/1/6a/5709012/avatar.jpg.320x320px.jpg?096"
  affiliation: "IBM Dublin Research Lab"
  title: "CombineML for Seamless Ensembling of Machine Learning Models from Scikit-learn, Caret, and Julia"
  type: "lightning"
  abstract: ""
  desc: |
    <em>Abstract</em>
    CombineML main feature is to provide a framework for seamless ensembling of existing machine learning implementations from scikitlearn, caret, and Julia. It supports the following ensembles: stack, voting, and best. It is a heterogeneous ensemble driven by a uniform machine learner API designed for learner composition of machine learning implementations from scikit-learn, caret, and Julia.&nbsp;It allows the building of complex ensemble architecture in a few lines of code.&nbsp;

     #Create learners for parallel processing
     nprocs() ==1 && addprocs()

     @everywhere import CombineML.Util
     @everywhere import CombineML.Transformers
     @everywhere import RDatasets
     @everywhere CU=CombineML.Util
     @everywhere CT=CombineML.Transformers
     @everywhere RD=RDatasets

     #Scikit wrapper that provides access to scikit learners
     @everywhere sk_gblearner = CT.SKLLearner(
     &nbsp; Dict( :output =&gt; :class,
     &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; :learner =&gt; "GradientBoostingClassifier",
     &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; :impl_options =&gt; Dict()
     &nbsp; &nbsp;)
     )

     # Select best learner from the set
     @everywhere best_learner = CT.BestLearner(
     &nbsp; &nbsp; &nbsp; Dict(
     &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; :learners =&gt; [sk_gblearner,CT.PrunedTree(),CT.RandomForest()],
     &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; :output =&gt; :class, :score_type =&gt; Real, :learner_options_grid =&gt; nothing
     &nbsp; &nbsp; &nbsp; )
     )

     # Learners in voting committee
     @everywhere vote_learner = CT.VoteEnsemble(
     &nbsp; &nbsp; &nbsp;Dict(
     &nbsp; &nbsp; &nbsp; &nbsp;:output =&gt; :class,
     &nbsp; &nbsp; &nbsp; &nbsp;:learners =&gt; [
     &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; CT.PrunedTree(), CT.DecisionStumpAdaboost(),
     &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; CT.RandomForest(),sk_gblearner,best_learner
     &nbsp; &nbsp; &nbsp; &nbsp;]
     &nbsp; )
     )

     # Learners in stack ensemble
     @everywhere stack_learner = CT.StackEnsemble(
     &nbsp; Dict(
     &nbsp; &nbsp; :learners =&gt; [
     &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;CT.PrunedTree(), CT.RandomForest(),
     &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;CT.DecisionStumpAdaboost(),
     &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;best_learner, sk_gblearner
     &nbsp; &nbsp; &nbsp;],
     &nbsp; &nbsp; :stacker =&gt; CT.RandomForest()
     &nbsp; )
     )

     # Create a Pipeline
     pipeline = CT.Pipeline(
     &nbsp; Dict(
     &nbsp; &nbsp; :transformers =&gt; [
     &nbsp; &nbsp; &nbsp; &nbsp; CT.OneHotEncoder(), # Encodes nominal features into numeric
     &nbsp; &nbsp; &nbsp; &nbsp; CT.Imputer(), # Imputes NA values
     &nbsp; &nbsp; &nbsp; &nbsp; CT.StandardScaler(), # Standardizes features
     &nbsp; &nbsp; &nbsp; &nbsp; learner&nbsp;
     &nbsp; &nbsp; ]
     &nbsp; )
    )

     # Sample dataset from Iris
     dataset = RD.dataset("datasets", "iris")
     instances = Array(dataset[:, 1:(end-1)])
     labels = Array(dataset[:, end])

     # Split into training and test sets
     (train_ind, test_ind) = CU.holdout(size(instances, 1), 0.3)

     #Train and Predict
     CT.fit!(pipeline, instances[train_ind, :], labels[train_ind])
     predictions = CT.transform!(pipeline, instances[test_ind, :])

     # Compute accuracy
     result = CU.score(:accuracy, labels[test_ind], predictions)

     # Evaluate Ensembles in Parallel
     @everywhere function predict(learner)
     &nbsp; dataset = RD.dataset("datasets", "iris")
     &nbsp; instances = Array(dataset[:, 1:(end-1)])
     &nbsp; labels = Array(dataset[:, end])
     &nbsp; (train_ind, test_ind) = CU.holdout(size(instances, 1), 0.3)
     &nbsp; pipeline = CT.Pipeline(
     &nbsp; &nbsp; Dict(
     &nbsp; &nbsp; &nbsp; :transformers =&gt; [
     &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;CT.OneHotEncoder(), # Encodes nominal features into numeric
     &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;CT.Imputer(), # Imputes NA values
     &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;CT.StandardScaler(), # Standardizes features
     &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;CT.PCA(),
     &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;learner&nbsp;&nbsp;
     &nbsp; &nbsp; &nbsp; ]
     &nbsp; &nbsp; )
     &nbsp; )
     &nbsp; CT.fit!(pipeline, instances[train_ind, :], labels[train_ind]);
     &nbsp; predictions = CT.transform!(pipeline, instances[test_ind, :]);
     &nbsp; result = CU.score(:accuracy, labels[test_ind], predictions)
     &nbsp; return result
     end

     using DataFrames
     function main(trials)
     &nbsp; learners=Dict(
     &nbsp; &nbsp; &nbsp; &nbsp;:gradientboosting=&gt;sk_gblearner, :randomforest=&gt;CT.RandomForest(),
     &nbsp; &nbsp; &nbsp; &nbsp;:adaboost=&gt;CT.DecisionStumpAdaboost(), :votelearner=&gt;vote_learner,
     &nbsp; &nbsp; &nbsp; &nbsp;:bestlearner=&gt;best_learner, :stacklearner=&gt;stack_learner
     &nbsp; )
     &nbsp; models=collect(keys(learners))
     &nbsp; ctable=@parallel (vcat) for model in models
     &nbsp; &nbsp; &nbsp;acc=@parallel (vcat) for i=1:trials
     &nbsp; &nbsp; &nbsp; &nbsp; res=predict(learners[model])
     &nbsp; &nbsp; &nbsp; &nbsp; println(model," =&gt; ",round(res))
     &nbsp; &nbsp; &nbsp; &nbsp; res
     &nbsp; &nbsp; &nbsp;end
     &nbsp; &nbsp; &nbsp;[model round(mean(acc)) round(std(acc)) length(acc)]
     &nbsp; end
     &nbsp; sorted=sortrows(ctable,by=(x)-&gt;x[2],rev=true) |&gt; DataFrame
     &nbsp; rename!(sorted,Dict(:x1=&gt;:model,:x2=&gt;:mean_acc,:x3=&gt;:std_acc,:x4=&gt;:trials))
     &nbsp; return sorted
     end

     const trials = 5
     res = main(trials)
     @show res

     # Known Limitations
     # 1. Learners have only been tested on instances with numeric features.
     # 2. Inconsistencies may result in using nominal features
     #&nbsp; &nbsp; &nbsp;directly without a numeric transformation (i.e.&nbsp;OneHotEncoder).
  bio: |
    I am a research scientist at the IBM Dublin Research Lab working in the areas of analytics, datamining, machine learning, and AI. I finished my Doctor of Engineering degree from the Toyohashi University of Technology in Japan (2005). I have a Master’s degree in Computer Science majoring in Artificial Intelligence (Ateneo de Manila University, 1995) and a Bachelor’s degree in Applied Mathematics (University of the Philippines in the Visayas, 1991). I used to work as a technical staff for two years in the Neuroinformatics Lab of RIKEN Brain Science Institute, Japan before finishing my DEng degree. I spent a total of 4 years as a Postdoctoral Fellow in the National University of Singapore and the National Neuroscience Institute working on diverse topics such as context-aware reasoning, datamining models for activity recognition in smarthome environment, detecting biomarkers for Parkinson’s Disease by image processing of fMRI and DTI images, and automated diagnosis of movement disorder for intelligent healthcare. Moreover, I held an Asst. Professorship for a total of 6 years in the University of the Philippines and Ateneo de Manila University. My research interests include datamining, optimization, development of intelligent agents using machine learning and evolutionary computation, neuroinformatics, and biomedical engineering.
  id: 101

- speaker: "Jonathan Louis Kaplan"
  title: "RHEOS - Making mechanical testing more accessible with Julia"
  type: "lightning"
  abstract: "Analyzing mechanical testing data can be tricky, especially for those conducting interdisciplinary research (e.g. biomechanics) who may not have in-house code. We are using Julia to develop an open source software package to make this process simpler and more reproducible."
  desc: |
    Physicists and engineers have been investigating the mechanical properties of materials for a long time. Biologists, aided by recent developments in microscopy, have gained fascinating insights into the fundamental role mechanical properties play during many biological processes. One of the barriers to entry for biologists interested in biomechanics is the mathematical and programming knowledge required to analyse viscoelastic experimental data. RHEOS, written in Julia, is an open source project aiming to address that issue whilst also providing a more general rheological analysis toolkit for anyone who wants to analyse their viscoelastic material data, biological or otherwise. The software was originally written in Python. It was slow, but just about acceptable for a patient PhD student who had other things to keep busy with whilst the data was processing. Once the decision was made to extend it and publish it as open source software, it was clear that either more of the computationally intense parts would have to be outsourced from Python, or that it should be rewritten in a new language entirely. We chose the latter and the software has now been rewritten in Julia, with a first public release scheduled for March 2018. In this talk I will discuss the software’s capabilities, examples of rheology informing biology, more detail on the motivations for choosing Julia, the features of Julia which has helped the project come together, and any obstacles I ran into along the way and how they were overcome.
  bio: |

  id: 102

- speaker: "Hector Andrade Loarca"
  title: "LightFields.jl: Fast 3D image reconstruction for VR applications"
  type: "lightning"
  abstract: "Virtual Reality plays the leading role on the new media revolution with Light Field reconstruction as a common technique for content generation.High industrial interests make this technique hard to understand and implement, I will present a novel method to reconstruct the depth of objects in images."
  desc: |
    Light Field reconstruction is a relatively new technique for 3D reconstruction and rendering, that can be used to compute the depth of objects from a particular scene (physical subspace) given a set of images from different viewpoints.
    This technique has gained a lot of interest in the last ten years due the applications to Virtual and Augmented Reality; reflected most recently on the acquisition of the company Lytro (Light Field Camera Developer) by Google on <a href="https://www.theverge.com/2018/3/21/17148622/google-lytro-acquisition-light-field">March of this year</a>, and the recent advances presented also by <a href="https://www.blog.google/products/google-vr/experimenting-light-fields/">Google</a> and <a href="https://www.wired.com/story/magic-leap-lightwear-headset-hardware/">Magic Leap</a> for Light Field Applications on the new VR media revolution. Industrial interest also typically carries development closure and Light Field is not an exception, in addition it involves a great computational complexity.
    Inspired by the open source spirit (characterizing the julia Comunity) and the search of interesting applications for the julia package <a href="https://github.com/arsenal9971/Shearlab.jl">Shearlab.jl</a> (developed by me and presented at the last JuliaCon), I developed a julia library for Light Field reconstruction that optimizes the computation by using the Shearlet transform to represent sparsely the Light Field, called <a href="https://github.com/arsenal9971/LightFields.jl">LightFields.jl</a>. In this lightning talk I will present the basics of the LightFields.jl’s API, some nice results, and also a very easy and cheap, open hardware implementation of a Light Field Camera using no more than julia and a Raspberry Pi.
  bio: |

  id: 103

- speaker: "Jane Herriman"
  affiliation: "Caltech/Lawrence Livermore National Lab"
  title: "Making Julia inclusive and accessible"
  type: "lightning"
  abstract: "How can we make Julia more inclusive of and accessible to new users from all backgrounds and experience levels? We want to create fantastic teaching materials that don’t assume a ton of prior knowledge. I’ll share what we’ve done so far to make Julia more accessible and how you can help!"
  desc: |
    Most of us are here because we’re already using and excited about Julia. How can we make the language and ecosystem more inclusive of and accessible to potential new users coming from all backgrounds and experience levels? I believe the keys are creating fantastic teaching materials and making these materials free, open, and visible. We want to make sure that the barrier to learning Julia is low — and not just for experienced programmers.
    I will share with you efforts underway in the Julia community to develop and distribute accessible materials to learn Julia, including in-person outreach at schools around North America and an online tutorial series. Of course, our focus cannot simply be on teaching Julia, but on using Julia to teach other in-demand skills, like programming and data science. To this end, I will also discuss the development of machine learning curriculum using Julia and ways that you can get involved in making the Julia language and ecosystem more accessible.
  bio: |
    Jane is a graduate student in computational materials physics enrolled at Caltech. She is interning at Lawrence Livermore National Lab, where she is working with Xavier Andrade on methods for and applications of density functional theory.
  id: 104

- speaker: "Mike Innes"
  title: "Flux: The Elegant Machine Learning Library"
  type: "talk"
  abstract: "Flux is a new machine learning library that’s easy and intuitive to use with state-of-the-art performance. I’ll show how we achieve this using Julia’s advanced features alongside modern compiler and language technology, as well as cool things that people are doing with Flux."
  desc: |
    As machine learning models grow increasingly complex, we suggest that neural networks are best viewed as an emerging, differentiable programming paradigm, and ask what decades of research into programming languages and compilers has to offer to the machine learning world.
    Julia is an ideal platform not only for this kind of high-performance, numerical programming, but for the research into compiler and language features needed to push the state of the art forward. Features such as wide hardware support (GPUs, TPUs), kernel fusion, compiler-level automatic differentiation, push-button compilation and deployment and elegant mathematical syntax are all invaluable to researchers. This talk will explain how we are able to take the Julia compiler to its limits and push forward the state of the art in the machine learning world.
  bio: |

  id: 105

- speaker: "Giovanni Ballarin"
  avatar: "http://avatars.schd.ws/d/98/5709083/avatar.jpg.320x320px.jpg?8f6"
  affiliation: "Konstanz U"
  title: "GPU-Accelerated Value Function Iteration in Julia: Faster Macroeconomic Modeling"
  type: "talk"
  abstract: "Value Function Iteration (VFI) is a technique widely used by economists to solve dynamic programming problems. VFI is conceptually simple, but computationally very taxing with complex models or high dimensions. However, using Julia and GPUs, it is possible to run VFI algorithms up to 150x faster."
  desc: |
    Among the many computational techniques that economists, and more specifically macroeconomists use to solve models, value function iteration (VFI) is probably the most commonly used. VFI is simple to implement, conceptually very close to the theoretical results of dynamic programming and works over a wide range of models, especially if these entail complex stochastic elements. Unfortunately, VFI algorithms are computationally very taxing even for modern machines, usually requiring long times (in the order of <em>hours</em>) to converge to a solution.
    To address this problem, much in the footsteps laid down by the paper by Aldrich, Fernandez-Villaverde,Gallant and Rubio-Ramirez “<em>Tapping the Supercomputer under your Desk: Solving Dynamic Equilibrium Models with Graphics Processors</em>” , I would like to present how it is almost trivial to use Julia, OpenCL, and the packages GPUArrays.jl and CLArrays.jl to run VFI algorithms <strong>orders of magnitude faster</strong>, using only a consumer (integrated) graphics card and without loosing appreciable precision.
    We focus our attention on the following topics:

    * <strong>Introduction to Dynamic Programming and why VFI is so common</strong> …Many problems in macroeconomic are usually posed, or can be posed in the form of dynamic programming: this usually entails writing the so-called Bellman equation of the problem. We introduce the Value Function Iteration algorithm in the context of the super simple Real Business Cycle model.
    * <strong>VFI in Julia</strong> …Value function iteration is easy to implement in Julia, but can be very slow: this is because the algorithm explicitly requires a maximization step. Because of the so called “curse of dimensionality” this approach does not scale well as we increase the number of points. This effectively creates a “physical” barrier between the researcher and exploring the model features with ease by changing parameters and studying the resulting solution.
    * <strong>Leveraging the GPU</strong> …We first port the VFI algorithm for the RBC using OpenCL.jl and writing a simple OpenCL kernel. This approach however is cumbersome and may be unfeasible. Then, we discuss how the packages GPUArrays.jl and CLArrays.jl allow to make this transition much, much simpler.
    * <strong>More complex models and GPU superiority</strong> …Finally, we expand the GPU value function iteration algorithm used for the RBC model to two more articulate settings: and RBC model with uncertainty; and an Overlapping Generations Model, for which the GPU implementation cuts the solution time from more than 40 minutes to less than 30 seconds, with a speed gain of around 150x.

  bio: |
    I am an M.SC in Economics student in my second and last year at Konstanz University, Germany, in a double degree program with the University of Rome Tor Vergata. I have an undergraduate degree in Mathematics (which is and will be my secret passion), even thought I’ve now turned to Macroeconomics. My passions are: programming, tennis, pasta all’amatriciana and listening to music during long car trips. I don’t have to write code, but it gives me much joy.
  id: 106

- speaker: "Elliot Saba"
  title: "10 tips on how to build better binaries; you won't believe #8!"
  type: "talk"
  abstract: "Building and serving binary dependencies for Julia has been a challenging problem in the past. With BinaryBuilder.jl and BinaryProvider.jl, we present a set of powerful and straightfoward tools to compile, serve and load binary dependencies for packages on all platforms Julia supports."
  desc: |
    The old world of BinDeps.jl fades slowly into the long, dark sleep of forgotten heroes. From the deep places arises a new contender, strong and eager to lay to rest the complaints of the commonfolk. Songs of ancient deeds and whispers of arcane knowledge wend their ways around the terrible visage of BinaryBuilder.jl like a luminous crown, forcing all who lay eye upon it to tremble in a mixture of fear and awe. The age of terror has passed. A new world dawns.
    Building binary dependencies for the wide range of platforms that Julia supports is difficult; BinaryBuilder makes this easier for you. Come to this talk to learn about how we are solving this problem, and how you can use these tools to compile your C/C++/Fortran binary dependencies into tarballs for use in your Julia packages. We will start with a brief introduction to the internals of BinaryProvider and BinaryBuilder, then end with building a tarball for a binary dependency and installing it for a Julia package. By the end of this talk, you should be comfortable with using BinaryBuilder to build tarballs, and using BinaryProvider to install them within your own packages.
  bio: |

  id: 107

- speaker: "Patrick Kofod Mogensen"
  avatar: "https://graph.facebook.com/v2.3/10154694169813030/picture?width=400&height=400"
  affiliation: "University of Copenhagen"
  title: "Native Elementary Functions in Julia"
  type: "lightning"
  abstract: "People doing numerical computing are greedy. They want results now and accurately, and we have been ready to accept loss of readability and extensibility to get it. As a result, the elementary functions we take for granted in paper math are often coded in low-level languages. We can do better."
  desc: |
    People doing numerical computing are greedy. They want results now and accurately, and we have been ready to accept loss of readability and extensibility to get it. As a result, the elementary functions we take for granted in paper math are often coded in low-level languages. We can do better.
    The talk will go through the motivation, the work done, what remains to be done, and what further possibilities there are to improve performance and accuracy of elementary function evaluations in Julia. Collectively, these functions are often provided in so-called “libm”’s (library of mathematical functions), and many languages oriented towards numerical computing tend to call libraries written in C or Fortran.
    Julia has depended on a collection of functions bundled in the C-based openlibm to provide this functionality. As we will see, there has been a push to free Julia of openlibm and similar C- or Fortran-libraries without loss of speed, accuracy or readability.
  bio: |
    Ph.D. student in economics, JuliaNLSolvers owner and developer, Julia nerd.
  id: 108

- speaker: "Niccolò Antonello"
  title: "StructuredOptimization.jl: a new optimization package for Julia"
  type: "talk"
  abstract: "Numerical optimization is used in many scientific fields such as signal processing, machine learning, finance and control. We propose a new Julia package providing an intuitive language for defining and solving possibly nonconvex, nonsmooth optimization problems using natural mathematical notation."
  desc: |
    <a href="https://github.com/kul-forbes/StructuredOptimization.jl">StructuredOptimization</a> provides a modelling language to formulate and solve optimization problems, using a syntax that closely resembles the original mathematical formulation. This user-friendly interface acts as a parser to use three different packages:

    * <a href="https://github.com/kul-forbes/ProximalOperators.jl">ProximalOperators.jl</a>: a library of proximal mappings of functions that are frequently used in optimization.
    * <a href="https://github.com/kul-forbes/AbstractOperators.jl">AbstractOperators.jl</a>: a library of linear and nonlinear mappings that can be combined for gradient evaluation using automatic differentiation.
    * <a href="https://github.com/kul-forbes/ProximalAlgorithms.jl">ProximalAlgorithms.jl</a>: a library of optimization algorithms that includes the Proximal Gradient (PG) algorithm and its enhanced variants.  StructuredOptimization can handle large-scale convex and nonconvex problems with nonsmooth cost functions and supports complex variables as well.

    The package will be presented by illustrating the high versatility of the PG algorithms through a series of application examples. In particular, classical signal processing applications (sparse deconvolution and line spectra estimation) will be shown together with audio, image and video processing applications (audio de-clipping, total variation denoising and video background removal) and nonlinear classification using machine learning techniques.
  bio: |

  id: 109

- speaker: "Demian Panigo and Pablo Gluzmann and Esteban Mocskos and Adán Mauri Ungaro and Valentin Mari"
  affiliation: "Universidad de Buenos Aires/CONICET and and"
  title: "GSReg.jl: High Performance Computing in Econometrics. Let’s do it faster and simpler with Julia"
  type: "lightning"
  abstract: "The objective of this talk is to introduce GSReg.jl, a new all-subset-regression package to perform High Performance Computing in econometrics using Julia. GSReg.jl runs 4 to 100 times faster than similar packages and comes with a simplified GUI to allow smooth-transitions for R and Stata users."
  desc: |
    Econometrics allows researchers to deal with competing theories about complex processes which could lead to very different diagnosis and even opposite policy advises. Advances in model selection techniques, driven by the increasing number of available HPC algorithms, constitutes one of its major contributions to Economic Theory.
    In-sample model selection has benefited from using mathematical developments to reduce the search space (e.g. Branch and Bound theorems) and efficiently find the best subset regression (in terms of defined information criteria). It is also possible to use heuristic approaches like Genetic algorithms, or different dimension reduction methods like Stepwise, Lasso or Ridge estimators. While failing to guarantee global optimality, they are fast and well-suited for Big and/or Sparse Data.
    On the contrary, out-of-sample model selection techniques require more computing resources. In a Machine Learning environment (e.g. problems focusing on predictive analysis) there is an increasing universe of “training/test” algorithms (many of them showing very interesting performance in <strong>Julia</strong>) to compare alternative results and find-out a suitable model. In Econometrics (e.g. problems focusing on causal inference) we require five important features which narrow the set of available algorithms: 1) Parsimony (to avoid very large atheoretical models); 2) Interpretability (for causal inference, rejecting “intuition-loss” transformation and/or complex combinations); 3) Across-models sensitivity analysis (economic theory is preferred against “best-model” unique results); 4) Robustness to time series and panel data information (preventing the use of raw bootstrapping or random subsample selection for training and test sets); and 5) advanced residual properties (e.g. going beyond the i.i.d assumption and looking for additional panel structure properties -for each model being evaluated-, which force a departure from many algorithms).
    For these reasons, most economists prefer flexible all-subset-regression approaches, choosing among alternative models by means of some out-of-sample criteria, model averaging results, theoretical limits on covariates coefficients and residual constraints. While still unfeasible for Sparse Data (<em>p&gt;&gt;n</em>), hardware and software innovations allow researchers to choose among one billion models in a few hours using a standard personal computer. Therefore, almost all statistical applications have an all-subset regression function. Some of them, have even developed a parallel version of their core algorithm (<em>pdredge</em> in R or <em>gsregp</em> in Stata).
    The objective of this talk is to introduce <strong>GSReg.jl</strong> (https://github.com/ParallelGSReg/GSReg.jl), a new package to perform the all-subset-regression approach exploiting Julia’s parallel capabilities and allowing users to choose between a simple GUI (https://github.com/ParallelGSReg/GSRegGUI) or an R/Stata-friendly command line interface. We will discuss its main features, pros and cons, limitations, future extensions and differences with similar existing Julia packages like BestSubsetRegressionl.jl, LARS.jl Lasso.jl, Mads.jl, ParallelSparseRegression.jl or SubsetSelection.jl.
    We will show that <strong>GSReg.jl</strong> is 4 to 10 times faster than other similar alternatives and more than 100 times faster than the original (sequential) Gsreg Stata version (using a last generation personal computer). A forthcoming paper will include programming details, profiling data, extended examples and benchmarking results.
  bio: |
    HPC, Parallel Programming, Disitributed Systems, Applying parallel resources to real life applications




  id: 110

- speaker: "Jacob Quinn"
  affiliation: "Domo"
  title: "New in DataStreams.jl: Type flexibility, querying, and parallelism, oh my!"
  type: "lightning"
  abstract: "What’s new in the data framework package powering some of the most popular data packages in Julia? Come learn about advancements in flexibly typed schemas, querying functionality directly integrated with IO, and automatic data transfer parallelism."
  desc: |
    The DataStreams.jl framework is behind a number of key packages in the Julia data ecosystem. At it’s core, it defines the “Source” and “Sink” interfaces that various formats can implement to automatically integrate with other formats that also implement the interfaces. This solves the one-to-many interop problem that always plagues data formats (“what? it only takes CSV files??”). With DataStreams, it’s quick and easy to implement the interface and automatically hook into the rest of the Julia data ecosystem.
    So what’s new and noteworthy in DataStreams?

    * Flexibly typed schemas: a long-standing issue with any sort of data transfer is how to align expected types between source and sink; Base julia itself has pioneered a flexible, yet performant solution in it’s implementation of map over collections. This same approach has been applied to DataStreams to allow dynamic, type-inference-independent transfer from sources to sinks.
    * IO-integrated querying functionality: how many times have you thought, “sheesh, I wish there was a way to only parse a few columns, filter out certain values, and apply a transformation to this csv file all at the same time!” Ok, maybe not those words exactly, but with DataStreams, now you can! A fully integrated query-planner can now take any number of transformations and apply them at the IO-level to avoid more data transfer than absolutely necessary and fuse them all together in tightly compiled Julia code.
    * Data transfer parallelism: Sinks can now signal to Sources that they support parallel streaming; this can lead to massive improvements in data throughput and fully leveraging a system’s resources

  bio: |
    Attended Carnegie Mellon for a master's degree in data science and active Julia contributor for 4 years now.
  id: 111

- speaker: "Lionel Zoubritzky"
  avatar: "http://avatars.schd.ws/f/af/5709081/avatar.jpg.320x320px.jpg?9fe"
  title: "Engineering Julia for Speed"
  type: "talk"
  abstract: "Julia’s design enables efficient idiomatic code optimizations. I will detail Julia’s main optimizations and explain under which conditions on the code Julia’s JIT compiler can perform them. I will also show how users meet these conditions, using static and dynamic analyses of popular Julia packages."
  desc: |
    The Julia language has been designed in order to offer performance without sacrificing productivity. Its secret is a combination of carefully chosen features, such as multiple dispatch and rich type annotations, and some optimizations like inlining done by the just-in-time compiler. I will explain how the code is optimized by Julia’s JIT before being given to the LLVM back end, and, as a consequence, why a specific coding style is required for performance. I will also look at a selection of fifty popular Julia packages to see how amenable they are to these optimizations, using static and dynamic analyses. Finally, I will briefly talk about Julia’s design against the context of other related programming languages, to show the singular place it occupies.
  bio: |
    Currently in first year of Master at the École Normale Supérieure.
  id: 112

- speaker: "Shashi Gowda"
  avatar: "http://avatars.schd.ws/9/5a/5709093/avatar.jpg.320x320px.jpg?287"
  affiliation: "Julia Computing"
  title: "Getting Started with JuliaDB"
  type: "talk"
  abstract: "Introductory talk on JuliaDB, a large-scale analytical database in pure Julia."
  desc: |
    This talk introduces the core features of JuliaDB illustrating the same with examples.

    * Why we built JuliaDB?
    * Brief introduction to Indexed tables
    * Table construction
    * Benefits of Indexing
    * NDSparse view of a table
    * Selecting the data you need
    * Selection semantics
    * Aggregation
    * groupreduce vs groupby
    * Many aggregations at once
    * Use of selections in grouping
    * OnlineStats
    * Joins
    * Use of selection
    * About parallelism in JuliaDB
    * Representation of a distributed dataset
    * How parallel operations work
    * Demo of parallel speedup on a 100GB dataset.
    * Plotting
    * Demo of partitionplot on a big dataset
    * Demo of PlugAndPlot.jl and Sputnik.jl working with JuliaDB
    * Some trivia that are useful
    * Representation of String arrays
    * Representation of PooledArrays
    * The role of sortperm
    * Using the full power of Julia
    * User defined types and functions
    * Performance comparisons

  bio: |
    I’m a Julia programmer at Julia Computing.
  id: 114

- speaker: "Bart Janssens"
  title: "Parallel computing with MPI-3 RMA and Julia"
  type: "talk"
  abstract: "The remote memory access routines from MPI-3 are a natural fit for the Julia programming model. We show how to build a custom IO and distributed array on top of them, and how this system can help with interfacing with both Julia native parallelism and external MPI-based libraries."
  desc: |
    The objective of this talk is to illustrate how some of the “modern” MPI functions can be used to build new parallel tools in Julia and interface with existing native parallelism in Julia. The motivation for this work is to simplify working with libraries such as <a href="https://github.com/trilinos/Trilinos">Trilinos</a>.
    We will begin by outlining the differences between the Julia native parallelism and the MPI “single program, multiple data” approach. Next follows a gentle introduction to the MPI-3 calls (now available in <a href="https://github.com/JuliaParallel/MPI.jl">MPI.jl</a> master), which perform communication in a one-sided way, so not all processes need to call MPI routines at the same time. This property is very useful to build a custom Julia IO (similar to TCPSocket) for point-to-point communications over MPI. This IO can then be used to build a Julia cluster manager, enabling native Julia parallelism over asynchronous MPI communication. The steps required to build this system (code <a href="https://github.com/JuliaParallel/MPI.jl/pull/203">here</a>) will be outlined, together with some caveats encountered when implementing the interface required for IO. Once a program is running on an MPI cluster manager, it becomes possible to switch on the fly between native Julia parallel calls and MPI calls, which we will illustrate using a simple example.
    Distributed arrays are another key area where one-sided MPI calls can be put to use. The <a href="https://github.com/barche/MPIArrays.jl">MPIArrays.jl</a> package provides such an array type. The advantage of using MPI directly rather than the Julia parallel framework is that the “single program, multiple data” paradigm is preserved, so interfacing with external libraries using MPI becomes trivial. Furthermore, MPI supports the high-performance interconnects such as Infiniband that are available on many clusters. We will present the basic ideas behind MPIArrays, and show how building the basic distributed AbstractArray takes just a few lines of Julia code. A benchmark using a dense matrix-vector product will show it compares favorably to <a href="https://github.com/JuliaParallel/DistributedArrays.jl">DistributedArrays.jl</a> and the C++ library <a href="https://github.com/elemental/Elemental">Elemental</a>. We will then finish the talk with a concrete example of using MPIArrays to build the sparsity structure of a linear system to be solved by the Trilinos C++ library.
  bio: |

  id: 115

- speaker: "Harrison Grodin"
  title: "Algebraic Simplification Using Rewrite.jl"
  type: "lightning"
  abstract: ""
  desc: |
    Term rewriting is essential to a wide variety of fields, including elementary, boolean, and abstract algebras. Because existing symbolic simplification tools in Julia typically operate within fixed domains, it is difficult to obtain a level of control which allows for flexible inclusion and exclusion of specific mathematical properties. This talk discusses SymReduce.jl, a new term rewriting library written in Julia that simplifies algebraic expressions based on custom, domain-specific axioms. We will highlight aspects of our implementation and demonstrate the simplification process within sample domains.
  bio: |

  id: 116

- speaker: "Josh Day"
  title: "Scalable Data Science with JuliaDB and OnlineStats"
  type: "talk"
  abstract: "JuliaDB integrates with OnlineStats to provide scalable single pass algorithms (that can run in parallel) for statistics and modeling on big data. This integration allows you to transform small-scale analyses into out-of-core computations for huge datasets without changing your code."
  desc: |
    <a href="https://github.com/JuliaComputing/JuliaDB.jl">JuliaDB</a> is a distributed database for high performance analytics that allows you to load large multi-file datasets across multiple processes, index the data for fast queries, and save tables to disk for quick reloading. JuliaDB is 100% Julia, so user-defined functions are compiled and you can efficiently store any data type.
    <a href="https://github.com/joshday/OnlineStats.jl">OnlineStats</a> is a Julia package that provides online algorithms for statistics, machine learning, and big data visualization. Online algorithms update estimators one observation at a time in a single pass, making it unnecessary that your data fit in memory. JuliaDB interfaces with OnlineStats to provide a scalable analytical framework that does the heavy lifting for you. The same operations used on toy datasets can therefore be efficiently executed on a cluster without changing your code.
    This combination provides a powerful workflow for dealing with both large and small datasets. This talk will demonstrate how you can take advantage of these packages to implement scalable analytics over your own datasets.
  bio: |

  id: 117

- speaker: "Jarvist Moore Frost"
  avatar: "http://avatars.schd.ws/d/69/5709009/avatar.jpg.320x320px.jpg?4e8"
  affiliation: "King's College London"
  title: "Atomistic simulation with Julia"
  type: "lightning"
  abstract: "Atomistic simulation needs custom models, to approximate through hard O(N!) scaling of the underlying physical equations. Julia is a natural language to express such physical abstractions in. I will show how you can contribute to materials research with Julia and a fistful of 1960s PhysRevs."
  desc: |
    We can predict the properties of materials entirely within a computer. All material properties - strength, colour, opacity, conductivity etc. - come about as a result of the electronic structure adopted by the electrons in a material. This we can calculate by solving the Schrodinger equation. Unfortunately exact solutions are computationally intractable due to the O(N!) scaling with the number of electrons - the electron correlation problem. Progress in computational materials design has been made by solving approximate forms of this equation, numerically.
    Venerable codes written in Fortran (and to a limited extent in C) consume the majority of cycles on public super conductors. The often archaic code bases limits how easily they can be extended. The existence of standard, optimised, codes has enabled an enormous amount of research. At the same time, development of codes in relatively few walled gardens of physics has reduced the scope of techniques that are applied.
    Modern materials design attempts to go beyond predicting properties of pure crystals. Generally this is because disordered materials can be made with less energy and time. Trying to predict the properties of these materials is a challenge, as the length and time scales so exceed that which we can get to even with approximate theories. As such, we need bespoke codes and models to be able to model these systems.
    I will describe successful research projects in condensed matter theory which have made essential use of Julia, and will attempt to explain why Julia, with its mathematical expressiveness, physical abstraction, and high performance, is a natural language for future work in condensed matter theory.
    I will discuss revisiting Polaron mobility theories from the 1960s (https://github.com/jarvist/PolaronMobility.jl), approximate forms of quantum-nuclear effects (https://github.com/jarvist/FeynmanKleinert.jl) and Tight-Binding approaches to large scale electronic structure calculations.
  bio: |
    A simple physicist who works in computational materials design. Everything we make is wiggling and jiggling atoms, and these are fun to simulate.
  id: 118

- speaker: "Scott Thomas"
  title: "Julia-powered personalised mathematics homework"
  type: "lightning"
  abstract: "Anyone who works in a technical field has heard something like this from family or friends: “Oh, I was never any good at maths at school.” My job is to set targeted, achievable mathematics homework so that no child ends up feeling this way. Let me tell you how I use Julia to do this."
  desc: |
    Teaching children is hard, mathematics in particular. It’s all too easy for a student to shrug and say, “I’m just no good at maths.” Perhaps the most important way we can support them is by showing that they can always get better with practice, and one of the great promises of educational technology is to help busy teachers assign targeted and achievable tasks… but while it’s easy to gamify some parts of mathematics, it’s harder to produce something that meets every student at their level.
    My job at a UK educational research company is to do just that. We work in local classrooms to design and evaluate mathematics lessons and we produce personalised homework every week. As we work with more schools, it’s increasingly important to quickly try new things and carry out experiments to check that what we’re doing is effective. I’d like to share how I have increasingly been using Julia in my investigations into effective mathematics homework, giving you an inside view on what it has made easy (and what still causes pain).
  bio: |

  id: 119

- speaker: "Bart Janssens"
  title: "Solving sparse linear systems with Trilinos.jl"
  type: "lightning"
  abstract: "The Trilinos library features modern iterative solvers for large linear systems. Using the Tpetra library, it can exploit hybrid parallelism and GPUs. We present an overview of the current status of the package that makes this functionality available to Julia."
  desc: |
    The <a href="https://github.com/trilinos/Trilinos">Trilinos</a> C++ library features a large collection of packages, with a focus on solving large linear systems. The <a href="https://github.com/barche/Trilinos.jl">Trilinos.jl</a> package is an effort to provide access to the modern iterative solvers from the Belos package from within Julia. It focuses on using the sparse matrix structures from the Tpetra package, which enables features such as hybrid parallelism and GPU computing.
    In Trilinos, the solvers are driven by so-called parameter lists, which allow setting up the linear solver and preconditioner to use. This way, all iterative solvers from the Belos package (including GMRES and CG) are available from Julia, with preconditioners from the Ifpack2 package (providing ILU-type preconditioners) and the MueLU algebraic multigrid package. As with all of Trilinos, these support parallel execution using MPI. In our talk, we will show how to configure a parameter list from within Julia, build the linear system and finally solve it. In many places, native Julia interfaces are implemented, such as an array interface operating directly on views of Trilinos vectors, the Associative interface for parameter lists and the \ operator to perform the actual linear system solution.
    The talk will conclude with an example, showing how to solve the 2D Laplace equation and presenting a timing comparison with other Julia packages and native C++ Trilinos, showing that using the Julia interface does not slow down the system assembly.
  bio: |

  id: 120

- speaker: "Uri Patish"
  title: "Black-Box Combinatorial Optimization"
  type: "lightning"
  abstract: "Highly parallelizable black box combinatorial optimization algorithm that only relies on function evaluations, and which returns locally optimal solutions with high probability."
  desc: |
    Combinatorial optimization is a common theme in computer science which underlies a considerable variety of problems. While in general such problems are NP-Hard, from a practical point of view, locally optimal solutions can be quite useful. However, combinatorial problems require special solution strategies, and generic approaches like gradient methods for the continuous setting are hard to come by. We present a new stochastic optimization algorithm that can be applied in a generic fashion to a variety of combinatorial problems, and which only relies on function evaluations. In contrast to standard optimization algorithms, the new algorithm is highly parallelizable, and can rely on multiple evaluations simultaneously. The new algorithm is provided as part of a new Julia package that capitalizes on Julia’s parallel computation infrastructure in a manner that is completely transparent to the end user. Together with Julia’s excellent JIT compilation, this leads to a highly effective distributed optimizer for combinatorial problems that requires end users to provide nothing more than the function they seek to optimize.
  bio: |

  id: 121

- speaker: "Matt Bauman"
  avatar: "http://avatars.schd.ws/4/92/5709076/avatar.jpg.320x320px.jpg?b80"
  affiliation: "Julia Computing"
  title: "An introduction to high performance custom arrays"
  type: "talk"
  abstract: "Have you ever wondered how or why you might create a custom array? Have you never written struct ___ &lt;: AbstractArray{T,N}? It’s easier than you might expect! I’ll give a motivating example, incrementally define and refine a custom array, and demonstrate how to make it robust and fast."
  desc: |
    The ability to define fully-functional custom arrays with a struct definition and just a handful of methods is a powerful tool in Julia, but there are some tips and tricks that are essential to making them both fast and robust. In this talk, I’ll implement a custom array following the <a href="https://docs.julialang.org/en/stable/manual/interfaces/#man-interface-array-1">AbstractArray interface</a>, and then we’ll dig in deeper to examine and iteratively optimize the generated code in a typical use-case. We’ll examine some key examples where custom arrays can completely transform an algorithm. You’ll be able to follow along with an incremental approach to defining and improving the arrays. Along the way, you’ll learn about the key idioms — like Holy traits and bounds-checking — that are integral to this interface. Finally, I’ll take a look at some of the more advanced custom arrays that are published, useful, and widely used.
  bio: |
    Matt Bauman is a Senior Research Scientist at <a href="https://juliacomputing.com">JuliaComputing</a> at their Chicago outpost, where he spends lots of time working on Julia’s arrays. He’s been contributing to both the core language and multiple packages since 2014. At his previous position as a Data Science Fellow at the University of Chicago’s <a href="https://dssg.uchicago.edu">Center for Data Science and Public Policy</a>, he longed for dot-broadcasting in Python. He recently defended his PhD dissertation in Bioengineering from the University of Pittsburgh, focusing on neural prosthetics.
  id: 122

- speaker: "Frank Otto"
  avatar: "http://avatars.schd.ws/1/0e/5709055/avatar.jpg.320x320px.jpg?a16"
  affiliation: "University College London"
  title: "Hierarchical Tensor Decompositions in Julia"
  type: "lightning"
  abstract: "Julia’s high-level nature and speed helped me to implement an intricate algorithm for converting a set of high-dimensional data into a very compact representation, allowing me to efficiently solve real-world research problems."
  desc: |
    Tensor decompositions are a powerful method to compactly represent high-dimensional data. Such data is encountered quite naturally in the numerical treatment of quantum systems with many particles, e.g. small molecules. In this talk I will show how Julia helped me to represent a nine-dimensional potential energy surface for the H3O2- molecule as a compact hierarchical tensor, which allowed for a very efficient numerical computation of its ground state. The resulting Julia code for computing hierarchical tensor decompositions may be of general use for dealing with structured high-dimensional data.
  bio: |
    Frank has a PhD in Theoretical Chemistry, and many years of experience with scientific software development and high performance computing. In 2017 he joined the Department of Chemistry at University College London as an HPC support specialist. Frank has been keenly following the development of Julia since 2013, and continues to advocate its use to his colleagues.
  id: 123

- speaker: "Jens Weibezahn"
  title: "Joulia.jl -- A Large-scale Spatial Open-source Electricity Sector Model Package"
  type: "lightning"
  abstract: "With Joulia.jl we developed a package for electricity sector models in Julia, taking advantage of the possibilities to cover all steps of the modeling workflow from data pre-processing, over the algebraic modeling and solution up to the visualization of results in an open-source environment."
  desc: |
    In this paper, we develop a fully open-source bottom-up electricity sector model with high spatial resolution using the Julia programming environment, describing source code and data set. This large-scale model of the German electricity market includes both generation dispatch in the spot market as well as the physical transmission network, minimizing total system costs in a linear approach. It simulates the market on an hourly basis, taking into account demand, renewables infeed, storages, and exchanges with neighboring countries. Following an open-source approach, model code and used data set are being made fully publicly accessible and open-source solvers like ECOS and CLP are being used. The model is then being benchmarked regarding runtime of building and solving against a representation in GAMS as a commercial algebraic modeling language and against Gurobi, CPLEX, and Mosek as commercial solvers. With this paper we want to show the power and abilities as well as the beauty of open-source modeling systems, increasing transparency in policy advice, available free of charge to everyone and using the advatages of open data, open-source modeling, and open-access publications.
  bio: |

  id: 125

- speaker: "David Anthoff"
  avatar: "http://avatars.schd.ws/2/C2/4113619/avatar.jpg.320x320px.jpg"
  affiliation: "University of California, Berkeley"
  title: "Visual Studio Code julia extension"
  type: "talk"
  abstract: "The julia extension for Visual Studio Code provides a convenient coding environment for julia development. This talk will highlight key features of the extension."
  desc: |
    This talk will give an overview of the Julia extension for VS Code. The extension currently provides syntax highlighting, an integrated REPL, code completion, hover help, an integrated linter, code navigation, integration with the Julia testing infrastructure and integrated support for Weave documents (Julia’s knitr equivalent). A 30-minute version of this talk would talk about the internals of the extension. We would describe the Julia language server (our implementation of the Microsoft Language Server Protocol) that provides the integration with the VS Code UI. Other topics we would cover are our approach to build a robust and reliable software delivery mechanism that does not depend on the shared Julia package directory, our custom parser that is used in the language server and the developments currently being made to provide actionable parse-time formatting and linting hints, as well as any other features we might add between now and JuliaCon.
  bio: |
    David Anthoff is an environmental economist who studies climate change and environmental policy. He co-develops the integrated assessment model FUND that is used widely in academic research and in policy analysis. His research has appeared in Science, Nature Climate Change, the Journal of Environmental Economics and Management, Environmental and Resource Economics, the Oxford Review of Economic Policy and other academic journals. He contributed a background research paper to the Stern Review and has advised numerous organizations (including US EPA and the Canadian National Round Table on the Environment and the Economy) on the economics of climate change.



     He is an assistant professor in the Energy and Resources Group at the University of California, Berkeley. Previously he was an assistant professor in the School of Natural Resources and the Environment of the University of Michigan, a postdoc at the University of California, Berkeley and a postdoc at the Economic and Social Research Institute in Ireland. He also was a visiting research fellow at the Smith School of Enterprise and the Environment, University of Oxford.nHe holds a Ph.D. (Dr. rer. pol.) in economics from the University of Hamburg (Germany) and the International Max Planck Research School on Earth System Modelling, a MSc in Environmental Change and Management from the University of Oxford (UK) and a M.Phil. in philosophy, logic and philosophy of science from Ludwig-Maximilians-Universität München (Munich, Germany).
  id: 126

- speaker: "Mauro Werder"
  avatar: "http://avatars.schd.ws/5/c4/5709044/avatar.jpg.320x320px.jpg?316"
  title: "Parameters.jl: keyword constructors and default values for types"
  type: "lightning"
  abstract: "Parameters.jl provides a macro to decorate type-definitions which adds keyword constructors and default values. When working with instances it has macros to unpack their fields. I will demo its core features, the resulting cleaner code patterns, and the improvements to code maintainability."
  desc: |
    <a href="https://github.com/mauro3/Parameters.jl">Parameters.jl</a> is a small package providing macros which add keyword constructors to types including the possibility to set default values for each field. This allows to effectively construct with types which have a large number of fields, as often encountered –for instance– to hold configurations of programs. Additionally, it provides macros to unpack (and pack) the values within a type, thus allowing to access them easily inside functions (or other scopes).
    using Parameters @with_kw struct MyT a::Int = 1 # ... m = 1:3 # ... z::String = &quot;zzz&quot; end myt = MyT(z=&quot;j&quot;) # MyT(1, 1:3, &quot;j&quot;) function f(myt::MyT, x) @unpack a, m = myt m + a + x end f(myt, 1) # 3:5 Keyword constructors and default field values are so useful that they are scheduled to hit Julia during a 1.x release (<a href="https://github.com/JuliaLang/julia/issues/10146">#10146</a>). But don’t wait until then, unleash their power now!
  bio: |

  id: 127

- speaker: "Robin Deits"
  avatar: "http://avatars.schd.ws/7/c1/5709092/avatar.jpg.320x320px.jpg?e57"
  affiliation: "MIT"
  title: "JuliaRobotics: Making robots walk with Julia"
  type: "talk"
  abstract: "Do you want to build Baymax, Data, or Robby the Robot? Do you want a future with more robots for rescue, delivery, and exploration (and fewer C++ linker errors)? I’ll introduce the JuliaRobotics org and show off our work on visualizing, simulating, and controlling a humanoid robot in Julia."
  desc: |
    Robotics research combines some of the best challenges from optimization, differential equations, machine learning, and high-performance computing. Robots are complex dynamical systems, and the fundamental questions of how to coordinate and control all but the simplest of robots are still open. It’s up to us as scientists and engineers and makers to bring about the best robotic future we can, and Julia will be part of that future.
    In this talk, I’ll discuss how we’re replacing Python, C++, and MATLAB with a new set of tools in Julia to simulate, visualize, and control robots. I’ll also introduce the JuliaRobotics organization, which has been founded to coordinate and promote robotics software development in Julia.
    In particular, I’ll discuss our work at MIT towards a major goal: controlling a 350 pound hydraulic walking humanoid robot in Julia. In the process, I’ll talk about the custom tools that we’ve built in JuliaRobotics as well as the ways we’re integrating with the excellent tools from JuliaDiffEq, JuliaOpt, FluxML, JuliaGeometry, JuliaGizmos, and more. You’ll hear about:

    * Simulating humanoid robots with <a href="https://github.com/JuliaRobotics/RigidBodyDynamics.jl">RigidBodyDynamics.jl</a> and <a href="https://github.com/JuliaRobotics/RigidBodySim.jl">RigidBodySim.jl</a>
    * Integrating robot models with the <a href="https://github.com/JuliaDiffEq">JuliaDiffEq</a> ecosystem
    * Visualizing robots in 3D with <a href="https://github.com/JuliaRobotics/MeshCatMechanisms.jl">MeshCatMechanisms.jl</a>
    * Interfacing with existing APIs and drivers with ccall
    * Planning and control via optimization with <a href="https://github.com/JuliaOpt/JuMP.jl">JuMP.jl</a> and <a href="https://github.com/JuliaOpt/MathOptInterface.jl">MathOptInterface.jl</a>
    * Machine learning with <a href="https://github.com/FluxML/Flux.jl">Flux.jl</a>  And along the way, I’ll talk about the advantages of Julia for robotics development and where we’re going in the future.

  bio: |
    Robin is a PhD student at MIT who should probably be working on his thesis instead of writing JuliaCon talk proposals. His early PhD work involved planning and control of the Atlas humanoid robot at the <a href="http://drc.mit.edu/">DARPA Robotics Challenge</a>, and he is now interested in helping walking robots safely move through the world without falling. He’s a recovering former MATLAB user, and he’s been developing robotics tools in Julia for the past few years. You can see some of his work on <a href="https://github.com/rdeits/">github</a> some of his silly projects on his <a href="http://blog.robindeits.com/">blog</a> and some of his thoughts on Julia for robotics at <a href="https://juliacomputing.com/case-studies/mit-robotics.html">Julia Computing’s case studies</a>.
  id: 128

- speaker: "Ján Dolinský"
  title: "Our Journey Through the Perils of AOT Compilation"
  type: "lightning"
  abstract: "We develop TIM, a computational engine for large-scale forecasting in energy industry covering load, gas, solar and wind. We share our lessons learned when trying to do AOT compilation of TIM and deploying the binary in the cloud. We cover Linux and Windows scenarios."
  desc: |
    We followed AOT capabilities of Julia closely since very early, i.e., Julia in v0.3 as this is one of the crucial capabilities for a commercial product development. Recently there was a useful article written by Viral which guided us through the AOT compilation process. After some trials we successfully managed to compile our Julia source code and put it in the production. Moreover, we enhanced the original scripts to make the compilation process smoother and enabled its automation. We would like to share our journey through this entire mission in detail covering compilation on Linux and Windows too.
    We shall also take into account performance comparisons of JIT compiled routines to their AOT versions.
  bio: |

  id: 129

- speaker: "Tanmay Mohapatra"
  avatar: "http://avatars.schd.ws/c/a3/5709068/avatar.jpg.320x320px.jpg?8bf"
  affiliation: "Julia Computing"
  title: "A Scalable Scheduler Plugin For Dagger on JuliaRun"
  type: "lightning"
  abstract: "Computational problems can often be represented as specific types of graphs known as DAGs. That allows an execution framework to execute parts in right order, schedule in parallel, and make optimal use of available resources. We present ideas on which we are building a scalable scheduler for Julia."
  desc: |
    We at Julia Computing are working on a scheduler for running large DAGs (directed acyclic graphs) on many nodes in parallel. Though the concepts it is being built on are generic, it currently leverages on the existing Julia package Dagger (for representing computation DAGs) and is intended to be used with JuliaRun (to deploy Julia applications in production at scale).
    Based on experiences in running large scale DAG computations with JuliaDB, this talk will present problems we encountered and our approach to tackle them. In particular: - minimizing data transfer across process and node boundaries - inter-process data transfer without blocking computation - avoiding single point scheduler bottleneck - graceful failure handling
  bio: |

  id: 130
